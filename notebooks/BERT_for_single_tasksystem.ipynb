{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf578dbf-e0bd-4128-9908-e3fab7220b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint, pformat\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import bigbench.api.results as bb\n",
    "\n",
    "from lmasss.log_handling import LogLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df86d9b-952c-4932-a3ce-7a4d8b2b4d05",
   "metadata": {},
   "source": [
    "# Creating test set\n",
    "\n",
    "Things to keep in mind:\n",
    "- Instances are used for multiple systems. These multiple results should not be split across train and test.\n",
    "- Instances are used for multiple n-shots. These multiple results should not be split across train and test.\n",
    "- Not all models have results available for all tasks, specifically, BIG-G sparse results are not available for multiple tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a6e175-7f4b-4e49-b97c-12b23c2a8b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55431 samples\n",
      "Sample #0:\n",
      "{'absolute_scores': [-17.807415008544922,\n",
      "                     -18.298959732055664,\n",
      "                     -12.581655502319336,\n",
      "                     -17.21178436279297,\n",
      "                     -31.068716049194336],\n",
      " 'correct': 0.0,\n",
      " 'input': 'In what follows, we provide short narratives, each of which '\n",
      "          'illustrates a common proverb. \\n'\n",
      "          'Narrative: Carla was having trouble juggling college, working at '\n",
      "          'the diner and being a mother. She never had a day off and was burnt '\n",
      "          'out. Her friend told her that her hard work would pay off one day '\n",
      "          \"and to keep going! Carla's friend was right; after a few more years \"\n",
      "          'of hard work, Carla graduated school and was able to get a better '\n",
      "          'job. She was able to take a vacation and become overall '\n",
      "          'successful.\\n'\n",
      "          'This narrative is a good illustration of the following proverb: ',\n",
      " 'metrics': {'calibration_multiple_choice_brier_score': 0.38902647532800894,\n",
      "             'macro_f1': 0.0,\n",
      "             'weighted_log_probabilities': -17.21178436279297},\n",
      " 'normalized_scores': [-5.244009971618652,\n",
      "                       -5.7355546951293945,\n",
      "                       -0.018250465393066406,\n",
      "                       -4.648379325866699,\n",
      "                       -18.50531005859375],\n",
      " 'scores': [-17.807415008544922,\n",
      "            -18.298959732055664,\n",
      "            -12.581655502319336,\n",
      "            -17.21178436279297,\n",
      "            -31.068716049194336],\n",
      " 'target_values': {'April showers bring forth May flowers': 1,\n",
      "                   'Distance lends enchantment to the view': 0,\n",
      "                   \"It's better to light a candle than to curse the darkness\": 0,\n",
      "                   'Seek and you shall find': 0,\n",
      "                   'Strike while the iron is hot': 0},\n",
      " 'targets': ['Seek and you shall find',\n",
      "             \"It's better to light a candle than to curse the darkness\",\n",
      "             'Strike while the iron is hot',\n",
      "             'April showers bring forth May flowers',\n",
      "             'Distance lends enchantment to the view']} \n"
     ]
    }
   ],
   "source": [
    "loader = (LogLoader(logdir = Path('../artifacts/logs'))\n",
    "        .with_output_unit('sample')\n",
    "        .with_tasks('paper-full')\n",
    "        .with_model_families(['BIG-G T=0'])\n",
    "        .with_model_sizes(['128b'])\n",
    "        .with_shots([0])\n",
    "        .with_query_types([bb.MultipleChoiceQuery])\n",
    ")\n",
    "\n",
    "samples = list(loader.load())\n",
    "print(f\"{len(samples)} samples\\nSample #0:\\n{pformat(vars(samples[0]))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d418133d-d8df-4959-a197-c591484285c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3968f8b-89b6-4baf-8bc9-14e218345bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>targets</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_values</th>\n",
       "      <th>correct</th>\n",
       "      <th>absolute_scores</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what follows, we provide short narratives, ...</td>\n",
       "      <td>[Seek and you shall find, It's better to light...</td>\n",
       "      <td>[-17.807415008544922, -18.298959732055664, -12...</td>\n",
       "      <td>{'April showers bring forth May flowers': 1, '...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-17.807415008544922, -18.298959732055664, -12...</td>\n",
       "      <td>[-5.244009971618652, -5.7355546951293945, -0.0...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  In what follows, we provide short narratives, ...   \n",
       "\n",
       "                                             targets  \\\n",
       "0  [Seek and you shall find, It's better to light...   \n",
       "\n",
       "                                              scores  \\\n",
       "0  [-17.807415008544922, -18.298959732055664, -12...   \n",
       "\n",
       "                                       target_values  correct  \\\n",
       "0  {'April showers bring forth May flowers': 1, '...      0.0   \n",
       "\n",
       "                                     absolute_scores  \\\n",
       "0  [-17.807415008544922, -18.298959732055664, -12...   \n",
       "\n",
       "                                   normalized_scores  \\\n",
       "0  [-5.244009971618652, -5.7355546951293945, -0.0...   \n",
       "\n",
       "                                             metrics  \n",
       "0  {'calibration_multiple_choice_brier_score': 0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    36548\n",
       "1.0    18510\n",
       "0.8       85\n",
       "0.6       63\n",
       "Name: correct, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Huggingface ready data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what follows, we provide short narratives, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  In what follows, we provide short narratives, ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    36548\n",
       "1    18510\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Original data:\")\n",
    "df = pd.DataFrame(samples)\n",
    "display(df.head(1))\n",
    "display(df['correct'].value_counts().head(4))\n",
    "\n",
    "print(\"\\n\\nHuggingface ready data:\")\n",
    "# df_hf stands for HuggingFace dataset compatible DataFrame\n",
    "df_hf = df[['input', 'correct']].rename(columns={'input':'text','correct':'label'})\n",
    "df_hf = df_hf[df_hf['label'].isin([0.0, 1.0])]\n",
    "df_hf[['label']] = df_hf[['label']].astype(int)\n",
    "display(df_hf.head(1))\n",
    "display(df_hf['label'].value_counts().head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "731c85a5-b41c-405f-bb49-33dcbadf032c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train accuracy: 0.34 (44046 instances)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test accuracy: 0.34 (11012 instances)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'If you follow these instructions, do you return to the starting point?\\nQ: Turn left. Turn left. Take 5 steps. Turn around. Take 5 steps.\\nA: ',\n",
       " 'label': 1,\n",
       " '__index_level_0__': 34229}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "test_fraction = 0.2\n",
    "\n",
    "# Per instance\n",
    "df_hf_train=df_hf.sample(frac=(1-test_fraction),random_state=1234)\n",
    "df_hf_test=df_hf.drop(df_hf_train.index)\n",
    "\n",
    "# Per task (approx)\n",
    "# df_hf_train = df.iloc[:900,:]\n",
    "# df_hf_test = df.iloc[900:,:]\n",
    "\n",
    "display(f\"Train accuracy: {df_hf_train['label'].mean():.2f} ({len(df_hf_train)} instances)\")\n",
    "display(f\"Test accuracy: {df_hf_test['label'].mean():.2f} ({len(df_hf_test)} instances)\")\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(df_hf_train, split='train')\n",
    "ds['test'] = Dataset.from_pandas(df_hf_test, split='test')\n",
    "\n",
    "dataset = ds\n",
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73464b95-16d6-4640-ad8c-5d5994db49a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d6d53845fb4fe1a523585fd484668e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4809568670a44f85b0b501b0e2767ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5705b86c-7b5f-4c0d-b707-c29e8bcacea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44046, 11012)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42) #.select(range(50))\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42) #.select(range(50))\n",
    "len(train_dataset), len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bb053d-5306-4480-93c1-11bfd7b16a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "env: WANDB_PROJECT=langasss\n",
      "env: WANDB_LOG_MODEL=true\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwschella\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "%env WANDB_PROJECT=langasss\n",
    "%env WANDB_LOG_MODEL=true\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ba8a37-0113-4e30-b7e2-a599d9f15940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Couldn't find a directory or a metric named 'roc_auc' in this version. It was picked from the master branch on github instead.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/wout/pp/llm-assessors/.env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 44046\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13770\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wout/pp/llm-assessors/notebooks/wandb/run-20220427_162204-4wp47jlt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wschella/langasss/runs/4wp47jlt\" target=\"_blank\">bert-bs32</a></strong> to <a href=\"https://wandb.ai/wschella/langasss\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13770' max='13770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13770/13770 2:27:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>0.587997</td>\n",
       "      <td>0.688249</td>\n",
       "      <td>0.581036</td>\n",
       "      <td>0.282801</td>\n",
       "      <td>0.380437</td>\n",
       "      <td>0.720573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.541400</td>\n",
       "      <td>0.544373</td>\n",
       "      <td>0.709226</td>\n",
       "      <td>0.595005</td>\n",
       "      <td>0.441105</td>\n",
       "      <td>0.506626</td>\n",
       "      <td>0.753256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.569472</td>\n",
       "      <td>0.697239</td>\n",
       "      <td>0.554690</td>\n",
       "      <td>0.534746</td>\n",
       "      <td>0.544536</td>\n",
       "      <td>0.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.649657</td>\n",
       "      <td>0.705776</td>\n",
       "      <td>0.573587</td>\n",
       "      <td>0.509257</td>\n",
       "      <td>0.539511</td>\n",
       "      <td>0.739821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.747163</td>\n",
       "      <td>0.693607</td>\n",
       "      <td>0.552203</td>\n",
       "      <td>0.500939</td>\n",
       "      <td>0.525324</td>\n",
       "      <td>0.719459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.921601</td>\n",
       "      <td>0.693607</td>\n",
       "      <td>0.554125</td>\n",
       "      <td>0.484840</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.709578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>1.101204</td>\n",
       "      <td>0.694788</td>\n",
       "      <td>0.557259</td>\n",
       "      <td>0.477864</td>\n",
       "      <td>0.514517</td>\n",
       "      <td>0.693583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>1.288037</td>\n",
       "      <td>0.695060</td>\n",
       "      <td>0.552729</td>\n",
       "      <td>0.518916</td>\n",
       "      <td>0.535289</td>\n",
       "      <td>0.687968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>1.402703</td>\n",
       "      <td>0.695877</td>\n",
       "      <td>0.555654</td>\n",
       "      <td>0.506305</td>\n",
       "      <td>0.529833</td>\n",
       "      <td>0.685668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1.633535</td>\n",
       "      <td>0.690792</td>\n",
       "      <td>0.547049</td>\n",
       "      <td>0.502281</td>\n",
       "      <td>0.523710</td>\n",
       "      <td>0.677489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-2000\n",
      "Configuration saved in test_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-2500\n",
      "Configuration saved in test_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-3000\n",
      "Configuration saved in test_trainer/checkpoint-3000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-3500\n",
      "Configuration saved in test_trainer/checkpoint-3500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-4000\n",
      "Configuration saved in test_trainer/checkpoint-4000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-4000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-4500\n",
      "Configuration saved in test_trainer/checkpoint-4500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-5000\n",
      "Configuration saved in test_trainer/checkpoint-5000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-5500\n",
      "Configuration saved in test_trainer/checkpoint-5500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-5500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-6000\n",
      "Configuration saved in test_trainer/checkpoint-6000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-6500\n",
      "Configuration saved in test_trainer/checkpoint-6500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-6500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-7000\n",
      "Configuration saved in test_trainer/checkpoint-7000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-7500\n",
      "Configuration saved in test_trainer/checkpoint-7500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-8000\n",
      "Configuration saved in test_trainer/checkpoint-8000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-8000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-8500\n",
      "Configuration saved in test_trainer/checkpoint-8500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-9000\n",
      "Configuration saved in test_trainer/checkpoint-9000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-9500\n",
      "Configuration saved in test_trainer/checkpoint-9500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-9500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-10000\n",
      "Configuration saved in test_trainer/checkpoint-10000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-10500\n",
      "Configuration saved in test_trainer/checkpoint-10500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-11000\n",
      "Configuration saved in test_trainer/checkpoint-11000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-11000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-11500\n",
      "Configuration saved in test_trainer/checkpoint-11500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-12000\n",
      "Configuration saved in test_trainer/checkpoint-12000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-12000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to test_trainer/checkpoint-12500\n",
      "Configuration saved in test_trainer/checkpoint-12500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-13000\n",
      "Configuration saved in test_trainer/checkpoint-13000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-13500\n",
      "Configuration saved in test_trainer/checkpoint-13500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-13500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11012\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /tmp/tmpyoh367ha\n",
      "Configuration saved in /tmp/tmpyoh367ha/config.json\n",
      "Model weights saved in /tmp/tmpyoh367ha/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='413.249 MB of 413.249 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█▄▇▃▃▃▃▄▂</td></tr><tr><td>eval/f1</td><td>▁▆██▇▇▇█▇▇</td></tr><tr><td>eval/loss</td><td>▁▁▁▂▂▃▅▆▇█</td></tr><tr><td>eval/precision</td><td>▆█▂▅▂▂▂▂▂▁</td></tr><tr><td>eval/recall</td><td>▁▅█▇▇▇▆█▇▇</td></tr><tr><td>eval/roc_auc</td><td>▅█▇▇▅▄▂▂▂▁</td></tr><tr><td>eval/runtime</td><td>▂▁▄█▅▄▄█▂▃</td></tr><tr><td>eval/samples_per_second</td><td>▇█▅▁▄▅▅▁▇▆</td></tr><tr><td>eval/steps_per_second</td><td>▇█▅▁▄▅▅▁▇▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>████▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.69079</td></tr><tr><td>eval/f1</td><td>0.52371</td></tr><tr><td>eval/loss</td><td>1.63354</td></tr><tr><td>eval/precision</td><td>0.54705</td></tr><tr><td>eval/recall</td><td>0.50228</td></tr><tr><td>eval/roc_auc</td><td>0.67749</td></tr><tr><td>eval/runtime</td><td>71.1603</td></tr><tr><td>eval/samples_per_second</td><td>154.749</td></tr><tr><td>eval/steps_per_second</td><td>4.848</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>13770</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.13</td></tr><tr><td>train/total_flos</td><td>1.158898954438656e+17</td></tr><tr><td>train/train_loss</td><td>0.33052</td></tr><tr><td>train/train_runtime</td><td>8839.0085</td></tr><tr><td>train/train_samples_per_second</td><td>49.831</td></tr><tr><td>train/train_steps_per_second</td><td>1.558</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bert-bs32</strong>: <a href=\"https://wandb.ai/wschella/langasss/runs/4wp47jlt\" target=\"_blank\">https://wandb.ai/wschella/langasss/runs/4wp47jlt</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220427_162204-4wp47jlt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"./test_trainer/checkpoint-13500\", num_labels=2)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"bert-bs32\",\n",
    "    num_train_epochs=10\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": load_metric(\"accuracy\"),\n",
    "    \"precision\": load_metric(\"precision\"),\n",
    "    \"recall\": load_metric(\"recall\"),\n",
    "    \"f1\": load_metric(\"f1\"),\n",
    "    \"roc_auc\": load_metric(\"roc_auc\"),\n",
    "}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)    \n",
    "    # ROC AUC metric requires probabilities instead of logits, and only of the \"postive\" class (=\"highest label\" = 1).\n",
    "    # Needs to change for multi-class or multi-label.\n",
    "    prediction_scores = scipy.special.softmax(logits,axis=-1)[:,-1]\n",
    "    return {\n",
    "          \"accuracy\": metrics[\"accuracy\"].compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "          \"precision\": metrics[\"precision\"].compute(predictions=predictions, references=labels)[\"precision\"],\n",
    "          \"recall\": metrics[\"recall\"].compute(predictions=predictions, references=labels)[\"recall\"],\n",
    "          \"f1\": metrics[\"f1\"].compute(predictions=predictions, references=labels)[\"f1\"],\n",
    "          \"roc_auc\": metrics[\"roc_auc\"].compute(prediction_scores=prediction_scores, references=labels)[\"roc_auc\"],\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "406d51ce-e5c8-4c44-958e-c12d1e4818c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce8153-b7de-46ff-9457-fcf1f1e58090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
