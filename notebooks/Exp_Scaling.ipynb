{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a2ab21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T15:09:04.708102Z",
     "iopub.status.busy": "2022-10-19T15:09:04.707427Z",
     "iopub.status.idle": "2022-10-19T15:09:04.739365Z",
     "shell.execute_reply": "2022-10-19T15:09:04.738362Z"
    },
    "papermill": {
     "duration": 0.051095,
     "end_time": "2022-10-19T15:09:04.742313",
     "exception": false,
     "start_time": "2022-10-19T15:09:04.691218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8a4b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T15:09:04.769716Z",
     "iopub.status.busy": "2022-10-19T15:09:04.768817Z",
     "iopub.status.idle": "2022-10-19T15:09:10.115268Z",
     "shell.execute_reply": "2022-10-19T15:09:10.114045Z"
    },
    "papermill": {
     "duration": 5.362439,
     "end_time": "2022-10-19T15:09:10.118515",
     "exception": false,
     "start_time": "2022-10-19T15:09:04.756076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from dataclasses import dataclass\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import lass.train\n",
    "import lass.test\n",
    "import lass.datasets\n",
    "from lass.log_handling import PaperTasks, LogIssues, LogLoaderArgs, LogLoader\n",
    "\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_warning() # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af13443",
   "metadata": {
    "papermill": {
     "duration": 0.008265,
     "end_time": "2022-10-19T15:09:10.141781",
     "exception": false,
     "start_time": "2022-10-19T15:09:10.133516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Find non-empty tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24827d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T15:09:10.159687Z",
     "iopub.status.busy": "2022-10-19T15:09:10.158779Z",
     "iopub.status.idle": "2022-10-19T15:09:27.920386Z",
     "shell.execute_reply": "2022-10-19T15:09:27.919066Z"
    },
    "papermill": {
     "duration": 17.773207,
     "end_time": "2022-10-19T15:09:27.923701",
     "exception": false,
     "start_time": "2022-10-19T15:09:10.150494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader_args = LogLoaderArgs(\n",
    "    logdir=\"../artifacts/logs\",\n",
    "    tasks='paper-full',\n",
    "    model_families=[\"BIG-G T=0\"],\n",
    "    model_sizes=[\"128b\"],\n",
    "    shots=[0],\n",
    "    query_types=[\"multiple_choice\"],\n",
    ")\n",
    "\n",
    "loader = LogLoader(loader_args)\n",
    "data = lass.datasets.to_dataframe(loader)\n",
    "nonempty_tasks = data.task.unique().tolist()\n",
    "non_empty_tasks = [task for task in PaperTasks.full() if task in nonempty_tasks]\n",
    "assert \"ascii_word_recognition\" not in non_empty_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748d944b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T15:09:27.946746Z",
     "iopub.status.busy": "2022-10-19T15:09:27.946372Z",
     "iopub.status.idle": "2022-10-19T15:09:27.976905Z",
     "shell.execute_reply": "2022-10-19T15:09:27.975875Z"
    },
    "papermill": {
     "duration": 0.042904,
     "end_time": "2022-10-19T15:09:27.979835",
     "exception": false,
     "start_time": "2022-10-19T15:09:27.936931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Architecture():\n",
    "    name: str\n",
    "    name_short: str\n",
    "    batch_size: int\n",
    "    gradient_accumulation_steps: int\n",
    "\n",
    "architecture = Architecture(\n",
    "    name=\"microsoft/deberta-v3-base\",\n",
    "    name_short=\"deberta\",\n",
    "    batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "MODEL_SIZES = {\n",
    "    # \"2m\": 2098048,\n",
    "    \"16m\": 16780288,\n",
    "    \"53m\": 56629632,\n",
    "    \"125m\": 134228992,\n",
    "    \"244m\": 262161280,\n",
    "    \"422m\": 453009408,\n",
    "    \"1b\": 1073784832,\n",
    "    \"2b\": 2097218560,\n",
    "    \"4b\": 3623973888,\n",
    "    \"8b\": 8590102528,\n",
    "    \"27b\": 28991404032,\n",
    "    \"128b\": 137440272384,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b73d78",
   "metadata": {
    "papermill": {
     "duration": 0.010655,
     "end_time": "2022-10-19T15:09:28.004676",
     "exception": false,
     "start_time": "2022-10-19T15:09:27.994021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train An Assessor Model for All Different BIG-G Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acaf64fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T15:09:28.028201Z",
     "iopub.status.busy": "2022-10-19T15:09:28.027637Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-10-19T15:09:28.017465",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/src/lass/pipeline.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'correct'] = df['correct'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'In what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: The anxiety about getting the injection made her unable to sleep that night, but the actual experience wasn\\'t as bad as she thought it would be.\\nThis narrative is a good illustration of the following proverb: Don\\'t meet troubles half-way\\n\\nNarrative: Inmate 76853 lay on the execution gurney ready to utter his last words before lethal drugs ended his life.  He looked through the mirror into the witness room and said to his family and his victim\\'s family: \"I killed Victoria.  It was wrong.  I can\\'t take it back.  I earned my punishment, and I accept it.\"  Inmate 76853 turned his head back to stare at the stark ceiling and paid his debt with his life.\\nThis narrative is a good illustration of the following proverb: The wages of sin is death\\n\\nNarrative: \"Oil change? Why would I want that Tim told the auto tech. Tim was convinced the mechanic was just trying to figure out a way to make even more money and he didn\\'t feel like spending $50 on one. Well, 12 months later, when his car started to smoke, Tim head back to the same auto shop. Unfortunately, because he declined the oil change, his engine became damaged over time and it was going to cost over $1,000 to repair the damage.\\nThis narrative is a good illustration of the following proverb: A stitch in time saves nine\\n\\nNarrative: A father brought his son to the local airport for a show. They got up close to an plane in the show. The pilot arrives and turns on the engine. The plane makes a considerable roar, scaring the child. The child cowers behind the father as the father reassures the child that it is just a loud noise and it won\\'t hurt him.\\nThis narrative is a good illustration of the following proverb: ', 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize.<locals>.tokenize_function at 0x7f38853a3130> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9cd1bb94454a03963d2da9ee2ea5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df306d38c9b4291b8088297c55bddb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwschella\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path scaling/wandb/wandb/ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path scaling/wandb/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20221019_171043-3kmjfcxk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wschella/lass/runs/3kmjfcxk\" target=\"_blank\">deberta-for-16m-bs16*2-3sh-instance-split</a></strong> to <a href=\"https://wandb.ai/wschella/lass\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 43236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Instantaneous batch size per device = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Gradient Accumulation steps = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total optimization steps = 10808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10808' max='10808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10808/10808 4:40:41, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Conf Distribution Accuracy</th>\n",
       "      <th>Conf Distribution Precision</th>\n",
       "      <th>Conf Distribution Recall</th>\n",
       "      <th>Conf Distribution F1</th>\n",
       "      <th>Conf Distribution Roc Auc</th>\n",
       "      <th>Conf Distribution Bs</th>\n",
       "      <th>Conf Distribution Bs Mcb</th>\n",
       "      <th>Conf Distribution Bs Dsc</th>\n",
       "      <th>Conf Distribution Bs Unc</th>\n",
       "      <th>Conf Distribution Balanced Accuracy</th>\n",
       "      <th>Conf Absolute Accuracy</th>\n",
       "      <th>Conf Absolute Precision</th>\n",
       "      <th>Conf Absolute Recall</th>\n",
       "      <th>Conf Absolute F1</th>\n",
       "      <th>Conf Absolute Roc Auc</th>\n",
       "      <th>Conf Absolute Bs</th>\n",
       "      <th>Conf Absolute Bs Mcb</th>\n",
       "      <th>Conf Absolute Bs Dsc</th>\n",
       "      <th>Conf Absolute Bs Unc</th>\n",
       "      <th>Conf Absolute Balanced Accuracy</th>\n",
       "      <th>Conf Normalized Accuracy</th>\n",
       "      <th>Conf Normalized Precision</th>\n",
       "      <th>Conf Normalized Recall</th>\n",
       "      <th>Conf Normalized F1</th>\n",
       "      <th>Conf Normalized Roc Auc</th>\n",
       "      <th>Conf Normalized Bs</th>\n",
       "      <th>Conf Normalized Bs Mcb</th>\n",
       "      <th>Conf Normalized Bs Dsc</th>\n",
       "      <th>Conf Normalized Bs Unc</th>\n",
       "      <th>Conf Normalized Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Bs</th>\n",
       "      <th>Bs Mcb</th>\n",
       "      <th>Bs Dsc</th>\n",
       "      <th>Bs Unc</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.587989</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.676280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.682198</td>\n",
       "      <td>0.200811</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.580500</td>\n",
       "      <td>0.578786</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.674986</td>\n",
       "      <td>0.498058</td>\n",
       "      <td>0.512564</td>\n",
       "      <td>0.505207</td>\n",
       "      <td>0.697789</td>\n",
       "      <td>0.198110</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.023748</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.632649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.575302</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.680163</td>\n",
       "      <td>0.510682</td>\n",
       "      <td>0.286693</td>\n",
       "      <td>0.367228</td>\n",
       "      <td>0.698215</td>\n",
       "      <td>0.196428</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.572620</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.676650</td>\n",
       "      <td>0.500633</td>\n",
       "      <td>0.451742</td>\n",
       "      <td>0.474932</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.195855</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.025705</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.618025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.569700</td>\n",
       "      <td>0.582962</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.684507</td>\n",
       "      <td>0.582868</td>\n",
       "      <td>0.089377</td>\n",
       "      <td>0.154989</td>\n",
       "      <td>0.701874</td>\n",
       "      <td>0.199268</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.025317</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.529380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.567766</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.684600</td>\n",
       "      <td>0.519363</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.414349</td>\n",
       "      <td>0.706048</td>\n",
       "      <td>0.193715</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.026449</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.595991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.571959</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.679053</td>\n",
       "      <td>0.505102</td>\n",
       "      <td>0.424043</td>\n",
       "      <td>0.461037</td>\n",
       "      <td>0.703463</td>\n",
       "      <td>0.194533</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.026161</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.612582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.567200</td>\n",
       "      <td>0.572652</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.682104</td>\n",
       "      <td>0.508675</td>\n",
       "      <td>0.527413</td>\n",
       "      <td>0.517875</td>\n",
       "      <td>0.708943</td>\n",
       "      <td>0.194911</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.026699</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.641782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.571785</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.685339</td>\n",
       "      <td>0.523626</td>\n",
       "      <td>0.310109</td>\n",
       "      <td>0.389527</td>\n",
       "      <td>0.706044</td>\n",
       "      <td>0.195557</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.026131</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.587531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.563400</td>\n",
       "      <td>0.573841</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.680163</td>\n",
       "      <td>0.505833</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.512813</td>\n",
       "      <td>0.707956</td>\n",
       "      <td>0.195542</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.026698</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.638411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.559300</td>\n",
       "      <td>0.574573</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.679516</td>\n",
       "      <td>0.505886</td>\n",
       "      <td>0.429469</td>\n",
       "      <td>0.464556</td>\n",
       "      <td>0.701693</td>\n",
       "      <td>0.196479</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.025092</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.614338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>0.576404</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.676003</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.445174</td>\n",
       "      <td>0.470784</td>\n",
       "      <td>0.702417</td>\n",
       "      <td>0.197593</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.615835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.581880</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.679053</td>\n",
       "      <td>0.504459</td>\n",
       "      <td>0.484580</td>\n",
       "      <td>0.494320</td>\n",
       "      <td>0.703851</td>\n",
       "      <td>0.199456</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>0.025760</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.628362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.619196</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.666020</td>\n",
       "      <td>0.483022</td>\n",
       "      <td>0.450885</td>\n",
       "      <td>0.466401</td>\n",
       "      <td>0.686028</td>\n",
       "      <td>0.213252</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.021436</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.609942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.627290</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.666204</td>\n",
       "      <td>0.483697</td>\n",
       "      <td>0.461736</td>\n",
       "      <td>0.472462</td>\n",
       "      <td>0.681055</td>\n",
       "      <td>0.215470</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.612907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.496700</td>\n",
       "      <td>0.630888</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.676280</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372930</td>\n",
       "      <td>0.427216</td>\n",
       "      <td>0.676790</td>\n",
       "      <td>0.214499</td>\n",
       "      <td>0.015263</td>\n",
       "      <td>0.019689</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.597208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.663607</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.671751</td>\n",
       "      <td>0.491165</td>\n",
       "      <td>0.388921</td>\n",
       "      <td>0.434104</td>\n",
       "      <td>0.663873</td>\n",
       "      <td>0.222877</td>\n",
       "      <td>0.021269</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.598028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.442900</td>\n",
       "      <td>0.669535</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.668423</td>\n",
       "      <td>0.485676</td>\n",
       "      <td>0.411479</td>\n",
       "      <td>0.445509</td>\n",
       "      <td>0.662239</td>\n",
       "      <td>0.225155</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.601448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.697493</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.668608</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>0.424615</td>\n",
       "      <td>0.453423</td>\n",
       "      <td>0.662853</td>\n",
       "      <td>0.231196</td>\n",
       "      <td>0.029659</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.605008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.735629</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.670549</td>\n",
       "      <td>0.489506</td>\n",
       "      <td>0.412907</td>\n",
       "      <td>0.447955</td>\n",
       "      <td>0.657027</td>\n",
       "      <td>0.237044</td>\n",
       "      <td>0.034756</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.603392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.741181</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.276985</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.191582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.482692</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.297511</td>\n",
       "      <td>0.585515</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.552357</td>\n",
       "      <td>0.495840</td>\n",
       "      <td>0.379178</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.529016</td>\n",
       "      <td>0.631065</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.594580</td>\n",
       "      <td>0.666389</td>\n",
       "      <td>0.483181</td>\n",
       "      <td>0.438892</td>\n",
       "      <td>0.459973</td>\n",
       "      <td>0.654678</td>\n",
       "      <td>0.239677</td>\n",
       "      <td>0.036935</td>\n",
       "      <td>0.016184</td>\n",
       "      <td>0.218925</td>\n",
       "      <td>0.607090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-1500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-2500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-4500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-5500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-6500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-7500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-8500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-10000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-10000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-9500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-10500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-10500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-10500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-10000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from scaling/deberta-for-16m-bs16*2-3sh-instance-split-10191710/checkpoint-3000 (score: 0.5677661299705505).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b14e50582647518b858f47bfb9e35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/balanced_accuracy</td><td></td></tr><tr><td>eval/bs</td><td></td></tr><tr><td>eval/bs_dsc</td><td></td></tr><tr><td>eval/bs_mcb</td><td></td></tr><tr><td>eval/bs_unc</td><td></td></tr><tr><td>eval/conf_absolute_accuracy</td><td></td></tr><tr><td>eval/conf_absolute_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_absolute_bs</td><td></td></tr><tr><td>eval/conf_absolute_bs_dsc</td><td></td></tr><tr><td>eval/conf_absolute_bs_mcb</td><td></td></tr><tr><td>eval/conf_absolute_bs_unc</td><td></td></tr><tr><td>eval/conf_absolute_f1</td><td></td></tr><tr><td>eval/conf_absolute_precision</td><td></td></tr><tr><td>eval/conf_absolute_recall</td><td></td></tr><tr><td>eval/conf_absolute_roc_auc</td><td></td></tr><tr><td>eval/conf_distribution_accuracy</td><td></td></tr><tr><td>eval/conf_distribution_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_distribution_bs</td><td></td></tr><tr><td>eval/conf_distribution_bs_dsc</td><td></td></tr><tr><td>eval/conf_distribution_bs_mcb</td><td></td></tr><tr><td>eval/conf_distribution_bs_unc</td><td></td></tr><tr><td>eval/conf_distribution_f1</td><td></td></tr><tr><td>eval/conf_distribution_precision</td><td></td></tr><tr><td>eval/conf_distribution_recall</td><td></td></tr><tr><td>eval/conf_distribution_roc_auc</td><td></td></tr><tr><td>eval/conf_normalized_accuracy</td><td></td></tr><tr><td>eval/conf_normalized_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_normalized_bs</td><td></td></tr><tr><td>eval/conf_normalized_bs_dsc</td><td></td></tr><tr><td>eval/conf_normalized_bs_mcb</td><td></td></tr><tr><td>eval/conf_normalized_bs_unc</td><td></td></tr><tr><td>eval/conf_normalized_f1</td><td></td></tr><tr><td>eval/conf_normalized_precision</td><td></td></tr><tr><td>eval/conf_normalized_recall</td><td></td></tr><tr><td>eval/conf_normalized_roc_auc</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/roc_auc</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.66639</td></tr><tr><td>eval/balanced_accuracy</td><td>0.60709</td></tr><tr><td>eval/bs</td><td>0.23968</td></tr><tr><td>eval/bs_dsc</td><td>0.01618</td></tr><tr><td>eval/bs_mcb</td><td>0.03694</td></tr><tr><td>eval/bs_unc</td><td>0.21893</td></tr><tr><td>eval/conf_absolute_accuracy</td><td>0.67129</td></tr><tr><td>eval/conf_absolute_balanced_accuracy</td><td>0.55236</td></tr><tr><td>eval/conf_absolute_bs</td><td>0.25829</td></tr><tr><td>eval/conf_absolute_bs_dsc</td><td>0.0076</td></tr><tr><td>eval/conf_absolute_bs_mcb</td><td>0.04696</td></tr><tr><td>eval/conf_absolute_bs_unc</td><td>0.21893</td></tr><tr><td>eval/conf_absolute_f1</td><td>0.29751</td></tr><tr><td>eval/conf_absolute_precision</td><td>0.48269</td></tr><tr><td>eval/conf_absolute_recall</td><td>0.21502</td></tr><tr><td>eval/conf_absolute_roc_auc</td><td>0.58552</td></tr><tr><td>eval/conf_distribution_accuracy</td><td>0.69514</td></tr><tr><td>eval/conf_distribution_balanced_accuracy</td><td>0.58614</td></tr><tr><td>eval/conf_distribution_bs</td><td>0.19158</td></tr><tr><td>eval/conf_distribution_bs_dsc</td><td>0.02734</td></tr><tr><td>eval/conf_distribution_bs_mcb</td><td>0.0</td></tr><tr><td>eval/conf_distribution_bs_unc</td><td>0.21893</td></tr><tr><td>eval/conf_distribution_f1</td><td>0.37037</td></tr><tr><td>eval/conf_distribution_precision</td><td>0.55876</td></tr><tr><td>eval/conf_distribution_recall</td><td>0.27698</td></tr><tr><td>eval/conf_distribution_roc_auc</td><td>0.71563</td></tr><tr><td>eval/conf_normalized_accuracy</td><td>0.49584</td></tr><tr><td>eval/conf_normalized_balanced_accuracy</td><td>0.59458</td></tr><tr><td>eval/conf_normalized_bs</td><td>0.34432</td></tr><tr><td>eval/conf_normalized_bs_dsc</td><td>0.01175</td></tr><tr><td>eval/conf_normalized_bs_mcb</td><td>0.13715</td></tr><tr><td>eval/conf_normalized_bs_unc</td><td>0.21893</td></tr><tr><td>eval/conf_normalized_f1</td><td>0.52902</td></tr><tr><td>eval/conf_normalized_precision</td><td>0.37918</td></tr><tr><td>eval/conf_normalized_recall</td><td>0.87464</td></tr><tr><td>eval/conf_normalized_roc_auc</td><td>0.63107</td></tr><tr><td>eval/f1</td><td>0.45997</td></tr><tr><td>eval/loss</td><td>0.74118</td></tr><tr><td>eval/precision</td><td>0.48318</td></tr><tr><td>eval/recall</td><td>0.43889</td></tr><tr><td>eval/roc_auc</td><td>0.65468</td></tr><tr><td>eval/runtime</td><td>152.0338</td></tr><tr><td>eval/samples_per_second</td><td>71.155</td></tr><tr><td>eval/steps_per_second</td><td>4.453</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>10808</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4007</td></tr><tr><td>train/total_flos</td><td>9.100753635761357e+16</td></tr><tr><td>train/train_loss</td><td>0.52315</td></tr><tr><td>train/train_runtime</td><td>16842.8541</td></tr><tr><td>train/train_samples_per_second</td><td>20.536</td></tr><tr><td>train/train_steps_per_second</td><td>0.642</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">deberta-for-16m-bs16*2-3sh-instance-split</strong>: <a href=\"https://wandb.ai/wschella/lass/runs/3kmjfcxk\" target=\"_blank\">https://wandb.ai/wschella/lass/runs/3kmjfcxk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/run-20221019_171043-3kmjfcxk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/src/lass/pipeline.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'correct'] = df['correct'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "for size, size_precise in MODEL_SIZES.items():\n",
    "    data_args = LogLoaderArgs(\n",
    "        logdir=\"../artifacts/logs\",\n",
    "        tasks='paper-full',\n",
    "        model_families=[\"BIG-G T=0\"],\n",
    "        model_sizes=[size],\n",
    "        shots=[3],\n",
    "        query_types=[\"multiple_choice\"],\n",
    "    )\n",
    "\n",
    "    model = lass.train.train(\n",
    "        data_args=data_args,\n",
    "        group=\"scale-relation\",\n",
    "        split=\"instance\",\n",
    "        model_name=architecture.name,\n",
    "        model_name_short=f\"{architecture.name_short}-for-{size}\",\n",
    "        batch_size=architecture.batch_size,\n",
    "        gradient_accumulation_steps=architecture.gradient_accumulation_steps,\n",
    "        include_model_in_input=False,\n",
    "        include_n_targets_in_input=False,\n",
    "        output_dir=\"scaling\",\n",
    "        n_epochs=8,\n",
    "        extra_training_args={\n",
    "            \"warmup_steps\": 3000,\n",
    "            \"learning_rate\": 2e-5,\n",
    "        },\n",
    "        # is_test_run=True,\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Metrics in total\n",
    "    results_ = lass.test.test(\n",
    "            data_args=data_args,\n",
    "            split = 'instance',\n",
    "            model_loc=model,\n",
    "            model_name=architecture.name,\n",
    "            max_sequence_length = 512,\n",
    "    )\n",
    "    results['_total'] = results_['metrics']\n",
    "    results['_total']['count'] = len(results_['test'])\n",
    "\n",
    "    print(\"Tested on everything\")\n",
    "\n",
    "    # Metrics per task\n",
    "    for task in non_empty_tasks:\n",
    "        task_data_args = LogLoaderArgs(**(loader_args.__dict__ | {'tasks': [task]}))\n",
    "        results_ = lass.test.test(\n",
    "            data_args=task_data_args,\n",
    "            split = 'instance',\n",
    "            model_loc=model,\n",
    "            model_name=architecture.name,\n",
    "            max_sequence_length = 512,\n",
    "        )\n",
    "        results[task] = results_['metrics']\n",
    "        results[task]['count'] = len(results_['test'])\n",
    "\n",
    "        df = pd.DataFrame.from_dict(results, orient='index')\n",
    "        df.to_csv(f\"scaling/{size}.csv\")\n",
    "        print(f\"Tested on {task}\")\n",
    "\n",
    "    print(\"Tested on all tasks\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "Exp_Scaling.ipynb",
   "output_path": "Exp_Scaling.ipynb",
   "parameters": {},
   "start_time": "2022-10-19T15:09:03.802684",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "eed4bfcf3d3cfcdb00482c10052e8eba5705b015008b357326d56e176b5397df"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04f4b0c8be91487fbe42d1ce5815d0b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b32e7fddec343d9b2321b4d1210dc97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ce6b73fff9f4669bb6f23d1af93a387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b2fc164d166f4188ac28e0b6a60fe9f6",
       "placeholder": "",
       "style": "IPY_MODEL_a278bd8c30194df1894c1cb1649d9cae",
       "value": "100%"
      }
     },
     "15827d9d99504fb3b88e17672778e680": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18f6e890ecd14702944c3539177b13d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e5a36b920304e18920160639e140376": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_723ea4d8387840a18e7c175d106b7072",
        "IPY_MODEL_7fc75ca9aab6457e980e7a3fa4051706"
       ],
       "layout": "IPY_MODEL_b106bd7421e040988d70b25daa92cd79"
      }
     },
     "30992fa1ab51493bbee0e9cc261cdb41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "332a015982f24956b3a39b4ca2ddc856": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6bb092fb799e4b20abfd8d4c58146fad",
       "placeholder": "",
       "style": "IPY_MODEL_7c9957ff07f646e3809698a6226f3718",
       "value": " 44/44 [00:41&lt;00:00,  7.09s/ba]"
      }
     },
     "42c2a8633b07482c809a9ce7f80706f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0ce6b73fff9f4669bb6f23d1af93a387",
        "IPY_MODEL_9db54ba3953e43ad8fa80c7cf99da07e",
        "IPY_MODEL_332a015982f24956b3a39b4ca2ddc856"
       ],
       "layout": "IPY_MODEL_d36258a8d46d4feab32ddfa38aa4477f"
      }
     },
     "44f8f685ad5248f79cad4966f47915c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7deaac4f7bb84ea593f5a2c19359acbc",
       "placeholder": "",
       "style": "IPY_MODEL_ec8739cd3e2c40f4b4dca688d64aed71",
       "value": " 11/11 [00:08&lt;00:00,  1.45s/ba]"
      }
     },
     "4c2f15e1ed134639895d57241bbe16f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e3c243854e7460f8a8d875a9ac065fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_645f0487846a4900a8d62ca3bd66b315",
        "IPY_MODEL_7ca568d44e234f2c90e3128be30f70b1"
       ],
       "layout": "IPY_MODEL_97e6ff26997144119d461607cd486fd9"
      }
     },
     "645f0487846a4900a8d62ca3bd66b315": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_15827d9d99504fb3b88e17672778e680",
       "placeholder": "",
       "style": "IPY_MODEL_7534483960994abd8d320d911898bd15",
       "value": ""
      }
     },
     "6495aaad0c1e47369e28305b0bd4e8db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c264cffbdb9a4840bc2285f43012d258",
        "IPY_MODEL_8a0dedc4828f410d8c5989abea7b6e98",
        "IPY_MODEL_44f8f685ad5248f79cad4966f47915c4"
       ],
       "layout": "IPY_MODEL_e3dd3025694b40c1b2a153237741743e"
      }
     },
     "6bb092fb799e4b20abfd8d4c58146fad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "723ea4d8387840a18e7c175d106b7072": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18f6e890ecd14702944c3539177b13d6",
       "placeholder": "",
       "style": "IPY_MODEL_dd2466ed1f1c42f78837b29cd4bf99ed",
       "value": ""
      }
     },
     "7534483960994abd8d320d911898bd15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "76e9c6a2014c452eb4520d9e4d64a806": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7c9957ff07f646e3809698a6226f3718": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7ca568d44e234f2c90e3128be30f70b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c2f15e1ed134639895d57241bbe16f0",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9501065f1e444c39ba4218a2ba6c3e68",
       "value": 0
      }
     },
     "7cd4ae3db2b644aa9898a22de41d84e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7deaac4f7bb84ea593f5a2c19359acbc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f80a871e91b4225908f3e968204b4a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7fc75ca9aab6457e980e7a3fa4051706": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_04f4b0c8be91487fbe42d1ce5815d0b3",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7f80a871e91b4225908f3e968204b4a4",
       "value": 0
      }
     },
     "8a0dedc4828f410d8c5989abea7b6e98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7cd4ae3db2b644aa9898a22de41d84e5",
       "max": 11,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76e9c6a2014c452eb4520d9e4d64a806",
       "value": 11
      }
     },
     "8d420949b50142e7b4150066293eee56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9501065f1e444c39ba4218a2ba6c3e68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "97e6ff26997144119d461607cd486fd9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9db54ba3953e43ad8fa80c7cf99da07e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b32e7fddec343d9b2321b4d1210dc97",
       "max": 44,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b4a82e83df6a44108ca1633a9dcf6e3c",
       "value": 44
      }
     },
     "a278bd8c30194df1894c1cb1649d9cae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b106bd7421e040988d70b25daa92cd79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2fc164d166f4188ac28e0b6a60fe9f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4a82e83df6a44108ca1633a9dcf6e3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c264cffbdb9a4840bc2285f43012d258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8d420949b50142e7b4150066293eee56",
       "placeholder": "",
       "style": "IPY_MODEL_30992fa1ab51493bbee0e9cc261cdb41",
       "value": "100%"
      }
     },
     "d36258a8d46d4feab32ddfa38aa4477f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd2466ed1f1c42f78837b29cd4bf99ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e3dd3025694b40c1b2a153237741743e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec8739cd3e2c40f4b4dca688d64aed71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}