{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b540e10",
   "metadata": {
    "papermill": {
     "duration": 0.018711,
     "end_time": "2022-07-29T08:02:16.348112",
     "exception": false,
     "start_time": "2022-07-29T08:02:16.329401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Assessor Architecture Comparison\n",
    "\n",
    "This notebook does a rudimentary comparison of different architectures for to use for assessors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cd0f2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-29T08:02:16.370727Z",
     "iopub.status.busy": "2022-07-29T08:02:16.369546Z",
     "iopub.status.idle": "2022-07-29T08:02:16.395982Z",
     "shell.execute_reply": "2022-07-29T08:02:16.395069Z"
    },
    "papermill": {
     "duration": 0.040472,
     "end_time": "2022-07-29T08:02:16.399345",
     "exception": false,
     "start_time": "2022-07-29T08:02:16.358873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d40a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-29T08:02:16.467350Z",
     "iopub.status.busy": "2022-07-29T08:02:16.466742Z",
     "iopub.status.idle": "2022-07-29T08:02:21.637959Z",
     "shell.execute_reply": "2022-07-29T08:02:21.636957Z"
    },
    "papermill": {
     "duration": 5.189242,
     "end_time": "2022-07-29T08:02:21.641015",
     "exception": false,
     "start_time": "2022-07-29T08:02:16.451773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import lass.train\n",
    "from lass.log_handling import LoaderArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccb44ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-29T08:02:21.660620Z",
     "iopub.status.busy": "2022-07-29T08:02:21.659563Z",
     "iopub.status.idle": "2022-07-29T08:02:21.684176Z",
     "shell.execute_reply": "2022-07-29T08:02:21.682867Z"
    },
    "papermill": {
     "duration": 0.035756,
     "end_time": "2022-07-29T08:02:21.685688",
     "exception": false,
     "start_time": "2022-07-29T08:02:21.649932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbad83a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-29T08:02:21.702000Z",
     "iopub.status.busy": "2022-07-29T08:02:21.701798Z",
     "iopub.status.idle": "2022-07-29T08:02:21.734870Z",
     "shell.execute_reply": "2022-07-29T08:02:21.733716Z"
    },
    "papermill": {
     "duration": 0.043651,
     "end_time": "2022-07-29T08:02:21.736740",
     "exception": false,
     "start_time": "2022-07-29T08:02:21.693089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Architecture():\n",
    "    name: str\n",
    "    name_short: str\n",
    "    batch_size: int\n",
    "    gradient_accumulation_steps: int\n",
    "\n",
    "ARCHITECTURES = [\n",
    "    # Architecture(\n",
    "    #     name=\"albert-base-v2\",\n",
    "    #     name_short=\"albert\",\n",
    "    #     batch_size=32,\n",
    "    #     gradient_accumulation_steps=1,\n",
    "    # ),\n",
    "    # Architecture(\n",
    "    #     name=\"bert-base-cased\",\n",
    "    #     name_short=\"bert\",\n",
    "    #     batch_size=32,\n",
    "    #     gradient_accumulation_steps=1,\n",
    "    # ),\n",
    "    Architecture(\n",
    "        name=\"roberta-base\",\n",
    "        name_short=\"roberta\",\n",
    "        batch_size=32,\n",
    "        gradient_accumulation_steps=1,\n",
    "    ),\n",
    "    Architecture(\n",
    "        name=\"microsoft/deberta-v3-base\",\n",
    "        name_short=\"deberta\",\n",
    "        batch_size=16,\n",
    "        gradient_accumulation_steps=2,\n",
    "    ),\n",
    "    # Architecture(\n",
    "    #     name=\"gpt2\",\n",
    "    #     name_short=\"gpt2\",\n",
    "    #     batch_size=8,\n",
    "    #     gradient_accumulation_steps=4,\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5912cb25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-29T08:02:21.762367Z",
     "iopub.status.busy": "2022-07-29T08:02:21.761940Z",
     "iopub.status.idle": "2022-07-29T17:45:57.324032Z",
     "shell.execute_reply": "2022-07-29T17:45:57.323073Z"
    },
    "papermill": {
     "duration": 35015.575421,
     "end_time": "2022-07-29T17:45:57.327078",
     "exception": false,
     "start_time": "2022-07-29T08:02:21.751657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/src/lass/pipeline.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'correct'] = df['correct'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"In what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: A father brought his son to the local airport for a show. They got up close to an plane in the show. The pilot arrives and turns on the engine. The plane makes a considerable roar, scaring the child. The child cowers behind the father as the father reassures the child that it is just a loud noise and it won't hurt him.\\nThis narrative is a good illustration of the following proverb: \", 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize.<locals>.tokenize_function at 0x7fcae37b0dc0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33d6815dd194c31a946a9aecdabf69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a2676fba58415098a440515548e48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwschella\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path architectures/wandb/wandb/ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path architectures/wandb/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20220729_100255-2mfpvqhb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wschella/lass/runs/2mfpvqhb\" target=\"_blank\">roberta-bs32-0sh-instance-split</a></strong> to <a href=\"https://wandb.ai/wschella/lass\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 43246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Instantaneous batch size per device = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Gradient Accumulation steps = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total optimization steps = 8112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8112' max='8112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8112/8112 3:40:27, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Conf Distribution Accuracy</th>\n",
       "      <th>Conf Distribution Precision</th>\n",
       "      <th>Conf Distribution Recall</th>\n",
       "      <th>Conf Distribution F1</th>\n",
       "      <th>Conf Distribution Roc Auc</th>\n",
       "      <th>Conf Distribution Bs</th>\n",
       "      <th>Conf Distribution Bs Mcb</th>\n",
       "      <th>Conf Distribution Bs Dsc</th>\n",
       "      <th>Conf Distribution Bs Unc</th>\n",
       "      <th>Conf Distribution Balanced Accuracy</th>\n",
       "      <th>Conf Absolute Accuracy</th>\n",
       "      <th>Conf Absolute Precision</th>\n",
       "      <th>Conf Absolute Recall</th>\n",
       "      <th>Conf Absolute F1</th>\n",
       "      <th>Conf Absolute Roc Auc</th>\n",
       "      <th>Conf Absolute Bs</th>\n",
       "      <th>Conf Absolute Bs Mcb</th>\n",
       "      <th>Conf Absolute Bs Dsc</th>\n",
       "      <th>Conf Absolute Bs Unc</th>\n",
       "      <th>Conf Absolute Balanced Accuracy</th>\n",
       "      <th>Conf Normalized Accuracy</th>\n",
       "      <th>Conf Normalized Precision</th>\n",
       "      <th>Conf Normalized Recall</th>\n",
       "      <th>Conf Normalized F1</th>\n",
       "      <th>Conf Normalized Roc Auc</th>\n",
       "      <th>Conf Normalized Bs</th>\n",
       "      <th>Conf Normalized Bs Mcb</th>\n",
       "      <th>Conf Normalized Bs Dsc</th>\n",
       "      <th>Conf Normalized Bs Unc</th>\n",
       "      <th>Conf Normalized Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Bs</th>\n",
       "      <th>Bs Mcb</th>\n",
       "      <th>Bs Dsc</th>\n",
       "      <th>Bs Unc</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.583249</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.681146</td>\n",
       "      <td>0.557402</td>\n",
       "      <td>0.300979</td>\n",
       "      <td>0.390890</td>\n",
       "      <td>0.704983</td>\n",
       "      <td>0.200198</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.026462</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.588952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.579700</td>\n",
       "      <td>0.572676</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.689187</td>\n",
       "      <td>0.593361</td>\n",
       "      <td>0.272159</td>\n",
       "      <td>0.373159</td>\n",
       "      <td>0.716154</td>\n",
       "      <td>0.196355</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.029683</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.588054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.564061</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.546416</td>\n",
       "      <td>0.505710</td>\n",
       "      <td>0.525275</td>\n",
       "      <td>0.730538</td>\n",
       "      <td>0.193271</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.644762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>0.558180</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.704898</td>\n",
       "      <td>0.580753</td>\n",
       "      <td>0.474171</td>\n",
       "      <td>0.522078</td>\n",
       "      <td>0.740984</td>\n",
       "      <td>0.189522</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.648945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>0.540062</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.719778</td>\n",
       "      <td>0.637799</td>\n",
       "      <td>0.406471</td>\n",
       "      <td>0.496513</td>\n",
       "      <td>0.760511</td>\n",
       "      <td>0.182271</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.044473</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.643798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.546879</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.712384</td>\n",
       "      <td>0.579584</td>\n",
       "      <td>0.560359</td>\n",
       "      <td>0.569809</td>\n",
       "      <td>0.755404</td>\n",
       "      <td>0.185680</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.675517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.548722</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.721349</td>\n",
       "      <td>0.600181</td>\n",
       "      <td>0.539967</td>\n",
       "      <td>0.568484</td>\n",
       "      <td>0.768749</td>\n",
       "      <td>0.185340</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>0.047673</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.677363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.535537</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.723937</td>\n",
       "      <td>0.619097</td>\n",
       "      <td>0.488309</td>\n",
       "      <td>0.545980</td>\n",
       "      <td>0.774259</td>\n",
       "      <td>0.179747</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.050550</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.666795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.593124</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.713494</td>\n",
       "      <td>0.592214</td>\n",
       "      <td>0.504622</td>\n",
       "      <td>0.544921</td>\n",
       "      <td>0.759010</td>\n",
       "      <td>0.193686</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.045960</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.662840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.657539</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.712200</td>\n",
       "      <td>0.594949</td>\n",
       "      <td>0.480424</td>\n",
       "      <td>0.531588</td>\n",
       "      <td>0.747307</td>\n",
       "      <td>0.205078</td>\n",
       "      <td>0.023675</td>\n",
       "      <td>0.042973</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.655992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.704381</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.716636</td>\n",
       "      <td>0.603588</td>\n",
       "      <td>0.484774</td>\n",
       "      <td>0.537696</td>\n",
       "      <td>0.743457</td>\n",
       "      <td>0.209363</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.042410</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.660407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.713573</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.698521</td>\n",
       "      <td>0.549312</td>\n",
       "      <td>0.629962</td>\n",
       "      <td>0.586879</td>\n",
       "      <td>0.757266</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.037734</td>\n",
       "      <td>0.044111</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.681895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.316700</td>\n",
       "      <td>0.759473</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.711091</td>\n",
       "      <td>0.580279</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.560708</td>\n",
       "      <td>0.747081</td>\n",
       "      <td>0.218549</td>\n",
       "      <td>0.036087</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.670185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.709242</td>\n",
       "      <td>0.578097</td>\n",
       "      <td>0.535345</td>\n",
       "      <td>0.555901</td>\n",
       "      <td>0.747285</td>\n",
       "      <td>0.221795</td>\n",
       "      <td>0.039299</td>\n",
       "      <td>0.041880</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.667071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>0.879078</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.707671</td>\n",
       "      <td>0.572028</td>\n",
       "      <td>0.556009</td>\n",
       "      <td>0.563905</td>\n",
       "      <td>0.743323</td>\n",
       "      <td>0.230499</td>\n",
       "      <td>0.046117</td>\n",
       "      <td>0.039994</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.670891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.885638</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.703604</td>\n",
       "      <td>0.563426</td>\n",
       "      <td>0.568787</td>\n",
       "      <td>0.566094</td>\n",
       "      <td>0.741002</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>0.047144</td>\n",
       "      <td>0.039342</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.670910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-1500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-2500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-3500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-5500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-6500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-8000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-8000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-7500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from architectures/roberta-bs32-0sh-instance-split-07291003/checkpoint-4000 (score: 0.5355374813079834).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c21a6df2abb4de582bd68daa6273304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/balanced_accuracy</td><td></td></tr><tr><td>eval/bs</td><td></td></tr><tr><td>eval/bs_dsc</td><td></td></tr><tr><td>eval/bs_mcb</td><td></td></tr><tr><td>eval/bs_unc</td><td></td></tr><tr><td>eval/conf_absolute_accuracy</td><td></td></tr><tr><td>eval/conf_absolute_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_absolute_bs</td><td></td></tr><tr><td>eval/conf_absolute_bs_dsc</td><td></td></tr><tr><td>eval/conf_absolute_bs_mcb</td><td></td></tr><tr><td>eval/conf_absolute_bs_unc</td><td></td></tr><tr><td>eval/conf_absolute_f1</td><td></td></tr><tr><td>eval/conf_absolute_precision</td><td></td></tr><tr><td>eval/conf_absolute_recall</td><td></td></tr><tr><td>eval/conf_absolute_roc_auc</td><td></td></tr><tr><td>eval/conf_distribution_accuracy</td><td></td></tr><tr><td>eval/conf_distribution_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_distribution_bs</td><td></td></tr><tr><td>eval/conf_distribution_bs_dsc</td><td></td></tr><tr><td>eval/conf_distribution_bs_mcb</td><td></td></tr><tr><td>eval/conf_distribution_bs_unc</td><td></td></tr><tr><td>eval/conf_distribution_f1</td><td></td></tr><tr><td>eval/conf_distribution_precision</td><td></td></tr><tr><td>eval/conf_distribution_recall</td><td></td></tr><tr><td>eval/conf_distribution_roc_auc</td><td></td></tr><tr><td>eval/conf_normalized_accuracy</td><td></td></tr><tr><td>eval/conf_normalized_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_normalized_bs</td><td></td></tr><tr><td>eval/conf_normalized_bs_dsc</td><td></td></tr><tr><td>eval/conf_normalized_bs_mcb</td><td></td></tr><tr><td>eval/conf_normalized_bs_unc</td><td></td></tr><tr><td>eval/conf_normalized_f1</td><td></td></tr><tr><td>eval/conf_normalized_precision</td><td></td></tr><tr><td>eval/conf_normalized_recall</td><td></td></tr><tr><td>eval/conf_normalized_roc_auc</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/roc_auc</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7036</td></tr><tr><td>eval/balanced_accuracy</td><td>0.67091</td></tr><tr><td>eval/bs</td><td>0.23218</td></tr><tr><td>eval/bs_dsc</td><td>0.03934</td></tr><tr><td>eval/bs_mcb</td><td>0.04714</td></tr><tr><td>eval/bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_absolute_accuracy</td><td>0.65582</td></tr><tr><td>eval/conf_absolute_balanced_accuracy</td><td>0.50337</td></tr><tr><td>eval/conf_absolute_bs</td><td>0.30649</td></tr><tr><td>eval/conf_absolute_bs_dsc</td><td>0.00072</td></tr><tr><td>eval/conf_absolute_bs_mcb</td><td>0.08284</td></tr><tr><td>eval/conf_absolute_bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_absolute_f1</td><td>0.05097</td></tr><tr><td>eval/conf_absolute_precision</td><td>0.4065</td></tr><tr><td>eval/conf_absolute_recall</td><td>0.02719</td></tr><tr><td>eval/conf_absolute_roc_auc</td><td>0.48658</td></tr><tr><td>eval/conf_distribution_accuracy</td><td>0.68928</td></tr><tr><td>eval/conf_distribution_balanced_accuracy</td><td>0.59564</td></tr><tr><td>eval/conf_distribution_bs</td><td>0.19563</td></tr><tr><td>eval/conf_distribution_bs_dsc</td><td>0.02875</td></tr><tr><td>eval/conf_distribution_bs_mcb</td><td>0.0</td></tr><tr><td>eval/conf_distribution_bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_distribution_f1</td><td>0.39878</td></tr><tr><td>eval/conf_distribution_precision</td><td>0.58255</td></tr><tr><td>eval/conf_distribution_recall</td><td>0.30315</td></tr><tr><td>eval/conf_distribution_roc_auc</td><td>0.71635</td></tr><tr><td>eval/conf_normalized_accuracy</td><td>0.51423</td></tr><tr><td>eval/conf_normalized_balanced_accuracy</td><td>0.59511</td></tr><tr><td>eval/conf_normalized_bs</td><td>0.31473</td></tr><tr><td>eval/conf_normalized_bs_dsc</td><td>0.01112</td></tr><tr><td>eval/conf_normalized_bs_mcb</td><td>0.10148</td></tr><tr><td>eval/conf_normalized_bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_normalized_f1</td><td>0.54264</td></tr><tr><td>eval/conf_normalized_precision</td><td>0.39903</td></tr><tr><td>eval/conf_normalized_recall</td><td>0.84774</td></tr><tr><td>eval/conf_normalized_roc_auc</td><td>0.61241</td></tr><tr><td>eval/f1</td><td>0.56609</td></tr><tr><td>eval/loss</td><td>0.88564</td></tr><tr><td>eval/precision</td><td>0.56343</td></tr><tr><td>eval/recall</td><td>0.56879</td></tr><tr><td>eval/roc_auc</td><td>0.741</td></tr><tr><td>eval/runtime</td><td>88.7474</td></tr><tr><td>eval/samples_per_second</td><td>121.919</td></tr><tr><td>eval/steps_per_second</td><td>1.916</td></tr><tr><td>train/epoch</td><td>12.0</td></tr><tr><td>train/global_step</td><td>8112</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.253</td></tr><tr><td>train/total_flos</td><td>1.3654200840118272e+17</td></tr><tr><td>train/train_loss</td><td>0.4424</td></tr><tr><td>train/train_runtime</td><td>13230.5908</td></tr><tr><td>train/train_samples_per_second</td><td>39.224</td></tr><tr><td>train/train_steps_per_second</td><td>0.613</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">roberta-bs32-0sh-instance-split</strong>: <a href=\"https://wandb.ai/wschella/lass/runs/2mfpvqhb\" target=\"_blank\">https://wandb.ai/wschella/lass/runs/2mfpvqhb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/run-20220729_100255-2mfpvqhb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/src/lass/pipeline.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'correct'] = df['correct'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"In what follows, we provide short narratives, each of which illustrates a common proverb. \\nNarrative: A father brought his son to the local airport for a show. They got up close to an plane in the show. The pilot arrives and turns on the engine. The plane makes a considerable roar, scaring the child. The child cowers behind the father as the father reassures the child that it is just a loud noise and it won't hurt him.\\nThis narrative is a good illustration of the following proverb: \", 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding [MASK] to the vocabulary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a897944288d44b7a37edc392035136b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b6020343f5435b8582746ac6621191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path architectures/wandb/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20220729_134418-2887zne3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wschella/lass/runs/2887zne3\" target=\"_blank\">deberta-bs16*2-0sh-instance-split</a></strong> to <a href=\"https://wandb.ai/wschella/lass\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/pytorch_model.bin from cache at /home/wout/.cache/huggingface/transformers/322954555e18d37b9f98196875590497a8b33244551ec195e00fcdb831878224.f80cec19a933132f8b9636fbb3b736b2f4b9c8deaa45dfe4dd6e40a4d9970f44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 43246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Instantaneous batch size per device = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Gradient Accumulation steps = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total optimization steps = 8112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8112' max='8112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8112/8112 6:01:24, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Conf Distribution Accuracy</th>\n",
       "      <th>Conf Distribution Precision</th>\n",
       "      <th>Conf Distribution Recall</th>\n",
       "      <th>Conf Distribution F1</th>\n",
       "      <th>Conf Distribution Roc Auc</th>\n",
       "      <th>Conf Distribution Bs</th>\n",
       "      <th>Conf Distribution Bs Mcb</th>\n",
       "      <th>Conf Distribution Bs Dsc</th>\n",
       "      <th>Conf Distribution Bs Unc</th>\n",
       "      <th>Conf Distribution Balanced Accuracy</th>\n",
       "      <th>Conf Absolute Accuracy</th>\n",
       "      <th>Conf Absolute Precision</th>\n",
       "      <th>Conf Absolute Recall</th>\n",
       "      <th>Conf Absolute F1</th>\n",
       "      <th>Conf Absolute Roc Auc</th>\n",
       "      <th>Conf Absolute Bs</th>\n",
       "      <th>Conf Absolute Bs Mcb</th>\n",
       "      <th>Conf Absolute Bs Dsc</th>\n",
       "      <th>Conf Absolute Bs Unc</th>\n",
       "      <th>Conf Absolute Balanced Accuracy</th>\n",
       "      <th>Conf Normalized Accuracy</th>\n",
       "      <th>Conf Normalized Precision</th>\n",
       "      <th>Conf Normalized Recall</th>\n",
       "      <th>Conf Normalized F1</th>\n",
       "      <th>Conf Normalized Roc Auc</th>\n",
       "      <th>Conf Normalized Bs</th>\n",
       "      <th>Conf Normalized Bs Mcb</th>\n",
       "      <th>Conf Normalized Bs Dsc</th>\n",
       "      <th>Conf Normalized Bs Unc</th>\n",
       "      <th>Conf Normalized Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Bs</th>\n",
       "      <th>Bs Mcb</th>\n",
       "      <th>Bs Dsc</th>\n",
       "      <th>Bs Unc</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.620100</td>\n",
       "      <td>0.581782</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.688447</td>\n",
       "      <td>0.562171</td>\n",
       "      <td>0.377379</td>\n",
       "      <td>0.451602</td>\n",
       "      <td>0.709858</td>\n",
       "      <td>0.199028</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.028042</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.613010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.575500</td>\n",
       "      <td>0.567378</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.691590</td>\n",
       "      <td>0.582968</td>\n",
       "      <td>0.325721</td>\n",
       "      <td>0.417931</td>\n",
       "      <td>0.725471</td>\n",
       "      <td>0.194135</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.602863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.556022</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.694177</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.590810</td>\n",
       "      <td>0.567734</td>\n",
       "      <td>0.747526</td>\n",
       "      <td>0.189998</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.039107</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.669110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.538272</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.716543</td>\n",
       "      <td>0.586421</td>\n",
       "      <td>0.563622</td>\n",
       "      <td>0.574796</td>\n",
       "      <td>0.764394</td>\n",
       "      <td>0.182845</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.046744</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.679458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.528503</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.726525</td>\n",
       "      <td>0.661718</td>\n",
       "      <td>0.399946</td>\n",
       "      <td>0.498560</td>\n",
       "      <td>0.772712</td>\n",
       "      <td>0.177951</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.049185</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.647326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.526664</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.721165</td>\n",
       "      <td>0.595936</td>\n",
       "      <td>0.558184</td>\n",
       "      <td>0.576443</td>\n",
       "      <td>0.774014</td>\n",
       "      <td>0.178843</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.050263</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.681640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.599032</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.707763</td>\n",
       "      <td>0.564922</td>\n",
       "      <td>0.610386</td>\n",
       "      <td>0.586775</td>\n",
       "      <td>0.763033</td>\n",
       "      <td>0.199564</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.047808</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.684149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.417900</td>\n",
       "      <td>0.584644</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.714510</td>\n",
       "      <td>0.579702</td>\n",
       "      <td>0.582382</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.768849</td>\n",
       "      <td>0.192609</td>\n",
       "      <td>0.017441</td>\n",
       "      <td>0.049208</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.682468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>0.656968</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.707856</td>\n",
       "      <td>0.578262</td>\n",
       "      <td>0.519304</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>0.749740</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.026347</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.662130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>0.697693</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.710074</td>\n",
       "      <td>0.581846</td>\n",
       "      <td>0.522838</td>\n",
       "      <td>0.550766</td>\n",
       "      <td>0.750913</td>\n",
       "      <td>0.210653</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>0.044315</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.664668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.825054</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.712662</td>\n",
       "      <td>0.588381</td>\n",
       "      <td>0.514954</td>\n",
       "      <td>0.549224</td>\n",
       "      <td>0.742446</td>\n",
       "      <td>0.222889</td>\n",
       "      <td>0.039652</td>\n",
       "      <td>0.041140</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.664716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.757289</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.705268</td>\n",
       "      <td>0.563391</td>\n",
       "      <td>0.590810</td>\n",
       "      <td>0.576775</td>\n",
       "      <td>0.758541</td>\n",
       "      <td>0.218251</td>\n",
       "      <td>0.038934</td>\n",
       "      <td>0.045059</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.677511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.912199</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.710351</td>\n",
       "      <td>0.575180</td>\n",
       "      <td>0.565797</td>\n",
       "      <td>0.570450</td>\n",
       "      <td>0.746088</td>\n",
       "      <td>0.232355</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.675295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>0.965315</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.708318</td>\n",
       "      <td>0.569489</td>\n",
       "      <td>0.581566</td>\n",
       "      <td>0.575464</td>\n",
       "      <td>0.745774</td>\n",
       "      <td>0.236875</td>\n",
       "      <td>0.053587</td>\n",
       "      <td>0.041088</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.677579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>1.084470</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.698983</td>\n",
       "      <td>0.553823</td>\n",
       "      <td>0.588907</td>\n",
       "      <td>0.570826</td>\n",
       "      <td>0.738322</td>\n",
       "      <td>0.248693</td>\n",
       "      <td>0.062516</td>\n",
       "      <td>0.038199</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.672289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>1.071378</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>0.582550</td>\n",
       "      <td>0.303154</td>\n",
       "      <td>0.398784</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.655823</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>0.486579</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.503373</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.399027</td>\n",
       "      <td>0.847743</td>\n",
       "      <td>0.542638</td>\n",
       "      <td>0.612411</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.101476</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.703327</td>\n",
       "      <td>0.559724</td>\n",
       "      <td>0.596248</td>\n",
       "      <td>0.577409</td>\n",
       "      <td>0.742090</td>\n",
       "      <td>0.244823</td>\n",
       "      <td>0.059709</td>\n",
       "      <td>0.039262</td>\n",
       "      <td>0.224376</td>\n",
       "      <td>0.677359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-1500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-2500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-4500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-5500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-6500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 10820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-8000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-8000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-7500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from architectures/deberta-bs16*2-0sh-instance-split-07291344/checkpoint-3000 (score: 0.5266638398170471).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862138b5b83a4a9688d04883f7a1322f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/balanced_accuracy</td><td></td></tr><tr><td>eval/bs</td><td></td></tr><tr><td>eval/bs_dsc</td><td></td></tr><tr><td>eval/bs_mcb</td><td></td></tr><tr><td>eval/bs_unc</td><td></td></tr><tr><td>eval/conf_absolute_accuracy</td><td></td></tr><tr><td>eval/conf_absolute_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_absolute_bs</td><td></td></tr><tr><td>eval/conf_absolute_bs_dsc</td><td></td></tr><tr><td>eval/conf_absolute_bs_mcb</td><td></td></tr><tr><td>eval/conf_absolute_bs_unc</td><td></td></tr><tr><td>eval/conf_absolute_f1</td><td></td></tr><tr><td>eval/conf_absolute_precision</td><td></td></tr><tr><td>eval/conf_absolute_recall</td><td></td></tr><tr><td>eval/conf_absolute_roc_auc</td><td></td></tr><tr><td>eval/conf_distribution_accuracy</td><td></td></tr><tr><td>eval/conf_distribution_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_distribution_bs</td><td></td></tr><tr><td>eval/conf_distribution_bs_dsc</td><td></td></tr><tr><td>eval/conf_distribution_bs_mcb</td><td></td></tr><tr><td>eval/conf_distribution_bs_unc</td><td></td></tr><tr><td>eval/conf_distribution_f1</td><td></td></tr><tr><td>eval/conf_distribution_precision</td><td></td></tr><tr><td>eval/conf_distribution_recall</td><td></td></tr><tr><td>eval/conf_distribution_roc_auc</td><td></td></tr><tr><td>eval/conf_normalized_accuracy</td><td></td></tr><tr><td>eval/conf_normalized_balanced_accuracy</td><td></td></tr><tr><td>eval/conf_normalized_bs</td><td></td></tr><tr><td>eval/conf_normalized_bs_dsc</td><td></td></tr><tr><td>eval/conf_normalized_bs_mcb</td><td></td></tr><tr><td>eval/conf_normalized_bs_unc</td><td></td></tr><tr><td>eval/conf_normalized_f1</td><td></td></tr><tr><td>eval/conf_normalized_precision</td><td></td></tr><tr><td>eval/conf_normalized_recall</td><td></td></tr><tr><td>eval/conf_normalized_roc_auc</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/roc_auc</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.70333</td></tr><tr><td>eval/balanced_accuracy</td><td>0.67736</td></tr><tr><td>eval/bs</td><td>0.24482</td></tr><tr><td>eval/bs_dsc</td><td>0.03926</td></tr><tr><td>eval/bs_mcb</td><td>0.05971</td></tr><tr><td>eval/bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_absolute_accuracy</td><td>0.65582</td></tr><tr><td>eval/conf_absolute_balanced_accuracy</td><td>0.50337</td></tr><tr><td>eval/conf_absolute_bs</td><td>0.30649</td></tr><tr><td>eval/conf_absolute_bs_dsc</td><td>0.00072</td></tr><tr><td>eval/conf_absolute_bs_mcb</td><td>0.08284</td></tr><tr><td>eval/conf_absolute_bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_absolute_f1</td><td>0.05097</td></tr><tr><td>eval/conf_absolute_precision</td><td>0.4065</td></tr><tr><td>eval/conf_absolute_recall</td><td>0.02719</td></tr><tr><td>eval/conf_absolute_roc_auc</td><td>0.48658</td></tr><tr><td>eval/conf_distribution_accuracy</td><td>0.68928</td></tr><tr><td>eval/conf_distribution_balanced_accuracy</td><td>0.59564</td></tr><tr><td>eval/conf_distribution_bs</td><td>0.19563</td></tr><tr><td>eval/conf_distribution_bs_dsc</td><td>0.02875</td></tr><tr><td>eval/conf_distribution_bs_mcb</td><td>0.0</td></tr><tr><td>eval/conf_distribution_bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_distribution_f1</td><td>0.39878</td></tr><tr><td>eval/conf_distribution_precision</td><td>0.58255</td></tr><tr><td>eval/conf_distribution_recall</td><td>0.30315</td></tr><tr><td>eval/conf_distribution_roc_auc</td><td>0.71635</td></tr><tr><td>eval/conf_normalized_accuracy</td><td>0.51423</td></tr><tr><td>eval/conf_normalized_balanced_accuracy</td><td>0.59511</td></tr><tr><td>eval/conf_normalized_bs</td><td>0.31473</td></tr><tr><td>eval/conf_normalized_bs_dsc</td><td>0.01112</td></tr><tr><td>eval/conf_normalized_bs_mcb</td><td>0.10148</td></tr><tr><td>eval/conf_normalized_bs_unc</td><td>0.22438</td></tr><tr><td>eval/conf_normalized_f1</td><td>0.54264</td></tr><tr><td>eval/conf_normalized_precision</td><td>0.39903</td></tr><tr><td>eval/conf_normalized_recall</td><td>0.84774</td></tr><tr><td>eval/conf_normalized_roc_auc</td><td>0.61241</td></tr><tr><td>eval/f1</td><td>0.57741</td></tr><tr><td>eval/loss</td><td>1.07138</td></tr><tr><td>eval/precision</td><td>0.55972</td></tr><tr><td>eval/recall</td><td>0.59625</td></tr><tr><td>eval/roc_auc</td><td>0.74209</td></tr><tr><td>eval/runtime</td><td>165.8941</td></tr><tr><td>eval/samples_per_second</td><td>65.222</td></tr><tr><td>eval/steps_per_second</td><td>2.043</td></tr><tr><td>train/epoch</td><td>12.0</td></tr><tr><td>train/global_step</td><td>8112</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1854</td></tr><tr><td>train/total_flos</td><td>1.365444571239383e+17</td></tr><tr><td>train/train_loss</td><td>0.38992</td></tr><tr><td>train/train_runtime</td><td>21686.45</td></tr><tr><td>train/train_samples_per_second</td><td>23.93</td></tr><tr><td>train/train_steps_per_second</td><td>0.374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">deberta-bs16*2-0sh-instance-split</strong>: <a href=\"https://wandb.ai/wschella/lass/runs/2887zne3\" target=\"_blank\">https://wandb.ai/wschella/lass/runs/2887zne3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/run-20220729_134418-2887zne3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for architecture in ARCHITECTURES:\n",
    "    lass.train.train(\n",
    "        data_args=LoaderArgs(\n",
    "            logdir=\"../artifacts/logs\",\n",
    "            tasks=\"paper-full\",\n",
    "            model_families=[\"BIG-G T=0\"],\n",
    "            model_sizes=[\"128b\"],\n",
    "            shots=[0],\n",
    "            query_types=[\"multiple_choice\"],\n",
    "        ),\n",
    "        group=\"architecture-selection\",\n",
    "        split=\"instance\",\n",
    "        model_name=architecture.name,\n",
    "        model_name_short=architecture.name_short,\n",
    "        batch_size=architecture.batch_size,\n",
    "        gradient_accumulation_steps=architecture.gradient_accumulation_steps,\n",
    "        include_model_in_input=False,\n",
    "        include_n_targets_in_input=False,\n",
    "        output_dir=\"architectures\",\n",
    "        n_epochs=12,\n",
    "        extra_training_args={\n",
    "            \"warmup_steps\": 3000,\n",
    "            \"learning_rate\": 2e-5,\n",
    "        },\n",
    "        # is_test_run=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fcace5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-29T17:45:57.380520Z",
     "iopub.status.busy": "2022-07-29T17:45:57.379924Z",
     "iopub.status.idle": "2022-07-29T17:45:57.418254Z",
     "shell.execute_reply": "2022-07-29T17:45:57.417063Z"
    },
    "papermill": {
     "duration": 0.059276,
     "end_time": "2022-07-29T17:45:57.419867",
     "exception": false,
     "start_time": "2022-07-29T17:45:57.360591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class Assessor():\n",
    "#   name: str\n",
    "#   path: Path\n",
    "\n",
    "# BASE = Path(\"../artifacts/assessors/\")\n",
    "# transformers.logging.set_verbosity_error() # type: ignore\n",
    "# tokenizers = {\n",
    "#   \"bert\": AutoTokenizer.from_pretrained(\"bert-base-cased\"),\n",
    "#   \"roberta\": AutoTokenizer.from_pretrained(\"roberta-base\"),\n",
    "#   \"albert\": AutoTokenizer.from_pretrained(\"albert-base-v2\"),\n",
    "#   \"gpt2\": AutoTokenizer.from_pretrained(\"gpt2\"),\n",
    "# }\n",
    "# tokenizers[\"gpt2\"].pad_token = tokenizers[\"gpt2\"].eos_token\n",
    "\n",
    "# assessors = [\n",
    "#   Assessor(\"gpt2\", BASE / \"gpt2-bs8-0sh-task-split/checkpoint-5500\"),\n",
    "#   Assessor(\"bert\", BASE / \"bert-bs32-0sh-task-split/checkpoint-1500\"),\n",
    "#   Assessor(\"roberta\", BASE / \"roberta-bs32-0sh-task-split/checkpoint-1500\"),\n",
    "#   Assessor(\"albert\", BASE / \"albert-bs32-0sh-task-split/checkpoint-1500\"),\n",
    "# ]\n",
    "\n",
    "# compute_metrics = lass.metrics.hf.get_metric_computer([\n",
    "#   \"accuracy\",\n",
    "#   \"precision\",\n",
    "#   \"recall\",\n",
    "#   \"f1\",\n",
    "#   \"roc_auc\",\n",
    "#   \"brier_score\",\n",
    "# ])\n",
    "\n",
    "# results = []\n",
    "# for assessor in assessors:\n",
    "#   transformers.logging.set_verbosity_error() # type: ignore\n",
    "#   model = AutoModelForSequenceClassification.from_pretrained(assessor.path)\n",
    "\n",
    "#   # Tokenize according to specific model tokenizer\n",
    "#   tokenizer = tokenizers[assessor.name]\n",
    "#   def tokenize(examples):\n",
    "#     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"np\")\n",
    "#   tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "\n",
    "#   # Dummy Trainer for easy batched predictions\n",
    "#   dummy_trainer = Trainer(model=model, compute_metrics=compute_metrics)\n",
    "\n",
    "#   predictions, labels, metrics = dummy_trainer.predict(tokenized_datasets['test']) #type: ignore\n",
    "#   print(metrics)\n",
    "#   assert metrics is not None\n",
    "\n",
    "#   metrics = {key: metrics[f\"test_{key}\"] for key in [\"accuracy\", \"brier_score\", \"roc_auc\"]}\n",
    "#   results.append({\"model\": assessor.name, **metrics})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35025.083342,
   "end_time": "2022-07-29T17:46:00.531191",
   "environment_variables": {},
   "exception": null,
   "input_path": "Exp_Assessor_Architecture.ipynb",
   "output_path": "Exp_Assessor_Architecture.ipynb",
   "parameters": {},
   "start_time": "2022-07-29T08:02:15.447849",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "eed4bfcf3d3cfcdb00482c10052e8eba5705b015008b357326d56e176b5397df"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "153e89d19dea42b4b191b1cc7891ec27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18a4f6a139ce4f4e8fcb125c9317f4fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d749cc72a6b945d0b70027044f04a197",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aca3dc58de2b4ff3b378a4151072e5b5",
       "value": 1.0
      }
     },
     "2124dc70817543209f1276912697811d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22a2676fba58415098a440515548e48a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_70f743e4505849e784e64e0bc907b256",
        "IPY_MODEL_97f7b0505c6846bb9c54781ccdd6efd5",
        "IPY_MODEL_dabadfac5d0f40539543ffdf9d3d579b"
       ],
       "layout": "IPY_MODEL_bfaa7ba27b07461bb51f7653362ed60d"
      }
     },
     "269eb17545b6404caf48492180beb9e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a897944288d44b7a37edc392035136b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c738f2632d8e474f801d3c4800b0aaf3",
        "IPY_MODEL_f4a2539687de4286bf29697fb88ae6bd",
        "IPY_MODEL_f13f69d85d3246fc8947c26f69490990"
       ],
       "layout": "IPY_MODEL_5df9a19fa8c34031babc372046df62d8"
      }
     },
     "2c21a6df2abb4de582bd68daa6273304": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f56c7812195f445c960bd57a782bddd7",
        "IPY_MODEL_47b4b4a0d8b74b4489ebbeaba01f60f6"
       ],
       "layout": "IPY_MODEL_a13e3757e5bd4b98b6aad73eddaf77c3"
      }
     },
     "30d2d376c88c48239b2dd120015236d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "312cd37654764b41a3c99aa066a23730": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3265e2b9fbea498dbd03769985c194f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4563ec33808e4bbdb62361b3d79cb798": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47b4b4a0d8b74b4489ebbeaba01f60f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4fd2e04b9a4e406a92eb2268d39d090e",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_994871626b784b42ab0d50387a218a79",
       "value": 1.0
      }
     },
     "4dcbccdd763a4afea4797a399bc12bb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e159e2f2a97e48569573c951be9456bc",
       "placeholder": "",
       "style": "IPY_MODEL_88518221e601450794629b0772f752ac",
       "value": ""
      }
     },
     "4e4de41e5aba4a5da56abe9a22f96c8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_63df8a0a7f0b44589c19547f68bdc6b9",
       "max": 44.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9ce0e5caa3f3462587ac9c3977c9b884",
       "value": 44.0
      }
     },
     "4fd2e04b9a4e406a92eb2268d39d090e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "538b98d7de3c483a961258f7d4042013": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "58760ef2523e4dd18ab9ac0207fb29de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5898e2353195491b877b08bcad0381a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5df9a19fa8c34031babc372046df62d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f7a348e36324c4eb4761aafdc389525": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63df8a0a7f0b44589c19547f68bdc6b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "660de42f76b34e3898d0549df0444dda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a812288ba54c4a0b9b72be794407948f",
       "placeholder": "",
       "style": "IPY_MODEL_a2a37d1c41fb4da5965ed6e19e0b71fe",
       "value": ""
      }
     },
     "70ea290438714a548cfc0e92f32f054d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc65678ef2774f308c950851eb88738f",
       "placeholder": "",
       "style": "IPY_MODEL_d3019d2935cd49618afc0d82efbeea8f",
       "value": "0.482 MB of 0.482 MB uploaded (0.000 MB deduped)\r"
      }
     },
     "70f743e4505849e784e64e0bc907b256": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e549363a5f634acbb3adc7967978d609",
       "placeholder": "",
       "style": "IPY_MODEL_93a41e70208f4a3f8bfb5875294a4bd3",
       "value": "100%"
      }
     },
     "7330ef64b8bd4dff911def4d6c12f20f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7acc2bdd58b34a3389419100ed1faf17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "80f624ecbaf64949984de2b44aabe407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7330ef64b8bd4dff911def4d6c12f20f",
       "max": 11.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_538b98d7de3c483a961258f7d4042013",
       "value": 11.0
      }
     },
     "85b33085b10c433f9d7ecbdd700f66f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "862138b5b83a4a9688d04883f7a1322f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_70ea290438714a548cfc0e92f32f054d",
        "IPY_MODEL_18a4f6a139ce4f4e8fcb125c9317f4fa"
       ],
       "layout": "IPY_MODEL_ea3a8160ef5e452ba9b2588b7c66690a"
      }
     },
     "88518221e601450794629b0772f752ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8aff8ee762db40dbb0cbbcf778ca59af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93a41e70208f4a3f8bfb5875294a4bd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94331b07c4404434ae99d871443c8282": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97f7b0505c6846bb9c54781ccdd6efd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_153e89d19dea42b4b191b1cc7891ec27",
       "max": 11.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_312cd37654764b41a3c99aa066a23730",
       "value": 11.0
      }
     },
     "9853424e29d24d7d81fac46360a5d858": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "986a0ce4af4e495f84d6cf11b82fc3f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3265e2b9fbea498dbd03769985c194f2",
       "placeholder": "",
       "style": "IPY_MODEL_bd50d2551a8d47df9366988e5d915fb0",
       "value": "100%"
      }
     },
     "994871626b784b42ab0d50387a218a79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9ce0e5caa3f3462587ac9c3977c9b884": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a13e3757e5bd4b98b6aad73eddaf77c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2a37d1c41fb4da5965ed6e19e0b71fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a2c9e89bb2f240848ac87c7aaa104a30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6edce8663274d7c95e040ab7e2f71bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a812288ba54c4a0b9b72be794407948f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a91bbbd106814d68be2cb427e8c3a00b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a964eaa68db24be4b17f0195a3017693": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aac9f07913924727bccb96d37e453340": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aca2e48a6f654de689b835633721627a",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_de516823f5274ef4a7395f6dfa9b7ef5",
       "value": 0.0
      }
     },
     "aca2e48a6f654de689b835633721627a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aca3dc58de2b4ff3b378a4151072e5b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ad45d25642134006b306351094545050": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_85b33085b10c433f9d7ecbdd700f66f4",
       "placeholder": "",
       "style": "IPY_MODEL_e9b73cd4f9ec4684889406bd2e4f19a9",
       "value": " 44/44 [00:08&lt;00:00,  2.98ba/s]"
      }
     },
     "b35b2e9633604e1785659f25bd678e33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a6edce8663274d7c95e040ab7e2f71bd",
       "placeholder": "",
       "style": "IPY_MODEL_ec0d11c7735a4b7f9fbd139188817267",
       "value": " 11/11 [00:03&lt;00:00,  1.44ba/s]"
      }
     },
     "b8b6020343f5435b8582746ac6621191": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_be63b7e63ef34faf9fedfb3dc9645736",
        "IPY_MODEL_80f624ecbaf64949984de2b44aabe407",
        "IPY_MODEL_b35b2e9633604e1785659f25bd678e33"
       ],
       "layout": "IPY_MODEL_2124dc70817543209f1276912697811d"
      }
     },
     "bd50d2551a8d47df9366988e5d915fb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "be63b7e63ef34faf9fedfb3dc9645736": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d915afe6997a4af68d24f8978dfb95ab",
       "placeholder": "",
       "style": "IPY_MODEL_e417bafc73934c649591db0ccec9e18f",
       "value": "100%"
      }
     },
     "bfaa7ba27b07461bb51f7653362ed60d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c738f2632d8e474f801d3c4800b0aaf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_269eb17545b6404caf48492180beb9e8",
       "placeholder": "",
       "style": "IPY_MODEL_a91bbbd106814d68be2cb427e8c3a00b",
       "value": "100%"
      }
     },
     "cc65678ef2774f308c950851eb88738f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d3019d2935cd49618afc0d82efbeea8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d37b0aa5b0fb4c3cab6ad0c4a35d76d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_660de42f76b34e3898d0549df0444dda",
        "IPY_MODEL_aac9f07913924727bccb96d37e453340"
       ],
       "layout": "IPY_MODEL_94331b07c4404434ae99d871443c8282"
      }
     },
     "d749cc72a6b945d0b70027044f04a197": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d915afe6997a4af68d24f8978dfb95ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9d4895345e34eadb364e83202a3ef6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4dcbccdd763a4afea4797a399bc12bb1",
        "IPY_MODEL_ef9f0dcea01c4e1fa9eeb1af2191b0f1"
       ],
       "layout": "IPY_MODEL_a2c9e89bb2f240848ac87c7aaa104a30"
      }
     },
     "da6d2f93336f45efbaba6aa870f3f043": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dabadfac5d0f40539543ffdf9d3d579b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4563ec33808e4bbdb62361b3d79cb798",
       "placeholder": "",
       "style": "IPY_MODEL_30d2d376c88c48239b2dd120015236d5",
       "value": " 11/11 [00:02&lt;00:00,  4.75ba/s]"
      }
     },
     "de516823f5274ef4a7395f6dfa9b7ef5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dffe62210fe348eaade951c317816dcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e159e2f2a97e48569573c951be9456bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e33d6815dd194c31a946a9aecdabf69a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_986a0ce4af4e495f84d6cf11b82fc3f9",
        "IPY_MODEL_4e4de41e5aba4a5da56abe9a22f96c8a",
        "IPY_MODEL_ad45d25642134006b306351094545050"
       ],
       "layout": "IPY_MODEL_58760ef2523e4dd18ab9ac0207fb29de"
      }
     },
     "e417bafc73934c649591db0ccec9e18f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e549363a5f634acbb3adc7967978d609": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9b73cd4f9ec4684889406bd2e4f19a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ea3a8160ef5e452ba9b2588b7c66690a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec0d11c7735a4b7f9fbd139188817267": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ef9f0dcea01c4e1fa9eeb1af2191b0f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5898e2353195491b877b08bcad0381a8",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7acc2bdd58b34a3389419100ed1faf17",
       "value": 0.0
      }
     },
     "f13f69d85d3246fc8947c26f69490990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5f7a348e36324c4eb4761aafdc389525",
       "placeholder": "",
       "style": "IPY_MODEL_9853424e29d24d7d81fac46360a5d858",
       "value": " 44/44 [00:12&lt;00:00,  1.25s/ba]"
      }
     },
     "f4a2539687de4286bf29697fb88ae6bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8aff8ee762db40dbb0cbbcf778ca59af",
       "max": 44.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da6d2f93336f45efbaba6aa870f3f043",
       "value": 44.0
      }
     },
     "f56c7812195f445c960bd57a782bddd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a964eaa68db24be4b17f0195a3017693",
       "placeholder": "",
       "style": "IPY_MODEL_dffe62210fe348eaade951c317816dcf",
       "value": "0.474 MB of 0.474 MB uploaded (0.000 MB deduped)\r"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}