{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf578dbf-e0bd-4128-9908-e3fab7220b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't find a directory or a metric named 'roc_auc' in this version. It was picked from the master branch on github instead.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint, pformat\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import bigbench.api.results as bb\n",
    "\n",
    "from lass.log_handling import LogLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df86d9b-952c-4932-a3ce-7a4d8b2b4d05",
   "metadata": {},
   "source": [
    "# Creating test set\n",
    "\n",
    "Things to keep in mind:\n",
    "- Instances are used for multiple systems. These multiple results should not be split across train and test.\n",
    "- Instances are used for multiple n-shots. These multiple results should not be split across train and test.\n",
    "- Not all models have results available for all tasks, specifically, BIG-G sparse results are not available for multiple tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a6e175-7f4b-4e49-b97c-12b23c2a8b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55431 samples\n",
      "Sample #0:\n",
      "{'absolute_scores': [-17.807415008544922,\n",
      "                     -18.298959732055664,\n",
      "                     -12.581655502319336,\n",
      "                     -17.21178436279297,\n",
      "                     -31.068716049194336],\n",
      " 'correct': 0.0,\n",
      " 'input': 'In what follows, we provide short narratives, each of which '\n",
      "          'illustrates a common proverb. \\n'\n",
      "          'Narrative: Carla was having trouble juggling college, working at '\n",
      "          'the diner and being a mother. She never had a day off and was burnt '\n",
      "          'out. Her friend told her that her hard work would pay off one day '\n",
      "          \"and to keep going! Carla's friend was right; after a few more years \"\n",
      "          'of hard work, Carla graduated school and was able to get a better '\n",
      "          'job. She was able to take a vacation and become overall '\n",
      "          'successful.\\n'\n",
      "          'This narrative is a good illustration of the following proverb: ',\n",
      " 'metrics': {'calibration_multiple_choice_brier_score': 0.38902647532800894,\n",
      "             'macro_f1': 0.0,\n",
      "             'weighted_log_probabilities': -17.21178436279297},\n",
      " 'normalized_scores': [-5.244009971618652,\n",
      "                       -5.7355546951293945,\n",
      "                       -0.018250465393066406,\n",
      "                       -4.648379325866699,\n",
      "                       -18.50531005859375],\n",
      " 'scores': [-17.807415008544922,\n",
      "            -18.298959732055664,\n",
      "            -12.581655502319336,\n",
      "            -17.21178436279297,\n",
      "            -31.068716049194336],\n",
      " 'target_values': {'April showers bring forth May flowers': 1,\n",
      "                   'Distance lends enchantment to the view': 0,\n",
      "                   \"It's better to light a candle than to curse the darkness\": 0,\n",
      "                   'Seek and you shall find': 0,\n",
      "                   'Strike while the iron is hot': 0},\n",
      " 'targets': ['Seek and you shall find',\n",
      "             \"It's better to light a candle than to curse the darkness\",\n",
      "             'Strike while the iron is hot',\n",
      "             'April showers bring forth May flowers',\n",
      "             'Distance lends enchantment to the view']} \n"
     ]
    }
   ],
   "source": [
    "loader = (LogLoader(logdir = Path('../artifacts/logs'))\n",
    "        .with_tasks('paper-full')\n",
    "        .with_model_families(['BIG-G T=0'])\n",
    "        .with_model_sizes(['128b'])\n",
    "        .with_shots([0])\n",
    "        .with_query_types([bb.MultipleChoiceQuery])\n",
    ")\n",
    "\n",
    "samples = list(loader.load_per_sample())\n",
    "print(f\"{len(samples)} samples\\nSample #0:\\n{pformat(vars(samples[0]))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d418133d-d8df-4959-a197-c591484285c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3968f8b-89b6-4baf-8bc9-14e218345bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>targets</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_values</th>\n",
       "      <th>correct</th>\n",
       "      <th>absolute_scores</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what follows, we provide short narratives, ...</td>\n",
       "      <td>[Seek and you shall find, It's better to light...</td>\n",
       "      <td>[-17.807415008544922, -18.298959732055664, -12...</td>\n",
       "      <td>{'April showers bring forth May flowers': 1, '...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-17.807415008544922, -18.298959732055664, -12...</td>\n",
       "      <td>[-5.244009971618652, -5.7355546951293945, -0.0...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  In what follows, we provide short narratives, ...   \n",
       "\n",
       "                                             targets  \\\n",
       "0  [Seek and you shall find, It's better to light...   \n",
       "\n",
       "                                              scores  \\\n",
       "0  [-17.807415008544922, -18.298959732055664, -12...   \n",
       "\n",
       "                                       target_values  correct  \\\n",
       "0  {'April showers bring forth May flowers': 1, '...      0.0   \n",
       "\n",
       "                                     absolute_scores  \\\n",
       "0  [-17.807415008544922, -18.298959732055664, -12...   \n",
       "\n",
       "                                   normalized_scores  \\\n",
       "0  [-5.244009971618652, -5.7355546951293945, -0.0...   \n",
       "\n",
       "                                             metrics  \n",
       "0  {'calibration_multiple_choice_brier_score': 0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    36548\n",
       "1.0    18510\n",
       "0.8       85\n",
       "0.6       63\n",
       "Name: correct, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Huggingface ready data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what follows, we provide short narratives, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  In what follows, we provide short narratives, ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    36548\n",
       "1    18510\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Original data:\")\n",
    "df = pd.DataFrame(samples)\n",
    "display(df.head(1))\n",
    "display(df['correct'].value_counts().head(4))\n",
    "\n",
    "print(\"\\n\\nHuggingface ready data:\")\n",
    "# df_hf stands for HuggingFace dataset compatible DataFrame\n",
    "df_hf = df[['input', 'correct']].rename(columns={'input':'text','correct':'label'})\n",
    "df_hf = df_hf[df_hf['label'].isin([0.0, 1.0])]\n",
    "df_hf[['label']] = df_hf[['label']].astype(int)\n",
    "display(df_hf.head(1))\n",
    "display(df_hf['label'].value_counts().head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "731c85a5-b41c-405f-bb49-33dcbadf032c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train accuracy: 0.34 (44046 instances)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test accuracy: 0.34 (11012 instances)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'If you follow these instructions, do you return to the starting point?\\nQ: Turn left. Turn left. Take 5 steps. Turn around. Take 5 steps.\\nA: ',\n",
       " 'label': 1,\n",
       " '__index_level_0__': 34229}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "test_fraction = 0.2\n",
    "\n",
    "# Per instance\n",
    "df_hf_train=df_hf.sample(frac=(1-test_fraction),random_state=1234)\n",
    "df_hf_test=df_hf.drop(df_hf_train.index)\n",
    "\n",
    "# Per task (approx)\n",
    "# df_hf_train = df.iloc[:900,:]\n",
    "# df_hf_test = df.iloc[900:,:]\n",
    "\n",
    "display(f\"Train accuracy: {df_hf_train['label'].mean():.2f} ({len(df_hf_train)} instances)\")\n",
    "display(f\"Test accuracy: {df_hf_test['label'].mean():.2f} ({len(df_hf_test)} instances)\")\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(df_hf_train, split='train')\n",
    "ds['test'] = Dataset.from_pandas(df_hf_test, split='test')\n",
    "\n",
    "dataset = ds\n",
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989f9c6d-4eea-4f40-9ff9-99e74a2c5928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1665671/2697771015.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lm_preds[['correct']] = lm_preds[['correct']].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5989991600738016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.49224262504836347"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse LM results\n",
    "import math\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "lm_preds = df[df['correct'].isin([0.0, 1.0])]\n",
    "lm_preds[['correct']] = lm_preds[['correct']].astype(int)\n",
    "lm_preds = lm_preds.drop(df_hf_train.index)\n",
    "\n",
    "# def target_idx(row):\n",
    "#     tvs = row['target_values']\n",
    "#     targets = row['targets']\n",
    "#     try:\n",
    "#         target_idx = [idx for idx, t in enumerate(targets) if tvs[t] == 1][0]\n",
    "#     # Goddamn questions where all answers are wrong...\n",
    "#     except IndexError as e:\n",
    "#         # print(row.name)\n",
    "#         return 0\n",
    "    \n",
    "#     return int(target_idx)\n",
    "def confidence(row):\n",
    "    return np.max(row['normalized_scores'])\n",
    "\n",
    "# lm_preds['target_idx'] = lm_preds.apply(target_idx, axis=1)\n",
    "# lm_preds['target_score_normalized'] = lm_preds.apply(lambda row: row['normalized_scores'][row['target_idx']], axis=1)\n",
    "# lm_preds['target_score_normalized'].head()\n",
    "\n",
    "# Assumes the actual output is arg_max\n",
    "lm_preds['confidence_normalized'] = lm_preds.apply(lambda row: math.exp(np.max(row['normalized_scores'])), axis=1)\n",
    "lm_preds['confidence_absolute'] = lm_preds.apply(lambda row: math.exp(np.max(row['absolute_scores'])), axis=1)\n",
    "\n",
    "display(sk.metrics.roc_auc_score(lm_preds['correct'], lm_preds['confidence_normalized']))\n",
    "sk.metrics.roc_auc_score(lm_preds['correct'], lm_preds['confidence_absolute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73464b95-16d6-4640-ad8c-5d5994db49a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db2b6fdac23436bb59de586d563ae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef36a35a2034fd487b9ff815ab6d439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5705b86c-7b5f-4c0d-b707-c29e8bcacea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44046, 11012)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42) #.select(range(50))\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42) #.select(range(50))\n",
    "len(train_dataset), len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5bb053d-5306-4480-93c1-11bfd7b16a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=lass\n",
      "env: WANDB_LOG_MODEL=true\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwschella\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "%env WANDB_PROJECT=lass\n",
    "%env WANDB_LOG_MODEL=true\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c365929-0149-4813-9042-f75ea8c2ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import lass\n",
    "import lass.metrics.hf\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=2)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"./test_trainer/checkpoint-13500\", num_labels=2)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"../artifacts/assessors/bert-bs32/checkpoint-3000\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"albert-bs32-0sh\",\n",
    "    run_name=\"albert-bs32-0sh\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    report_to=\"wandb\",\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "compute_metrics = lass.metrics.hf.get_metric_computer([\n",
    "  \"accuracy\",\n",
    "  \"precision\",\n",
    "  \"recall\",\n",
    "  \"f1\",\n",
    "  \"roc_auc\",\n",
    "  \"brier_score\",\n",
    "])\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44ba8a37-0113-4e30-b7e2-a599d9f15940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `AlbertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `AlbertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/wout/pp/lass/.env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 44046\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4131\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.19 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wout/pp/lass/notebooks/wandb/run-20220628_163443-1ib0dzlh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wschella/lass/runs/1ib0dzlh\" target=\"_blank\">albert-bs32-0sh</a></strong> to <a href=\"https://wandb.ai/wschella/lass\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 23.70 GiB total capacity; 19.66 GiB already allocated; 40.69 MiB free; 19.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/wout/pp/lass/notebooks/EXP1_BERT_inst_split_single_syst.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/EXP1_BERT_inst_split_single_syst.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/EXP1_BERT_inst_split_single_syst.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/trainer.py:1422\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1421\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1422\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1424\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1425\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1426\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1427\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1428\u001b[0m ):\n\u001b[1;32m   1429\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/trainer.py:2011\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2008\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2010\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocast_smart_context_manager():\n\u001b[0;32m-> 2011\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2013\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2014\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/trainer.py:2043\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2042\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2043\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2044\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2045\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py:1028\u001b[0m, in \u001b[0;36mAlbertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1028\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malbert(\n\u001b[1;32m   1029\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1030\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1031\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1032\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1033\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1034\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1035\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1036\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1037\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1038\u001b[0m )\n\u001b[1;32m   1040\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1042\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py:720\u001b[0m, in \u001b[0;36mAlbertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    715\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    717\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    718\u001b[0m     input_ids, position_ids\u001b[39m=\u001b[39mposition_ids, token_type_ids\u001b[39m=\u001b[39mtoken_type_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds\n\u001b[1;32m    719\u001b[0m )\n\u001b[0;32m--> 720\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    721\u001b[0m     embedding_output,\n\u001b[1;32m    722\u001b[0m     extended_attention_mask,\n\u001b[1;32m    723\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    724\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    725\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    726\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    727\u001b[0m )\n\u001b[1;32m    729\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    731\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler_activation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output[:, \u001b[39m0\u001b[39m])) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py:467\u001b[0m, in \u001b[0;36mAlbertTransformer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39m# Index of the hidden group\u001b[39;00m\n\u001b[1;32m    465\u001b[0m group_idx \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(i \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_groups))\n\u001b[0;32m--> 467\u001b[0m layer_group_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malbert_layer_groups[group_idx](\n\u001b[1;32m    468\u001b[0m     hidden_states,\n\u001b[1;32m    469\u001b[0m     attention_mask,\n\u001b[1;32m    470\u001b[0m     head_mask[group_idx \u001b[39m*\u001b[39;49m layers_per_group : (group_idx \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39;49m layers_per_group],\n\u001b[1;32m    471\u001b[0m     output_attentions,\n\u001b[1;32m    472\u001b[0m     output_hidden_states,\n\u001b[1;32m    473\u001b[0m )\n\u001b[1;32m    474\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_group_output[\u001b[39m0\u001b[39m]\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py:419\u001b[0m, in \u001b[0;36mAlbertLayerGroup.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    416\u001b[0m layer_attentions \u001b[39m=\u001b[39m ()\n\u001b[1;32m    418\u001b[0m \u001b[39mfor\u001b[39;00m layer_index, albert_layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malbert_layers):\n\u001b[0;32m--> 419\u001b[0m     layer_output \u001b[39m=\u001b[39m albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\n\u001b[1;32m    420\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_output[\u001b[39m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py:387\u001b[0m, in \u001b[0;36mAlbertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    385\u001b[0m     \u001b[39mself\u001b[39m, hidden_states, attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, head_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, output_hidden_states\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    386\u001b[0m ):\n\u001b[0;32m--> 387\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(hidden_states, attention_mask, head_mask, output_attentions)\n\u001b[1;32m    389\u001b[0m     ffn_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    390\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mff_chunk,\n\u001b[1;32m    391\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_size_feed_forward,\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq_len_dim,\n\u001b[1;32m    393\u001b[0m         attention_output[\u001b[39m0\u001b[39m],\n\u001b[1;32m    394\u001b[0m     )\n\u001b[1;32m    395\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_layer_layer_norm(ffn_output \u001b[39m+\u001b[39m attention_output[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.8/site-packages/transformers/models/albert/modeling_albert.py:361\u001b[0m, in \u001b[0;36mAlbertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     attention_probs \u001b[39m=\u001b[39m attention_probs \u001b[39m*\u001b[39m head_mask\n\u001b[0;32m--> 361\u001b[0m context_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attention_probs, value_layer)\n\u001b[1;32m    362\u001b[0m context_layer \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mflatten(\u001b[39m2\u001b[39m)\n\u001b[1;32m    364\u001b[0m projected_context_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(context_layer)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 23.70 GiB total capacity; 19.66 GiB already allocated; 40.69 MiB free; 19.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d51ce-e5c8-4c44-958e-c12d1e4818c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce8153-b7de-46ff-9457-fcf1f1e58090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eed4bfcf3d3cfcdb00482c10052e8eba5705b015008b357326d56e176b5397df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
