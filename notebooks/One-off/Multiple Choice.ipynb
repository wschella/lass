{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset swag (/home/wout/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edd49f883164a5bb25d69ead3326e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'video-id': 'anetv_jkn6uvmqwh4',\n",
       " 'fold-ind': '3416',\n",
       " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
       " 'sent2': 'A drum line',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'passes by walking down the street playing their instruments.',\n",
       " 'ending1': 'has heard approaching them.',\n",
       " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
       " 'ending3': 'turns the lead singer watches the performance.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.load import load_dataset\n",
    "\n",
    "swag = load_dataset(\"swag\", \"regular\")\n",
    "swag[\"train\"][0] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377eea4f62164d3291ef4423b68bafa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc93ae4126a4b75b4be7808af2b8359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fed79ec08094facaf05a0cdfb60dd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194fa8e7abb04cbbb47cc2cc0483fcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n",
    "    question_headers = examples[\"sent2\"]\n",
    "    second_sentences = [\n",
    "        [f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)\n",
    "    ]\n",
    "    print(len(first_sentences), len(second_sentences), first_sentences[0], second_sentences[0])\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    print(len(first_sentences), len(second_sentences), first_sentences[0], second_sentences[0])\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061ab6b61895478db131927365fd61b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 ['Members of the procession walk down the street holding small horn brass instruments.', 'Members of the procession walk down the street holding small horn brass instruments.', 'Members of the procession walk down the street holding small horn brass instruments.', 'Members of the procession walk down the street holding small horn brass instruments.'] ['A drum line passes by walking down the street playing their instruments.', 'A drum line has heard approaching them.', \"A drum line arrives and they're outside dancing and asleep.\", 'A drum line turns the lead singer watches the performance.']\n",
      "4000 4000 Members of the procession walk down the street holding small horn brass instruments. A drum line passes by walking down the street playing their instruments.\n",
      "1000 1000 ['A man shows off a snowboard, explaining how it works.', 'A man shows off a snowboard, explaining how it works.', 'A man shows off a snowboard, explaining how it works.', 'A man shows off a snowboard, explaining how it works.'] ['He puts pasta into a can and carves it.', 'He sands the board, alternating views of people skiing.', 'He wakes and talks to the camera as he talks into the camera.', 'He washes gel and shows a bright blue cloth.']\n",
      "4000 4000 A man shows off a snowboard, explaining how it works. He puts pasta into a can and carves it.\n",
      "1000 1000 [\"She approaches a children's choir singing in the open to an audience of adults who clap along.\", \"She approaches a children's choir singing in the open to an audience of adults who clap along.\", \"She approaches a children's choir singing in the open to an audience of adults who clap along.\", \"She approaches a children's choir singing in the open to an audience of adults who clap along.\"] ['Someone is playing the piano.', 'Someone stands wearing a long thin dark classroom auditorium.', \"Someone gazes up at the blonde's desperate face, then turns them off.\", 'Someone song plays at the forefront, then flies back into the audience.']\n",
      "4000 4000 She approaches a children's choir singing in the open to an audience of adults who clap along. Someone is playing the piano.\n",
      "1000 1000 ['A man stands in a bull ring.', 'A man stands in a bull ring.', 'A man stands in a bull ring.', 'A man stands in a bull ring.'] ['a bull runs towards the man.', 'a bull is being photographed by a bull.', 'a bull is marching over him.', 'a bull runs down the bull.']\n",
      "4000 4000 A man stands in a bull ring. a bull runs towards the man.\n",
      "1000 1000 [\"As someone opens the office door to exit, he shouts at someone's secretary in the outer office.\", \"As someone opens the office door to exit, he shouts at someone's secretary in the outer office.\", \"As someone opens the office door to exit, he shouts at someone's secretary in the outer office.\", \"As someone opens the office door to exit, he shouts at someone's secretary in the outer office.\"] ['Someone enters the hotel room.', 'Someone soaks at the desk in the cramped metal chamber, looking restless.', 'Someone paces and moans on her back, as if struggling to remain upright.', 'Someone stands behind her, looking out into the darkness.']\n",
      "4000 4000 As someone opens the office door to exit, he shouts at someone's secretary in the outer office. Someone enters the hotel room.\n",
      "1000 1000 ['A woman in a red shirt is standing in front of a tv talking.', 'A woman in a red shirt is standing in front of a tv talking.', 'A woman in a red shirt is standing in front of a tv talking.', 'A woman in a red shirt is standing in front of a tv talking.'] ['A woman is playing a violin.', 'A woman is talking up the stairs.', 'A woman is talking in front of a camera.', 'A woman is standing in front of a christmas table.']\n",
      "4000 4000 A woman in a red shirt is standing in front of a tv talking. A woman is playing a violin.\n",
      "1000 1000 ['The man then begins playing the instrument in front of the camera.', 'The man then begins playing the instrument in front of the camera.', 'The man then begins playing the instrument in front of the camera.', 'The man then begins playing the instrument in front of the camera.'] ['The man watches them riding around slowly.', 'The man continues to play while taking breaks here and there and showing text in the end.', 'The man gets off playing the drums while the camera zooms in on the piano.', 'The man pushes the object sideways while continuing to speak to the camera.']\n",
      "4000 4000 The man then begins playing the instrument in front of the camera. The man watches them riding around slowly.\n",
      "1000 1000 ['He drives away in his cream Mercedes.', 'He drives away in his cream Mercedes.', 'He drives away in his cream Mercedes.', 'He drives away in his cream Mercedes.'] ['Sitting with a cigarette burning in an ashtray beside him, someone sits tensely in the handwash access event.', 'Sitting with a cigarette burning in an ashtray beside him, someone slots a sim card into a mobile phone and replaces the battery.', 'Sitting with a cigarette burning in an ashtray beside him, someone smirks at - chested as she comes down to talk.', 'Sitting with a cigarette burning in an ashtray beside him, someone swigs his ipod from his hatch and climbs underneath it.']\n",
      "4000 4000 He drives away in his cream Mercedes. Sitting with a cigarette burning in an ashtray beside him, someone sits tensely in the handwash access event.\n",
      "1000 1000 ['A large group of people are seen standing in a ring speaking to one another.', 'A large group of people are seen standing in a ring speaking to one another.', 'A large group of people are seen standing in a ring speaking to one another.', 'A large group of people are seen standing in a ring speaking to one another.'] ['Two men then begin fighting one another while people watch on the sides.', 'Two men then begin spreading rope on the other while people watch on the sides.', 'Two men then shoot around one another and end by holding a bow and hitting the puck.', 'Two men then begin playing a game of tug of war while dancing with one another.']\n",
      "4000 4000 A large group of people are seen standing in a ring speaking to one another. Two men then begin fighting one another while people watch on the sides.\n",
      "1000 1000 ['Someone holds her gaze as she touches his stubbly cheek.', 'Someone holds her gaze as she touches his stubbly cheek.', 'Someone holds her gaze as she touches his stubbly cheek.', 'Someone holds her gaze as she touches his stubbly cheek.'] ['Someone runs out of the studio.', 'Someone does not move slightly.', 'Someone lifts his chin and tilts his head slightly and kisses her.', 'Someone gazes into her eyes.']\n",
      "4000 4000 Someone holds her gaze as she touches his stubbly cheek. Someone runs out of the studio.\n",
      "1000 1000 ['A man stands with a cup in hand next to a horse.', 'A man stands with a cup in hand next to a horse.', 'A man stands with a cup in hand next to a horse.', 'A man stands with a cup in hand next to a horse.'] ['The horse runs towards the gate.', 'The horse takes a swig of the cup and drains it.', 'The horse holds on to the man talking to the camera.', 'The horse walks along with the person.']\n",
      "4000 4000 A man stands with a cup in hand next to a horse. The horse runs towards the gate.\n",
      "1000 1000 ['The teen attempts to have a scared boy take a turn but the boy refuses.', 'The teen attempts to have a scared boy take a turn but the boy refuses.', 'The teen attempts to have a scared boy take a turn but the boy refuses.', 'The teen attempts to have a scared boy take a turn but the boy refuses.'] ['The children all push the wheelchair around by the window while the adults continues to play.', 'The children all fall over on the grass.', 'The children all wriggle around as she charges to the boy in the head below.', 'The children all swing on the bars.']\n",
      "4000 4000 The teen attempts to have a scared boy take a turn but the boy refuses. The children all push the wheelchair around by the window while the adults continues to play.\n",
      "1000 1000 ['An antique engagement ring sits on a velvet stand.', 'An antique engagement ring sits on a velvet stand.', 'An antique engagement ring sits on a velvet stand.', 'An antique engagement ring sits on a velvet stand.'] ['The young woman scans the play pages then finds a spiral bound notebook objects with a diamond map on fire.', 'The young woman looks at her beau.', 'The young woman tosses the stack of packets.', 'The young woman reads, blog list.']\n",
      "4000 4000 An antique engagement ring sits on a velvet stand. The young woman scans the play pages then finds a spiral bound notebook objects with a diamond map on fire.\n",
      "1000 1000 ['The man then takes off running.', 'The man then takes off running.', 'The man then takes off running.', 'The man then takes off running.'] ['the man jumps over a beam and lands on pads.', 'the man hits the bar several times and walks away.', 'the man is jumping on post from the jump rope to park the tightrope - style strip polo.', 'the man demonstrates tai chi to the camera while red hands storage the other side of him.']\n",
      "4000 4000 The man then takes off running. the man jumps over a beam and lands on pads.\n",
      "1000 1000 ['A woman stand and a lady walk on front a bench.', 'A woman stand and a lady walk on front a bench.', 'A woman stand and a lady walk on front a bench.', 'A woman stand and a lady walk on front a bench.'] ['The referee uses a microphone to show how the congregation stand in their path.', 'The referee sets the fans down and makes a high jump.', 'The referee bows as he approaches a high pink background.', 'The referee speaks and we see the lady speaking to a older lady.']\n",
      "4000 4000 A woman stand and a lady walk on front a bench. The referee uses a microphone to show how the congregation stand in their path.\n",
      "1000 1000 ['Both men demonstrate passing the lacrosse ball against the wall.', 'Both men demonstrate passing the lacrosse ball against the wall.', 'Both men demonstrate passing the lacrosse ball against the wall.', 'Both men demonstrate passing the lacrosse ball against the wall.'] ['The man in orange walks toward him and pulls another hit.', 'The man in orange takes a hit and tosses it in the air.', 'The man in orange talks to the camera a third time while demonstrating with his lacrosse stick.', 'The man in orange performs different jumps in the minivan and pins in the curling line.']\n",
      "4000 4000 Both men demonstrate passing the lacrosse ball against the wall. The man in orange walks toward him and pulls another hit.\n",
      "1000 1000 ['The young boy then reaches for his shin guard and puts it over his right leg and then folds his sock down over it.', 'The young boy then reaches for his shin guard and puts it over his right leg and then folds his sock down over it.', 'The young boy then reaches for his shin guard and puts it over his right leg and then folds his sock down over it.', 'The young boy then reaches for his shin guard and puts it over his right leg and then folds his sock down over it.'] ['Once that is finished, he picks up another copy of one mallet and makes a good layup shot and falls hard.', 'Once that is finished, he reaches over for his other sock and begins to do the same thing on the left leg.', 'Once that is finished, he throws the tile shoe and smears it on the ground with a towel.', 'Once that is finished, he turns back to the tractor and sits in front of the men standing.']\n",
      "4000 4000 The young boy then reaches for his shin guard and puts it over his right leg and then folds his sock down over it. Once that is finished, he picks up another copy of one mallet and makes a good layup shot and falls hard.\n",
      "1000 1000 ['Someone and grocer come up to counter.', 'Someone and grocer come up to counter.', 'Someone and grocer come up to counter.', 'Someone and grocer come up to counter.'] ['She stands with her market - basket, reacting to wolf whistles o. s.; she is carried by a glass tank.', 'She stands with her market - basket, reacting to wolf whistles o. s.; she is representing a rusty kitchen.', 'She stands with her market - basket, reacting to wolf whistles o. s.; she is expecting the news.', 'She stands with her market - basket, reacting to wolf whistles o. s.; she is seeking the world.']\n",
      "4000 4000 Someone and grocer come up to counter. She stands with her market - basket, reacting to wolf whistles o. s.; she is carried by a glass tank.\n",
      "1000 1000 ['A man and a little boy play badminton in an indoor court.', 'A man and a little boy play badminton in an indoor court.', 'A man and a little boy play badminton in an indoor court.', 'A man and a little boy play badminton in an indoor court.'] ['The little boy dives behind a table.', 'The little boy dives into the wall next to him.', 'The little boy walks around the bases on the market.', 'The little boy serves and returns the ball well.']\n",
      "4000 4000 A man and a little boy play badminton in an indoor court. The little boy dives behind a table.\n",
      "1000 1000 ['The girl goes up the stairs.', 'The girl goes up the stairs.', 'The girl goes up the stairs.', 'The girl goes up the stairs.'] ['The girl leaps from the board and falls onto the machine.', 'The girl walks towards the stairs and smiles at the camera.', \"The girl brushes the girl's hair without feeling for a hair style.\", 'The girl is sin and stepping side to side, making a design.']\n",
      "4000 4000 The girl goes up the stairs. The girl leaps from the board and falls onto the machine.\n",
      "1000 1000 ['An old man plays the ukulele and a boy plays the tam - tams in the street.', 'An old man plays the ukulele and a boy plays the tam - tams in the street.', 'An old man plays the ukulele and a boy plays the tam - tams in the street.', 'An old man plays the ukulele and a boy plays the tam - tams in the street.'] ['A person pushes a white awning on an elliptical machine.', 'A person pass on front the players.', 'A person leaves his room and stops working.', 'A person writes on another paper.']\n",
      "4000 4000 An old man plays the ukulele and a boy plays the tam - tams in the street. A person pushes a white awning on an elliptical machine.\n",
      "1000 1000 ['Later, someone enters his house.', 'Later, someone enters his house.', 'Later, someone enters his house.', 'Later, someone enters his house.'] ['He strides off onto a sidewalk steps to the house.', 'He finds some notes which are reflected in the black wall - high wall.', 'He shrugs, and brings his cane to her up, then slams the door.', 'He drops a book on the floor then shuts the door behind him.']\n",
      "4000 4000 Later, someone enters his house. He strides off onto a sidewalk steps to the house.\n",
      "1000 1000 ['A man is located inside a gym.', 'A man is located inside a gym.', 'A man is located inside a gym.', 'A man is located inside a gym.'] ['He is playing the accordian.', 'He removes behind the ropes!', \"He holds a rubik's cube in his hands.\", 'He is talking while several people are using rowing machines.']\n",
      "4000 4000 A man is located inside a gym. He is playing the accordian.\n",
      "1000 1000 ['He caresses her cheek, then leans in and kisses her.', 'He caresses her cheek, then leans in and kisses her.', 'He caresses her cheek, then leans in and kisses her.', 'He caresses her cheek, then leans in and kisses her.'] ['Pulling away, he allows a faint smile from the window.', 'Pulling away, he smirks as he faces his car and runs out.', 'Pulling away, he looks up, smiles.', \"Pulling away, he throws her head to someone's still body.\"]\n",
      "4000 4000 He caresses her cheek, then leans in and kisses her. Pulling away, he allows a faint smile from the window.\n",
      "1000 1000 ['Someone eats popcorn from a bowl on his belly.', 'Someone eats popcorn from a bowl on his belly.', 'Someone eats popcorn from a bowl on his belly.', 'Someone eats popcorn from a bowl on his belly.'] [\"Now, someone's parents have a great homeless tourists.\", \"Now, someone's parents sit on the couch wearing the blindfold.\", \"Now, someone's parents show their daughter a card.\", \"Now, someone's parents arrive at someone's mansion.\"]\n",
      "4000 4000 Someone eats popcorn from a bowl on his belly. Now, someone's parents have a great homeless tourists.\n",
      "1000 1000 ['A horse runs after and bucks a bull that charges it with its horns.', 'A horse runs after and bucks a bull that charges it with its horns.', 'A horse runs after and bucks a bull that charges it with its horns.', 'A horse runs after and bucks a bull that charges it with its horns.'] ['The horse celebrates with several spectators showing different techniques.', 'The horse nailed down on the horse and runs to grab it and hold it before of the cow.', 'The horse is let out of the coral by the cowboys.', 'The horse is unnaturally fast and sharp.']\n",
      "4000 4000 A horse runs after and bucks a bull that charges it with its horns. The horse celebrates with several spectators showing different techniques.\n",
      "1000 1000 ['He hands him a condom.', 'He hands him a condom.', 'He hands him a condom.', 'He hands him a condom.'] ['Someone takes it out of the packet.', 'Someone leaves him, then closes his eyes on someone.', 'Someone lifts his fist directly up his front lip.', 'Someone sits on a table fire by a campfire.']\n",
      "4000 4000 He hands him a condom. Someone takes it out of the packet.\n",
      "1000 1000 ['He is given a cup filled with water by a little girl, and he rinses with it.', 'He is given a cup filled with water by a little girl, and he rinses with it.', 'He is given a cup filled with water by a little girl, and he rinses with it.', 'He is given a cup filled with water by a little girl, and he rinses with it.'] ['He takes the bottle and starts talking to someone.', 'He swims quickly to a small clearing.', 'He takes the drink up and spits it out.', 'He puts the seeds back in his mouth.']\n",
      "4000 4000 He is given a cup filled with water by a little girl, and he rinses with it. He takes the bottle and starts talking to someone.\n",
      "1000 1000 ['The man wipes wax on wood.', 'The man wipes wax on wood.', 'The man wipes wax on wood.', 'The man wipes wax on wood.'] ['The man rubs his hand over a door and we see the place of shining drops.', 'The man rubs his hand over a door and we see the closing screen in a sink.', 'The man rubs his hand over a door and we see a chest of drawers.', 'The man rubs his hand over a door and we see the sandwich being cleaned.']\n",
      "4000 4000 The man wipes wax on wood. The man rubs his hand over a door and we see the place of shining drops.\n",
      "1000 1000 ['A man drives his car to the beach.', 'A man drives his car to the beach.', 'A man drives his car to the beach.', 'A man drives his car to the beach.'] ['He holds a cloth that holds the foreground picture.', 'He gears up for the surf.', 'He agility down a hill and over together for soldiers.', 'He adjusts the small fence on the car.']\n",
      "4000 4000 A man drives his car to the beach. He holds a cloth that holds the foreground picture.\n",
      "1000 1000 ['The horses tail is braided back and she is wearing pink.', 'The horses tail is braided back and she is wearing pink.', 'The horses tail is braided back and she is wearing pink.', 'The horses tail is braided back and she is wearing pink.'] ['The lady mows down excitedly steps over the country.', 'The lady rides the horse and talks to the camera.', 'The lady rinses her right hand and dips the brush on the horse.', 'The lady spins around and touches more and brushes.']\n",
      "4000 4000 The horses tail is braided back and she is wearing pink. The lady mows down excitedly steps over the country.\n",
      "1000 1000 ['Now a heavyset female guard brings a mug with a spoon in it to a cell where someone snores on a cot.', 'Now a heavyset female guard brings a mug with a spoon in it to a cell where someone snores on a cot.', 'Now a heavyset female guard brings a mug with a spoon in it to a cell where someone snores on a cot.', 'Now a heavyset female guard brings a mug with a spoon in it to a cell where someone snores on a cot.'] ['The guard knits a brow as he lands a series of steps by the window of the car.', 'The guard walks a way back in, throws a guard past someone.', 'The guard places his device in the high dresser.', 'The guard smiles as his wife eyes him then sets his bottle down.']\n",
      "4000 4000 Now a heavyset female guard brings a mug with a spoon in it to a cell where someone snores on a cot. The guard knits a brow as he lands a series of steps by the window of the car.\n",
      "1000 1000 ['Someone peers out the passenger window.', 'Someone peers out the passenger window.', 'Someone peers out the passenger window.', 'Someone peers out the passenger window.'] ['Someone turns to the radio.', 'Someone looks at him and grimaces.', 'Someone looks out in alarm as he goes down the stairs.', 'Someone turns out the lights.']\n",
      "4000 4000 Someone peers out the passenger window. Someone turns to the radio.\n",
      "1000 1000 ['Someone is a step behind.', 'Someone is a step behind.', 'Someone is a step behind.', 'Someone is a step behind.'] ['They climb the porch and notice that the front door is ajar.', 'They are inside the bar.', 'They punch and clap their hands.', 'They can be marshy and sustained.']\n",
      "4000 4000 Someone is a step behind. They climb the porch and notice that the front door is ajar.\n",
      "1000 1000 ['The men yell out of horns.', 'The men yell out of horns.', 'The men yell out of horns.', 'The men yell out of horns.'] ['Two women flip out of a stance, and they take the people off.', 'Two women flip out of a stance, and they engage in a cardio doing it.', 'Two women flip out of a stance, and they do screams and falls.', 'Two women flip out of a stance, and they end in the air.']\n",
      "4000 4000 The men yell out of horns. Two women flip out of a stance, and they take the people off.\n",
      "1000 1000 ['As she pulls away, he holds on to her hand.', 'As she pulls away, he holds on to her hand.', 'As she pulls away, he holds on to her hand.', 'As she pulls away, he holds on to her hand.'] ['She sleeps soundly on his stomach.', 'She pulls it away, and opens the door.', 'She drops an elbow holding her own body and forces her toward him.', 'She eases her back toward the open door and lingers close.']\n",
      "4000 4000 As she pulls away, he holds on to her hand. She sleeps soundly on his stomach.\n",
      "1000 1000 ['She rubs it on the mans face.', 'She rubs it on the mans face.', 'She rubs it on the mans face.', 'She rubs it on the mans face.'] ['She has a knife and rubs it down his chest.', 'She cocks the lamp, and stares at it, then blows it.', 'She claps his hands again.', 'She stares at the ceiling with a furrowed brow.']\n",
      "4000 4000 She rubs it on the mans face. She has a knife and rubs it down his chest.\n",
      "1000 1000 ['He lassos a little calf.', 'He lassos a little calf.', 'He lassos a little calf.', 'He lassos a little calf.'] ['He grabs two ropes and attaches it to his horse.', 'He gets off the horse and walks on it.', 'He ropes the calf with his arms and ties it on his arms.', 'He jumps off the horse and ties up the calf.']\n",
      "4000 4000 He lassos a little calf. He grabs two ropes and attaches it to his horse.\n",
      "1000 1000 [\"Someone gently takes her father's face in her hands and turns him toward her.\", \"Someone gently takes her father's face in her hands and turns him toward her.\", \"Someone gently takes her father's face in her hands and turns him toward her.\", \"Someone gently takes her father's face in her hands and turns him toward her.\"] ['A hooded figure sits in a nearby wall, her eyes fixed in her eyes.', 'A hooded figure arrives at the entrance behind her building.', 'A hooded figure sneaks out of the shadows, then lays down in blood.', \"A hooded figure lies behind a desk someone holds the boy's gaze.\"]\n",
      "4000 4000 Someone gently takes her father's face in her hands and turns him toward her. A hooded figure sits in a nearby wall, her eyes fixed in her eyes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/wout/pp/lass/notebooks/Scratchpad copy.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tokenized_swag \u001b[39m=\u001b[39m swag\u001b[39m.\u001b[39;49mmap(preprocess_function, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/dataset_dict.py:770\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 770\u001b[0m     {\n\u001b[1;32m    771\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m    772\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[1;32m    773\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[1;32m    774\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[1;32m    775\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[1;32m    776\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[1;32m    777\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    778\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    779\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[1;32m    780\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    781\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    782\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    783\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    784\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m    785\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[1;32m    786\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[1;32m    787\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[1;32m    788\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[1;32m    789\u001b[0m         )\n\u001b[1;32m    790\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    791\u001b[0m     }\n\u001b[1;32m    792\u001b[0m )\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/dataset_dict.py:771\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    770\u001b[0m     {\n\u001b[0;32m--> 771\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    772\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m    773\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m    774\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m    775\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m    776\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m    777\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    778\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m    779\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m    780\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m    781\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m    782\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[1;32m    783\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m    784\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m    785\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m    786\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m    787\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m    788\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m    789\u001b[0m         )\n\u001b[1;32m    790\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    791\u001b[0m     }\n\u001b[1;32m    792\u001b[0m )\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/arrow_dataset.py:2376\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2373\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2375\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2376\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   2377\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   2378\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   2379\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   2380\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   2381\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   2382\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2383\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   2384\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   2385\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   2386\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   2387\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   2388\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   2389\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2390\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   2391\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   2392\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   2393\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   2394\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   2395\u001b[0m     )\n\u001b[1;32m   2396\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2398\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/arrow_dataset.py:551\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    550\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    552\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    553\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    554\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/arrow_dataset.py:518\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    512\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    513\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    514\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    515\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    516\u001b[0m }\n\u001b[1;32m    517\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    519\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    520\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/fingerprint.py:458\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             kwargs[fingerprint_name] \u001b[39m=\u001b[39m update_fingerprint(\n\u001b[1;32m    453\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[1;32m    454\u001b[0m             )\n\u001b[1;32m    456\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/arrow_dataset.py:2781\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2779\u001b[0m                 writer\u001b[39m.\u001b[39mwrite_table(batch)\n\u001b[1;32m   2780\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2781\u001b[0m                 writer\u001b[39m.\u001b[39;49mwrite_batch(batch)\n\u001b[1;32m   2782\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mand\u001b[39;00m writer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2783\u001b[0m     writer\u001b[39m.\u001b[39mfinalize()  \u001b[39m# close_stream=bool(buf_writer is None))  # We only close if we are writing in a file\u001b[39;00m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/arrow_writer.py:503\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    501\u001b[0m     col_try_type \u001b[39m=\u001b[39m try_features[col] \u001b[39mif\u001b[39;00m try_features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m col \u001b[39min\u001b[39;00m try_features \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     typed_sequence \u001b[39m=\u001b[39m OptimizedTypedSequence(batch_examples[col], \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mcol_type, try_type\u001b[39m=\u001b[39mcol_try_type, col\u001b[39m=\u001b[39mcol)\n\u001b[0;32m--> 503\u001b[0m     arrays\u001b[39m.\u001b[39mappend(pa\u001b[39m.\u001b[39;49marray(typed_sequence))\n\u001b[1;32m    504\u001b[0m     inferred_features[col] \u001b[39m=\u001b[39m typed_sequence\u001b[39m.\u001b[39mget_inferred_type()\n\u001b[1;32m    505\u001b[0m schema \u001b[39m=\u001b[39m inferred_features\u001b[39m.\u001b[39marrow_schema \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpa_writer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/pyarrow/array.pxi:230\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/pyarrow/array.pxi:110\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/datasets/arrow_writer.py:183\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     trying_cast_to_python_objects \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     out \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(cast_to_python_objects(data, only_1d_for_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    184\u001b[0m \u001b[39m# use smaller integer precisions if possible\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrying_int_optimization:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenized_swag = swag.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized_swag[\"train\"][0] # type: ignore\n",
    "len(tokenized_swag[\"train\"][0]['input_ids']) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7943cdc6f1674219a1ce64c55b47f653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: ending3, ending0, gold-source, ending1, sent1, startphrase, video-id, fold-ind, ending2, sent2. If ending3, ending0, gold-source, ending1, sent1, startphrase, video-id, fold-ind, ending2, sent2 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 73546\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6897\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwschella\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wout/pp/lass/notebooks/wandb/run-20221124_171327-12pvb3ue</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/wschella/huggingface/runs/12pvb3ue\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/wschella/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3251' max='6897' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3251/6897 19:40 < 22:05, 2.75 it/s, Epoch 1.41/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>0.572500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: ending3, ending0, gold-source, ending1, sent1, startphrase, video-id, fold-ind, ending2, sent2. If ending3, ending0, gold-source, ending1, sent1, startphrase, video-id, fold-ind, ending2, sent2 are not expected by `BertForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20006\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/wout/pp/lass/notebooks/Scratchpad copy.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./results\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     data_collator\u001b[39m=\u001b[39mDataCollatorForMultipleChoice(tokenizer\u001b[39m=\u001b[39mtokenizer),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfalco/home/wout/pp/lass/notebooks/Scratchpad%20copy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/transformers/trainer.py:1409\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1406\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1408\u001b[0m )\n\u001b[0;32m-> 1409\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1410\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1411\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1412\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1413\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1414\u001b[0m )\n",
      "File \u001b[0;32m~/pp/lass/.env/lib/python3.10/site-packages/transformers/trainer.py:1656\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1651\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1653\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1654\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1655\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1656\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39;49misinf(tr_loss_step))\n\u001b[1;32m   1657\u001b[0m ):\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1660\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_swag[\"train\"],\n",
    "    eval_dataset=tokenized_swag[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eed4bfcf3d3cfcdb00482c10052e8eba5705b015008b357326d56e176b5397df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
