{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-09 17:59:20][INFO][test/test]: Starting data loading\n",
      "[2023-05-09 17:59:20][INFO][test/test]: Loaded data.\n",
      "[2023-05-09 17:59:20][INFO][pipeline/binarize]: Dropped 0 samples with non-binary correctness\n",
      "[2023-05-09 17:59:20][INFO][pipeline/clean]: Dropped 0 samples with faulty targets\n",
      "loading configuration file ../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'conf-absolute': {'acc': {'test': 0.6480446927374302,\n",
      "                                       'train': 0.5988857938718662},\n",
      "                               'balanced_acc': {'test': 0.45220125786163523,\n",
      "                                                'train': 0.44509345794392524},\n",
      "                               'bs': {'test': 0.23238584464766057,\n",
      "                                      'train': 0.24753629883553704},\n",
      "                               'bs_dcr': {'test': 0.0,\n",
      "                                          'train': 6.21619998391193e-05},\n",
      "                               'bs_mcb': {'test': 0.13313800594100347,\n",
      "                                          'train': 0.1529530127088098},\n",
      "                               'bs_unc': {'test': 0.0992478387066571,\n",
      "                                          'train': 0.09464544812656639},\n",
      "                               'roc_auc': {'test': 0.37232704402515726,\n",
      "                                           'train': 0.3781357599606493}},\n",
      "             'conf-normalized': {'acc': {'test': 0.11173184357541899,\n",
      "                                         'train': 0.11977715877437325},\n",
      "                                 'balanced_acc': {'test': 0.4781446540880503,\n",
      "                                                  'train': 0.4729873749795048},\n",
      "                                 'bs': {'test': 0.637508183021949,\n",
      "                                        'train': 0.6536743245602392},\n",
      "                                 'bs_dcr': {'test': 4.968962464199644e-06,\n",
      "                                            'train': 1.562640731683773e-05},\n",
      "                                 'bs_mcb': {'test': 0.5382653132777561,\n",
      "                                            'train': 0.5590445028409896},\n",
      "                                 'bs_unc': {'test': 0.0992478387066571,\n",
      "                                            'train': 0.09464544812656639},\n",
      "                                 'roc_auc': {'test': 0.3594339622641509,\n",
      "                                             'train': 0.367314313821938}},\n",
      "             'task-acc': {'test': 0.11173184357541899,\n",
      "                          'train': 0.10584958217270195}},\n",
      " 'stats': {'n_instances': {'test': 179, 'train': 718},\n",
      "           'n_instances_nonbinary': {'test': 0, 'train': 0},\n",
      "           'n_tasks': {'test': 1, 'train': 1}}}\n",
      "                                                 input  \\\n",
      "331  \\nQ: is the following reply unsupportive, neut...   \n",
      "\n",
      "                                 targets  \\\n",
      "331  [unsupportive, neutral, supportive]   \n",
      "\n",
      "                                                scores  \\\n",
      "331  [-0.727025032043457, -4.765151023864746, -3.92...   \n",
      "\n",
      "                                         target_values  correct  \\\n",
      "331  {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
      "\n",
      "                                       absolute_scores  \\\n",
      "331  [-0.727025032043457, -4.765151023864746, -3.92...   \n",
      "\n",
      "                                     normalized_scores  \\\n",
      "331  [-0.05685025453567505, -4.094976425170898, -3....   \n",
      "\n",
      "                                               metrics model_name  \\\n",
      "331  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
      "\n",
      "    model_family            task  shots  n_targets  conf_normalized  \\\n",
      "331    BIG-G T=0  social_support      0          3         0.944736   \n",
      "\n",
      "     conf_absolute  \n",
      "331       0.483345  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dfdbd818d049f986a023984d41850d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"\\nQ: is the following reply unsupportive, neutral, or supportive?Off top of my head I'd say ST_Force_2D , if not then start a new question please.\\n  choice: neutral\\n  choice: supportive\\n  choice: unsupportive\\nA: \", 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84abc41d0c984b74a734ec7f6f8b052f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 179\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# autopep8: off\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "from lass.test import test\n",
    "from lass.log_handling import LogLoaderArgs\n",
    "# autopep8: on\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[%(asctime)s][%(levelname)s][%(module)s/%(funcName)s]: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    return test(\n",
    "        data_args=LogLoaderArgs(\n",
    "            logdir=\"../artifacts/logs\",\n",
    "            # tasks=\"paper-full\",\n",
    "            tasks=[\"social_support\"],\n",
    "            model_families=[\"BIG-G T=0\"],\n",
    "            model_sizes=[\"128b\"],\n",
    "            # model_sizes=[\"2m\"],\n",
    "            shots=[0],\n",
    "            query_types=[\"multiple_choice\"],\n",
    "        ),\n",
    "        model_name=\"microsoft/deberta-v3-base\",\n",
    "        split=\"instance\",\n",
    "        model_loc=\"../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000\",\n",
    "        per_task=True,\n",
    "    )\n",
    "\n",
    "results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = results[\"test\"] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>targets</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_values</th>\n",
       "      <th>correct</th>\n",
       "      <th>absolute_scores</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>metrics</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_family</th>\n",
       "      <th>task</th>\n",
       "      <th>shots</th>\n",
       "      <th>n_targets</th>\n",
       "      <th>conf_normalized</th>\n",
       "      <th>conf_absolute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-1.1098090410232544, -4.575900077819824, -3.5...</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.1098090410232544, -4.575900077819824, -3.5...</td>\n",
       "      <td>[-0.11081051826477051, -3.576901435852051, -2....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.895108</td>\n",
       "      <td>0.329622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-0.5933729410171509, -3.6707634925842285, -3....</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.5933729410171509, -3.6707634925842285, -3....</td>\n",
       "      <td>[-0.10722392797470093, -3.184614419937134, -2....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.898324</td>\n",
       "      <td>0.552461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-1.2501238584518433, -2.508495807647705, -1.9...</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.2501238584518433, -2.508495807647705, -1.9...</td>\n",
       "      <td>[-0.5655719637870789, -1.823943853378296, -1.3...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.568035</td>\n",
       "      <td>0.286469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-0.640267014503479, -4.303163051605225, -3.31...</td>\n",
       "      <td>{'neutral': 0, 'supportive': 1, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.640267014503479, -4.303163051605225, -3.31...</td>\n",
       "      <td>[-0.09018737077713013, -3.7530834674835205, -2...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913760</td>\n",
       "      <td>0.527152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-0.45432960987091064, -3.9837069511413574, -3...</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.45432960987091064, -3.9837069511413574, -3...</td>\n",
       "      <td>[-0.07523393630981445, -3.604611396789551, -3....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.927526</td>\n",
       "      <td>0.634873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-1.2538237571716309, -4.313694953918457, -3.2...</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.2538237571716309, -4.313694953918457, -3.2...</td>\n",
       "      <td>[-0.16582417488098145, -3.2256953716278076, -2...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.847195</td>\n",
       "      <td>0.285411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-1.0576190948486328, -4.816817760467529, -3.9...</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.0576190948486328, -4.816817760467529, -3.9...</td>\n",
       "      <td>[-0.0767824649810791, -3.8359811305999756, -2....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926091</td>\n",
       "      <td>0.347282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-0.5255875587463379, -2.6033880710601807, -2....</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.5255875587463379, -2.6033880710601807, -2....</td>\n",
       "      <td>[-0.20191669464111328, -2.279717206954956, -2....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.817163</td>\n",
       "      <td>0.591208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-0.836595356464386, -3.9597673416137695, -3.1...</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.836595356464386, -3.9597673416137695, -3.1...</td>\n",
       "      <td>[-0.13230788707733154, -3.2554798126220703, -2...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.876071</td>\n",
       "      <td>0.433183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>\\nQ: is the following reply unsupportive, neut...</td>\n",
       "      <td>[unsupportive, neutral, supportive]</td>\n",
       "      <td>[-0.47369539737701416, -3.9668478965759277, -3...</td>\n",
       "      <td>{'neutral': 1, 'supportive': 0, 'unsupportive'...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.47369539737701416, -3.9668478965759277, -3...</td>\n",
       "      <td>[-0.09796136617660522, -3.591113805770874, -2....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>social_support</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.906684</td>\n",
       "      <td>0.622697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  \\\n",
       "1    \\nQ: is the following reply unsupportive, neut...   \n",
       "4    \\nQ: is the following reply unsupportive, neut...   \n",
       "13   \\nQ: is the following reply unsupportive, neut...   \n",
       "14   \\nQ: is the following reply unsupportive, neut...   \n",
       "20   \\nQ: is the following reply unsupportive, neut...   \n",
       "..                                                 ...   \n",
       "871  \\nQ: is the following reply unsupportive, neut...   \n",
       "873  \\nQ: is the following reply unsupportive, neut...   \n",
       "877  \\nQ: is the following reply unsupportive, neut...   \n",
       "889  \\nQ: is the following reply unsupportive, neut...   \n",
       "893  \\nQ: is the following reply unsupportive, neut...   \n",
       "\n",
       "                                 targets  \\\n",
       "1    [unsupportive, neutral, supportive]   \n",
       "4    [unsupportive, neutral, supportive]   \n",
       "13   [unsupportive, neutral, supportive]   \n",
       "14   [unsupportive, neutral, supportive]   \n",
       "20   [unsupportive, neutral, supportive]   \n",
       "..                                   ...   \n",
       "871  [unsupportive, neutral, supportive]   \n",
       "873  [unsupportive, neutral, supportive]   \n",
       "877  [unsupportive, neutral, supportive]   \n",
       "889  [unsupportive, neutral, supportive]   \n",
       "893  [unsupportive, neutral, supportive]   \n",
       "\n",
       "                                                scores  \\\n",
       "1    [-1.1098090410232544, -4.575900077819824, -3.5...   \n",
       "4    [-0.5933729410171509, -3.6707634925842285, -3....   \n",
       "13   [-1.2501238584518433, -2.508495807647705, -1.9...   \n",
       "14   [-0.640267014503479, -4.303163051605225, -3.31...   \n",
       "20   [-0.45432960987091064, -3.9837069511413574, -3...   \n",
       "..                                                 ...   \n",
       "871  [-1.2538237571716309, -4.313694953918457, -3.2...   \n",
       "873  [-1.0576190948486328, -4.816817760467529, -3.9...   \n",
       "877  [-0.5255875587463379, -2.6033880710601807, -2....   \n",
       "889  [-0.836595356464386, -3.9597673416137695, -3.1...   \n",
       "893  [-0.47369539737701416, -3.9668478965759277, -3...   \n",
       "\n",
       "                                         target_values  correct  \\\n",
       "1    {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "4    {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "13   {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "14   {'neutral': 0, 'supportive': 1, 'unsupportive'...        0   \n",
       "20   {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "..                                                 ...      ...   \n",
       "871  {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "873  {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "877  {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "889  {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "893  {'neutral': 1, 'supportive': 0, 'unsupportive'...        0   \n",
       "\n",
       "                                       absolute_scores  \\\n",
       "1    [-1.1098090410232544, -4.575900077819824, -3.5...   \n",
       "4    [-0.5933729410171509, -3.6707634925842285, -3....   \n",
       "13   [-1.2501238584518433, -2.508495807647705, -1.9...   \n",
       "14   [-0.640267014503479, -4.303163051605225, -3.31...   \n",
       "20   [-0.45432960987091064, -3.9837069511413574, -3...   \n",
       "..                                                 ...   \n",
       "871  [-1.2538237571716309, -4.313694953918457, -3.2...   \n",
       "873  [-1.0576190948486328, -4.816817760467529, -3.9...   \n",
       "877  [-0.5255875587463379, -2.6033880710601807, -2....   \n",
       "889  [-0.836595356464386, -3.9597673416137695, -3.1...   \n",
       "893  [-0.47369539737701416, -3.9668478965759277, -3...   \n",
       "\n",
       "                                     normalized_scores  \\\n",
       "1    [-0.11081051826477051, -3.576901435852051, -2....   \n",
       "4    [-0.10722392797470093, -3.184614419937134, -2....   \n",
       "13   [-0.5655719637870789, -1.823943853378296, -1.3...   \n",
       "14   [-0.09018737077713013, -3.7530834674835205, -2...   \n",
       "20   [-0.07523393630981445, -3.604611396789551, -3....   \n",
       "..                                                 ...   \n",
       "871  [-0.16582417488098145, -3.2256953716278076, -2...   \n",
       "873  [-0.0767824649810791, -3.8359811305999756, -2....   \n",
       "877  [-0.20191669464111328, -2.279717206954956, -2....   \n",
       "889  [-0.13230788707733154, -3.2554798126220703, -2...   \n",
       "893  [-0.09796136617660522, -3.591113805770874, -2....   \n",
       "\n",
       "                                               metrics model_name  \\\n",
       "1    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "4    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "13   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "14   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "20   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "..                                                 ...        ...   \n",
       "871  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "873  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "877  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "889  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "893  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "\n",
       "    model_family            task  shots  n_targets  conf_normalized  \\\n",
       "1      BIG-G T=0  social_support      0          3         0.895108   \n",
       "4      BIG-G T=0  social_support      0          3         0.898324   \n",
       "13     BIG-G T=0  social_support      0          3         0.568035   \n",
       "14     BIG-G T=0  social_support      0          3         0.913760   \n",
       "20     BIG-G T=0  social_support      0          3         0.927526   \n",
       "..           ...             ...    ...        ...              ...   \n",
       "871    BIG-G T=0  social_support      0          3         0.847195   \n",
       "873    BIG-G T=0  social_support      0          3         0.926091   \n",
       "877    BIG-G T=0  social_support      0          3         0.817163   \n",
       "889    BIG-G T=0  social_support      0          3         0.876071   \n",
       "893    BIG-G T=0  social_support      0          3         0.906684   \n",
       "\n",
       "     conf_absolute  \n",
       "1         0.329622  \n",
       "4         0.552461  \n",
       "13        0.286469  \n",
       "14        0.527152  \n",
       "20        0.634873  \n",
       "..             ...  \n",
       "871       0.285411  \n",
       "873       0.347282  \n",
       "877       0.591208  \n",
       "889       0.433183  \n",
       "893       0.622697  \n",
       "\n",
       "[179 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_preds = np.array(df.scores.values.tolist())\n",
    "subject_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 1, 'supportive': 0, 'unsupportive': 0}    137\n",
       "{'neutral': 0, 'supportive': 1, 'unsupportive': 0}     22\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 0\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'supportive': 0, 'unsupportive': 1}    18\n",
       "{'neutral': 1, 'supportive': 0, 'unsupportive': 0}     2\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 1\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>asss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct  asss\n",
       "35         1     0\n",
       "52         1     0\n",
       "71         1     0\n",
       "102        1     0\n",
       "105        1     0\n",
       "106        1     0\n",
       "159        1     0\n",
       "191        1     0\n",
       "242        1     0\n",
       "288        1     0\n",
       "295        1     0\n",
       "339        1     0\n",
       "461        1     0\n",
       "546        1     0\n",
       "561        1     0\n",
       "690        1     0\n",
       "719        1     0\n",
       "726        1     0\n",
       "758        1     0\n",
       "818        1     0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"logits\"].argmax(axis=1)\n",
    "\n",
    "j = df[\"correct\"].to_frame()\n",
    "j[\"asss\"] = results[\"logits\"].argmax(axis=1)\n",
    "j.query(\"correct != asss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.3133768141269684,\n",
       " 'test_conf_distribution_accuracy': 0.888268156424581,\n",
       " 'test_conf_distribution_precision': 0.0,\n",
       " 'test_conf_distribution_recall': 0.0,\n",
       " 'test_conf_distribution_f1': 0.0,\n",
       " 'test_conf_distribution_roc_auc': 0.5,\n",
       " 'test_conf_distribution_bs': 0.0992478387066571,\n",
       " 'test_conf_distribution_bs_mcb': 0.0,\n",
       " 'test_conf_distribution_bs_dsc': 0.0,\n",
       " 'test_conf_distribution_bs_unc': 0.0992478387066571,\n",
       " 'test_conf_distribution_balanced_accuracy': 0.5,\n",
       " 'test_conf_absolute_accuracy': 0.6480446927374302,\n",
       " 'test_conf_absolute_precision': 0.0784313725490196,\n",
       " 'test_conf_absolute_recall': 0.2,\n",
       " 'test_conf_absolute_f1': 0.11267605633802816,\n",
       " 'test_conf_absolute_roc_auc': 0.37232704402515726,\n",
       " 'test_conf_absolute_bs': 0.23238584464766057,\n",
       " 'test_conf_absolute_bs_mcb': 0.13313800594100347,\n",
       " 'test_conf_absolute_bs_dsc': 0.0,\n",
       " 'test_conf_absolute_bs_unc': 0.0992478387066571,\n",
       " 'test_conf_absolute_balanced_accuracy': 0.45220125786163523,\n",
       " 'test_conf_normalized_accuracy': 0.11173184357541899,\n",
       " 'test_conf_normalized_precision': 0.10734463276836158,\n",
       " 'test_conf_normalized_recall': 0.95,\n",
       " 'test_conf_normalized_f1': 0.19289340101522842,\n",
       " 'test_conf_normalized_roc_auc': 0.3594339622641509,\n",
       " 'test_conf_normalized_bs': 0.637508183021949,\n",
       " 'test_conf_normalized_bs_mcb': 0.5382653132777561,\n",
       " 'test_conf_normalized_bs_dsc': 4.968962464199644e-06,\n",
       " 'test_conf_normalized_bs_unc': 0.0992478387066571,\n",
       " 'test_conf_normalized_balanced_accuracy': 0.4781446540880503,\n",
       " 'test_accuracy': 0.888268156424581,\n",
       " 'test_precision': 0.0,\n",
       " 'test_recall': 0.0,\n",
       " 'test_f1': 0.0,\n",
       " 'test_roc_auc': 0.8009433962264151,\n",
       " 'test_bs': 0.09167281951540913,\n",
       " 'test_bs_mcb': 0.02177995646520106,\n",
       " 'test_bs_dsc': 0.029354975656449026,\n",
       " 'test_bs_unc': 0.0992478387066571,\n",
       " 'test_balanced_accuracy': 0.5,\n",
       " 'test_runtime': 2.5355,\n",
       " 'test_samples_per_second': 70.597,\n",
       " 'test_steps_per_second': 9.071}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"metrics\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
