{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-09 17:25:18][INFO][test/test]: Starting data loading\n",
      "[2023-05-09 17:25:18][INFO][test/test]: Loaded data.\n",
      "[2023-05-09 17:25:18][INFO][pipeline/binarize]: Dropped 0 samples with non-binary correctness\n",
      "[2023-05-09 17:25:18][INFO][pipeline/clean]: Dropped 0 samples with faulty targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'conf-absolute': {'acc': {'test': 0.4878048780487805,\n",
      "                                       'train': 0.48717948717948717},\n",
      "                               'balanced_acc': {'test': 0.5, 'train': 0.5},\n",
      "                               'bs': {'test': 0.4292732877086716,\n",
      "                                      'train': 0.42639204287866683},\n",
      "                               'bs_dcr': {'test': 0.010599516832484307,\n",
      "                                          'train': 0.004995771463788323},\n",
      "                               'bs_mcb': {'test': 0.19002152554056112,\n",
      "                                          'train': 0.18155217989143602},\n",
      "                               'bs_unc': {'test': 0.2498512790005948,\n",
      "                                          'train': 0.24983563445101914},\n",
      "                               'roc_auc': {'test': 0.539047619047619,\n",
      "                                           'train': 0.5513307077216851}},\n",
      "             'conf-normalized': {'acc': {'test': 0.5121951219512195,\n",
      "                                         'train': 0.5128205128205128},\n",
      "                                 'balanced_acc': {'test': 0.5, 'train': 0.5},\n",
      "                                 'bs': {'test': 0.2574548974424024,\n",
      "                                        'train': 0.25790157255901636},\n",
      "                                 'bs_dcr': {'test': 0.02440167440464877,\n",
      "                                            'train': 0.0176245886428531},\n",
      "                                 'bs_mcb': {'test': 0.03200529284645637,\n",
      "                                            'train': 0.025690526750850318},\n",
      "                                 'bs_unc': {'test': 0.2498512790005948,\n",
      "                                            'train': 0.24983563445101914},\n",
      "                                 'roc_auc': {'test': 0.6380952380952382,\n",
      "                                             'train': 0.6361976369495166}},\n",
      "             'task-acc': {'test': 0.5121951219512195,\n",
      "                          'train': 0.5128205128205128}},\n",
      " 'stats': {'n_instances': {'test': 205, 'train': 819},\n",
      "           'n_instances_nonbinary': {'test': 0, 'train': 0},\n",
      "           'n_tasks': {'test': 1, 'train': 1}}}\n",
      "                                                 input targets  \\\n",
      "525  \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
      "\n",
      "                                         scores     target_values  correct  \\\n",
      "525  [-3.1250035762786865, -2.8143413066864014]  {'a': 1, 'b': 0}        0   \n",
      "\n",
      "                                absolute_scores  \\\n",
      "525  [-3.1250035762786865, -2.8143413066864014]   \n",
      "\n",
      "                              normalized_scores  \\\n",
      "525  [-0.8604938983917236, -0.5498316287994385]   \n",
      "\n",
      "                                               metrics model_name  \\\n",
      "525  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
      "\n",
      "    model_family        task  shots  n_targets  conf_normalized  conf_absolute  \n",
      "525    BIG-G T=0  hyperbaton      0          2         0.577047       0.059944  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2023-05-09 17:25:23][WARNING][fingerprint/update_fingerprint]: Parameter 'function'=<function tokenize.<locals>.tokenize_function at 0x7f3c56b72dd0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7766d3cd631413fb6890dffbe1ed597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 205\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/26 00:00 < 00:02, 9.36 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[2023-05-09 17:25:27][INFO][test/test]: Starting tokenization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '\\nQ: Which sentence has the correct adjective order: a \" circular obnoxious old rubber little Japanese sock \" b \" obnoxious little old circular Japanese rubber sock \" ?\\nA: ', 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8128a65f101a4bc8816ea33dc2d82da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 205\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 205\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# autopep8: off\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "from lass.test import test\n",
    "from lass.log_handling import LogLoaderArgs\n",
    "# autopep8: on\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[%(asctime)s][%(levelname)s][%(module)s/%(funcName)s]: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    return test(\n",
    "        data_args=LogLoaderArgs(\n",
    "            logdir=\"../artifacts/logs\",\n",
    "            # tasks=\"paper-full\",\n",
    "            tasks=[\"hyperbaton\"],\n",
    "            model_families=[\"BIG-G T=0\"],\n",
    "            model_sizes=[\"128b\"],\n",
    "            # model_sizes=[\"2m\"],\n",
    "            shots=[0],\n",
    "            query_types=[\"multiple_choice\"],\n",
    "        ),\n",
    "        model_name=\"microsoft/deberta-v3-base\",\n",
    "        split=\"instance\",\n",
    "        model_loc=\"../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000\",\n",
    "        per_task=True,\n",
    "    )\n",
    "\n",
    "results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = results[\"test\"] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>targets</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_values</th>\n",
       "      <th>correct</th>\n",
       "      <th>absolute_scores</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>metrics</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_family</th>\n",
       "      <th>task</th>\n",
       "      <th>shots</th>\n",
       "      <th>n_targets</th>\n",
       "      <th>conf_normalized</th>\n",
       "      <th>conf_absolute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-2.7656452655792236, -2.2711105346679688]</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-2.7656452655792236, -2.2711105346679688]</td>\n",
       "      <td>[-0.9706785678863525, -0.47614383697509766]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.621174</td>\n",
       "      <td>0.103198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-3.1615405082702637, -2.5942275524139404]</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-3.1615405082702637, -2.5942275524139404]</td>\n",
       "      <td>[-1.0165059566497803, -0.44919300079345703]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.638143</td>\n",
       "      <td>0.074704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-3.158343553543091, -2.1781249046325684]</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>[-3.158343553543091, -2.1781249046325684]</td>\n",
       "      <td>[-1.2988389730453491, -0.31862032413482666]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>0.113254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-2.9822895526885986, -2.449110984802246]</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-2.9822895526885986, -2.449110984802246]</td>\n",
       "      <td>[-0.9948582649230957, -0.46167969703674316]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630224</td>\n",
       "      <td>0.086370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-2.873600959777832, -2.4020771980285645]</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-2.873600959777832, -2.4020771980285645]</td>\n",
       "      <td>[-0.9564471244812012, -0.4849233627319336]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.615744</td>\n",
       "      <td>0.090530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-2.93487548828125, -2.503232002258301]</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.93487548828125, -2.503232002258301]</td>\n",
       "      <td>[-0.9320797920227051, -0.5004363059997559]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606266</td>\n",
       "      <td>0.081820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-2.591588020324707, -2.522007942199707]</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.591588020324707, -2.522007942199707]</td>\n",
       "      <td>[-0.7285423278808594, -0.6589622497558594]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.517388</td>\n",
       "      <td>0.080298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-3.212395191192627, -2.241703987121582]</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-3.212395191192627, -2.241703987121582]</td>\n",
       "      <td>[-1.2919200658798218, -0.32122886180877686]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.725257</td>\n",
       "      <td>0.106277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-3.0566329956054688, -2.471961498260498]</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-3.0566329956054688, -2.471961498260498]</td>\n",
       "      <td>[-1.0276179313659668, -0.4429464340209961]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.642142</td>\n",
       "      <td>0.084419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>\\nQ: Which sentence has the correct adjective ...</td>\n",
       "      <td>[a, b]</td>\n",
       "      <td>[-3.155141592025757, -2.45941162109375]</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>[-3.155141592025757, -2.45941162109375]</td>\n",
       "      <td>[-1.100334882736206, -0.4046049118041992]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>hyperbaton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667240</td>\n",
       "      <td>0.085485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input targets  \\\n",
       "1     \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "4     \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "13    \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "14    \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "20    \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "...                                                 ...     ...   \n",
       "1000  \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "1004  \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "1006  \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "1016  \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "1020  \\nQ: Which sentence has the correct adjective ...  [a, b]   \n",
       "\n",
       "                                          scores     target_values  correct  \\\n",
       "1     [-2.7656452655792236, -2.2711105346679688]  {'a': 0, 'b': 1}        1   \n",
       "4     [-3.1615405082702637, -2.5942275524139404]  {'a': 0, 'b': 1}        1   \n",
       "13     [-3.158343553543091, -2.1781249046325684]  {'a': 1, 'b': 0}        0   \n",
       "14     [-2.9822895526885986, -2.449110984802246]  {'a': 0, 'b': 1}        1   \n",
       "20     [-2.873600959777832, -2.4020771980285645]  {'a': 0, 'b': 1}        1   \n",
       "...                                          ...               ...      ...   \n",
       "1000     [-2.93487548828125, -2.503232002258301]  {'a': 1, 'b': 0}        0   \n",
       "1004    [-2.591588020324707, -2.522007942199707]  {'a': 1, 'b': 0}        0   \n",
       "1006    [-3.212395191192627, -2.241703987121582]  {'a': 0, 'b': 1}        1   \n",
       "1016   [-3.0566329956054688, -2.471961498260498]  {'a': 0, 'b': 1}        1   \n",
       "1020     [-3.155141592025757, -2.45941162109375]  {'a': 1, 'b': 0}        0   \n",
       "\n",
       "                                 absolute_scores  \\\n",
       "1     [-2.7656452655792236, -2.2711105346679688]   \n",
       "4     [-3.1615405082702637, -2.5942275524139404]   \n",
       "13     [-3.158343553543091, -2.1781249046325684]   \n",
       "14     [-2.9822895526885986, -2.449110984802246]   \n",
       "20     [-2.873600959777832, -2.4020771980285645]   \n",
       "...                                          ...   \n",
       "1000     [-2.93487548828125, -2.503232002258301]   \n",
       "1004    [-2.591588020324707, -2.522007942199707]   \n",
       "1006    [-3.212395191192627, -2.241703987121582]   \n",
       "1016   [-3.0566329956054688, -2.471961498260498]   \n",
       "1020     [-3.155141592025757, -2.45941162109375]   \n",
       "\n",
       "                                normalized_scores  \\\n",
       "1     [-0.9706785678863525, -0.47614383697509766]   \n",
       "4     [-1.0165059566497803, -0.44919300079345703]   \n",
       "13    [-1.2988389730453491, -0.31862032413482666]   \n",
       "14    [-0.9948582649230957, -0.46167969703674316]   \n",
       "20     [-0.9564471244812012, -0.4849233627319336]   \n",
       "...                                           ...   \n",
       "1000   [-0.9320797920227051, -0.5004363059997559]   \n",
       "1004   [-0.7285423278808594, -0.6589622497558594]   \n",
       "1006  [-1.2919200658798218, -0.32122886180877686]   \n",
       "1016   [-1.0276179313659668, -0.4429464340209961]   \n",
       "1020    [-1.100334882736206, -0.4046049118041992]   \n",
       "\n",
       "                                                metrics model_name  \\\n",
       "1     {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "4     {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "13    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "14    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "20    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "...                                                 ...        ...   \n",
       "1000  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "1004  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "1006  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "1016  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "1020  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "\n",
       "     model_family        task  shots  n_targets  conf_normalized  \\\n",
       "1       BIG-G T=0  hyperbaton      0          2         0.621174   \n",
       "4       BIG-G T=0  hyperbaton      0          2         0.638143   \n",
       "13      BIG-G T=0  hyperbaton      0          2         0.727152   \n",
       "14      BIG-G T=0  hyperbaton      0          2         0.630224   \n",
       "20      BIG-G T=0  hyperbaton      0          2         0.615744   \n",
       "...           ...         ...    ...        ...              ...   \n",
       "1000    BIG-G T=0  hyperbaton      0          2         0.606266   \n",
       "1004    BIG-G T=0  hyperbaton      0          2         0.517388   \n",
       "1006    BIG-G T=0  hyperbaton      0          2         0.725257   \n",
       "1016    BIG-G T=0  hyperbaton      0          2         0.642142   \n",
       "1020    BIG-G T=0  hyperbaton      0          2         0.667240   \n",
       "\n",
       "      conf_absolute  \n",
       "1          0.103198  \n",
       "4          0.074704  \n",
       "13         0.113254  \n",
       "14         0.086370  \n",
       "20         0.090530  \n",
       "...             ...  \n",
       "1000       0.081820  \n",
       "1004       0.080298  \n",
       "1006       0.106277  \n",
       "1016       0.084419  \n",
       "1020       0.085485  \n",
       "\n",
       "[205 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_preds = np.array(df.scores.values.tolist())\n",
    "subject_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 0}    97\n",
       "{'a': 0, 'b': 1}     3\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 0\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1}    101\n",
       "{'a': 1, 'b': 0}      4\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 1\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17038/853927686.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  j[\"asss\"] = results[\"logits\"].argmax(axis=1)\n",
      "/tmp/ipykernel_17038/853927686.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  j[\"subject_preds\"] = subject_preds.argmax(axis=1)\n",
      "/tmp/ipykernel_17038/853927686.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  j[\"subject_preds\"] = j[\"subject_preds\"].map({0: \"A\", 1: \"B\"})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>target_values</th>\n",
       "      <th>asss</th>\n",
       "      <th>subject_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct     target_values  asss subject_preds\n",
       "106        0  {'a': 0, 'b': 1}     1             A\n",
       "161        0  {'a': 1, 'b': 0}     1             B\n",
       "214        1  {'a': 1, 'b': 0}     0             A\n",
       "458        1  {'a': 1, 'b': 0}     0             A\n",
       "475        1  {'a': 0, 'b': 1}     0             B\n",
       "574        0  {'a': 0, 'b': 1}     1             A\n",
       "681        0  {'a': 1, 'b': 0}     1             B\n",
       "871        1  {'a': 1, 'b': 0}     0             A\n",
       "957        0  {'a': 0, 'b': 1}     1             A\n",
       "986        1  {'a': 1, 'b': 0}     0             A"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"logits\"].argmax(axis=1)\n",
    "\n",
    "j = df[[\"correct\", \"target_values\"]]\n",
    "j[\"asss\"] = results[\"logits\"].argmax(axis=1)\n",
    "j[\"subject_preds\"] = subject_preds.argmax(axis=1)\n",
    "j[\"subject_preds\"] = j[\"subject_preds\"].map({0: \"A\", 1: \"B\"})\n",
    "j.query(\"correct != asss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>target_values</th>\n",
       "      <th>asss</th>\n",
       "      <th>subject_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0</td>\n",
       "      <td>{'a': 0, 'b': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1</td>\n",
       "      <td>{'a': 1, 'b': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct     target_values  asss subject_preds\n",
       "106        0  {'a': 0, 'b': 1}     1             A\n",
       "574        0  {'a': 0, 'b': 1}     1             A\n",
       "957        0  {'a': 0, 'b': 1}     1             A\n",
       "214        1  {'a': 1, 'b': 0}     0             A\n",
       "458        1  {'a': 1, 'b': 0}     0             A\n",
       "871        1  {'a': 1, 'b': 0}     0             A\n",
       "986        1  {'a': 1, 'b': 0}     0             A"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.query(\"subject_preds == 'A'\").sort_values(\"correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.18315140902996063,\n",
       " 'test_conf_distribution_accuracy': 0.5121951219512195,\n",
       " 'test_conf_distribution_precision': 0.5121951219512195,\n",
       " 'test_conf_distribution_recall': 1.0,\n",
       " 'test_conf_distribution_f1': 0.6774193548387097,\n",
       " 'test_conf_distribution_roc_auc': 0.5,\n",
       " 'test_conf_distribution_bs': 0.2498512790005948,\n",
       " 'test_conf_distribution_bs_mcb': 0.0,\n",
       " 'test_conf_distribution_bs_dsc': 0.0,\n",
       " 'test_conf_distribution_bs_unc': 0.2498512790005948,\n",
       " 'test_conf_distribution_balanced_accuracy': 0.5,\n",
       " 'test_conf_absolute_accuracy': 0.4878048780487805,\n",
       " 'test_conf_absolute_precision': 0.0,\n",
       " 'test_conf_absolute_recall': 0.0,\n",
       " 'test_conf_absolute_f1': 0.0,\n",
       " 'test_conf_absolute_roc_auc': 0.539047619047619,\n",
       " 'test_conf_absolute_bs': 0.4292732877086716,\n",
       " 'test_conf_absolute_bs_mcb': 0.19002152554056112,\n",
       " 'test_conf_absolute_bs_dsc': 0.010599516832484307,\n",
       " 'test_conf_absolute_bs_unc': 0.2498512790005948,\n",
       " 'test_conf_absolute_balanced_accuracy': 0.5,\n",
       " 'test_conf_normalized_accuracy': 0.5121951219512195,\n",
       " 'test_conf_normalized_precision': 0.5121951219512195,\n",
       " 'test_conf_normalized_recall': 1.0,\n",
       " 'test_conf_normalized_f1': 0.6774193548387097,\n",
       " 'test_conf_normalized_roc_auc': 0.6380952380952382,\n",
       " 'test_conf_normalized_bs': 0.25745489744240246,\n",
       " 'test_conf_normalized_bs_mcb': 0.032005292846456423,\n",
       " 'test_conf_normalized_bs_dsc': 0.02440167440464877,\n",
       " 'test_conf_normalized_bs_unc': 0.2498512790005948,\n",
       " 'test_conf_normalized_balanced_accuracy': 0.5,\n",
       " 'test_accuracy': 0.9512195121951219,\n",
       " 'test_precision': 0.9523809523809523,\n",
       " 'test_recall': 0.9523809523809523,\n",
       " 'test_f1': 0.9523809523809523,\n",
       " 'test_roc_auc': 0.9704285714285714,\n",
       " 'test_bs': 0.04145169275707315,\n",
       " 'test_bs_mcb': 0.008184825383569252,\n",
       " 'test_bs_dsc': 0.2165844116270909,\n",
       " 'test_bs_unc': 0.2498512790005948,\n",
       " 'test_balanced_accuracy': 0.9511904761904761,\n",
       " 'test_runtime': 2.8388,\n",
       " 'test_samples_per_second': 72.213,\n",
       " 'test_steps_per_second': 9.159}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"metrics\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
