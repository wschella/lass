{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-09 17:48:35][INFO][test/test]: Starting data loading\n",
      "[2023-05-09 17:48:35][INFO][test/test]: Loaded data.\n",
      "[2023-05-09 17:48:35][INFO][pipeline/binarize]: Dropped 0 samples with non-binary correctness\n",
      "[2023-05-09 17:48:35][INFO][pipeline/clean]: Dropped 0 samples with faulty targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'conf-absolute': {'acc': {'test': 0.5661764705882353,\n",
      "                                       'train': 0.6066176470588235},\n",
      "                               'balanced_acc': {'test': 0.5100877192982456,\n",
      "                                                'train': 0.49343712061701067},\n",
      "                               'bs': {'test': 0.3965975809972453,\n",
      "                                      'train': 0.3562637280016214},\n",
      "                               'bs_dcr': {'test': 0.003437673917777745,\n",
      "                                          'train': 0.0006983803078023654},\n",
      "                               'bs_mcb': {'test': 0.15349546252747978,\n",
      "                                          'train': 0.1203737919166902},\n",
      "                               'bs_unc': {'test': 0.24653979238754326,\n",
      "                                          'train': 0.2365883163927336},\n",
      "                               'roc_auc': {'test': 0.437938596491228,\n",
      "                                           'train': 0.438634578304649}},\n",
      "             'conf-normalized': {'acc': {'test': 0.4411764705882353,\n",
      "                                         'train': 0.38419117647058826},\n",
      "                                 'balanced_acc': {'test': 0.5, 'train': 0.5},\n",
      "                                 'bs': {'test': 0.4158962694892523,\n",
      "                                        'train': 0.4215478208354447},\n",
      "                                 'bs_dcr': {'test': 0.0,\n",
      "                                            'train': 0.0026725962269032455},\n",
      "                                 'bs_mcb': {'test': 0.16935647710170904,\n",
      "                                            'train': 0.18763210066961433},\n",
      "                                 'bs_unc': {'test': 0.24653979238754326,\n",
      "                                            'train': 0.2365883163927336},\n",
      "                                 'roc_auc': {'test': 0.3899122807017544,\n",
      "                                             'train': 0.5252731557523389}},\n",
      "             'task-acc': {'test': 0.4411764705882353,\n",
      "                          'train': 0.38419117647058826}},\n",
      " 'stats': {'n_instances': {'test': 136, 'train': 544},\n",
      "           'n_instances_nonbinary': {'test': 0, 'train': 0},\n",
      "           'n_tasks': {'test': 1, 'train': 1}}}\n",
      "                                                 input        targets  \\\n",
      "647  The essence of the task: Given a metaphoric se...  [True, False]   \n",
      "\n",
      "                                         scores                target_values  \\\n",
      "647  [-1.2710144519805908, -3.8004794120788574]  {'False': 1.0, 'True': 0.0}   \n",
      "\n",
      "     correct                             absolute_scores  \\\n",
      "647        0  [-1.2710144519805908, -3.8004794120788574]   \n",
      "\n",
      "                              normalized_scores  \\\n",
      "647  [-0.07668471336364746, -2.606149673461914]   \n",
      "\n",
      "                                               metrics model_name  \\\n",
      "647  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
      "\n",
      "    model_family              task  shots  n_targets  conf_normalized  \\\n",
      "647    BIG-G T=0  metaphor_boolean      0          2         0.926182   \n",
      "\n",
      "     conf_absolute  \n",
      "647       0.280547  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2023-05-09 17:48:41][WARNING][fingerprint/update_fingerprint]: Parameter 'function'=<function tokenize.<locals>.tokenize_function at 0x7fab0ffa3520> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e027715daf4a38ba7e15a5b6d5f83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 136\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 136\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[2023-05-09 17:48:44][INFO][test/test]: Starting tokenization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The essence of the task: Given a metaphoric sentence, identify if the second sentence is the correct paraphrase of the first.\\nQ: Krishna is an early bird. <--> Krishna is a bird.\\n  choice: True\\n  choice: False\\nA: ', 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caaf98dcd2ab4d5587fa3f1512181ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 136\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 136\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# autopep8: off\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "from lass.test import test\n",
    "from lass.log_handling import LogLoaderArgs\n",
    "# autopep8: on\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[%(asctime)s][%(levelname)s][%(module)s/%(funcName)s]: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    return test(\n",
    "        data_args=LogLoaderArgs(\n",
    "            logdir=\"../artifacts/logs\",\n",
    "            # tasks=\"paper-full\",\n",
    "            tasks=[\"metaphor_boolean\"],\n",
    "            model_families=[\"BIG-G T=0\"],\n",
    "            model_sizes=[\"128b\"],\n",
    "            # model_sizes=[\"2m\"],\n",
    "            shots=[0],\n",
    "            query_types=[\"multiple_choice\"],\n",
    "        ),\n",
    "        model_name=\"microsoft/deberta-v3-base\",\n",
    "        split=\"instance\",\n",
    "        model_loc=\"../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000\",\n",
    "        per_task=True,\n",
    "    )\n",
    "\n",
    "results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = results[\"test\"] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>targets</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_values</th>\n",
       "      <th>correct</th>\n",
       "      <th>absolute_scores</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>metrics</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_family</th>\n",
       "      <th>task</th>\n",
       "      <th>shots</th>\n",
       "      <th>n_targets</th>\n",
       "      <th>conf_normalized</th>\n",
       "      <th>conf_absolute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-7.691727638244629, -7.644883155822754]</td>\n",
       "      <td>{'False': 1.0, 'True': 0.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-7.691727638244629, -7.644883155822754]</td>\n",
       "      <td>[-0.7168436050415039, -0.6699991226196289]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511709</td>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-4.907443046569824, -6.679103851318359]</td>\n",
       "      <td>{'False': 0.0, 'True': 1.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-4.907443046569824, -6.679103851318359]</td>\n",
       "      <td>[-0.15704679489135742, -1.9287075996398926]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854664</td>\n",
       "      <td>0.007391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-4.442530155181885, -6.285279273986816]</td>\n",
       "      <td>{'False': 0.0, 'True': 1.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-4.442530155181885, -6.285279273986816]</td>\n",
       "      <td>[-0.14702367782592773, -1.9897727966308594]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.863274</td>\n",
       "      <td>0.011766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-3.221273183822632, -3.2224483489990234]</td>\n",
       "      <td>{'False': 0.0, 'True': 1.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-3.221273183822632, -3.2224483489990234]</td>\n",
       "      <td>[-0.6925597190856934, -0.693734884262085]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500294</td>\n",
       "      <td>0.039904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-6.161440849304199, -6.881628513336182]</td>\n",
       "      <td>{'False': 0.0, 'True': 1.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-6.161440849304199, -6.881628513336182]</td>\n",
       "      <td>[-0.3965325355529785, -1.116720199584961]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.672648</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-5.049830436706543, -6.155820846557617]</td>\n",
       "      <td>{'False': 1.0, 'True': 0.0}</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.049830436706543, -6.155820846557617]</td>\n",
       "      <td>[-0.2858428955078125, -1.3918333053588867]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>0.006410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-6.938714504241943, -7.369767665863037]</td>\n",
       "      <td>{'False': 0.0, 'True': 1.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-6.938714504241943, -7.369767665863037]</td>\n",
       "      <td>[-0.500669002532959, -0.9317221641540527]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606125</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-2.81099534034729, -4.886043548583984]</td>\n",
       "      <td>{'False': 1.0, 'True': 0.0}</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.81099534034729, -4.886043548583984]</td>\n",
       "      <td>[-0.11827206611633301, -2.1933202743530273]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888454</td>\n",
       "      <td>0.060145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-1.621280312538147, -3.200751543045044]</td>\n",
       "      <td>{'False': 0.0, 'True': 1.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>[-1.621280312538147, -3.200751543045044]</td>\n",
       "      <td>[-0.18737876415252686, -1.7668499946594238]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829130</td>\n",
       "      <td>0.197645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>The essence of the task: Given a metaphoric se...</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[-6.078128814697266, -8.060128211975098]</td>\n",
       "      <td>{'False': 1.0, 'True': 0.0}</td>\n",
       "      <td>0</td>\n",
       "      <td>[-6.078128814697266, -8.060128211975098]</td>\n",
       "      <td>[-0.1290907859802246, -2.1110901832580566]</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>metaphor_boolean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.878894</td>\n",
       "      <td>0.002292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input        targets  \\\n",
       "1    The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "4    The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "13   The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "14   The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "20   The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "..                                                 ...            ...   \n",
       "663  The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "664  The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "669  The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "674  The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "677  The essence of the task: Given a metaphoric se...  [True, False]   \n",
       "\n",
       "                                        scores                target_values  \\\n",
       "1     [-7.691727638244629, -7.644883155822754]  {'False': 1.0, 'True': 0.0}   \n",
       "4     [-4.907443046569824, -6.679103851318359]  {'False': 0.0, 'True': 1.0}   \n",
       "13    [-4.442530155181885, -6.285279273986816]  {'False': 0.0, 'True': 1.0}   \n",
       "14   [-3.221273183822632, -3.2224483489990234]  {'False': 0.0, 'True': 1.0}   \n",
       "20    [-6.161440849304199, -6.881628513336182]  {'False': 0.0, 'True': 1.0}   \n",
       "..                                         ...                          ...   \n",
       "663   [-5.049830436706543, -6.155820846557617]  {'False': 1.0, 'True': 0.0}   \n",
       "664   [-6.938714504241943, -7.369767665863037]  {'False': 0.0, 'True': 1.0}   \n",
       "669    [-2.81099534034729, -4.886043548583984]  {'False': 1.0, 'True': 0.0}   \n",
       "674   [-1.621280312538147, -3.200751543045044]  {'False': 0.0, 'True': 1.0}   \n",
       "677   [-6.078128814697266, -8.060128211975098]  {'False': 1.0, 'True': 0.0}   \n",
       "\n",
       "     correct                            absolute_scores  \\\n",
       "1          1   [-7.691727638244629, -7.644883155822754]   \n",
       "4          1   [-4.907443046569824, -6.679103851318359]   \n",
       "13         1   [-4.442530155181885, -6.285279273986816]   \n",
       "14         1  [-3.221273183822632, -3.2224483489990234]   \n",
       "20         1   [-6.161440849304199, -6.881628513336182]   \n",
       "..       ...                                        ...   \n",
       "663        0   [-5.049830436706543, -6.155820846557617]   \n",
       "664        1   [-6.938714504241943, -7.369767665863037]   \n",
       "669        0    [-2.81099534034729, -4.886043548583984]   \n",
       "674        1   [-1.621280312538147, -3.200751543045044]   \n",
       "677        0   [-6.078128814697266, -8.060128211975098]   \n",
       "\n",
       "                               normalized_scores  \\\n",
       "1     [-0.7168436050415039, -0.6699991226196289]   \n",
       "4    [-0.15704679489135742, -1.9287075996398926]   \n",
       "13   [-0.14702367782592773, -1.9897727966308594]   \n",
       "14     [-0.6925597190856934, -0.693734884262085]   \n",
       "20     [-0.3965325355529785, -1.116720199584961]   \n",
       "..                                           ...   \n",
       "663   [-0.2858428955078125, -1.3918333053588867]   \n",
       "664    [-0.500669002532959, -0.9317221641540527]   \n",
       "669  [-0.11827206611633301, -2.1933202743530273]   \n",
       "674  [-0.18737876415252686, -1.7668499946594238]   \n",
       "677   [-0.1290907859802246, -2.1110901832580566]   \n",
       "\n",
       "                                               metrics model_name  \\\n",
       "1    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "4    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "13   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "14   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "20   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "..                                                 ...        ...   \n",
       "663  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "664  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "669  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "674  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "677  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "\n",
       "    model_family              task  shots  n_targets  conf_normalized  \\\n",
       "1      BIG-G T=0  metaphor_boolean      0          2         0.511709   \n",
       "4      BIG-G T=0  metaphor_boolean      0          2         0.854664   \n",
       "13     BIG-G T=0  metaphor_boolean      0          2         0.863274   \n",
       "14     BIG-G T=0  metaphor_boolean      0          2         0.500294   \n",
       "20     BIG-G T=0  metaphor_boolean      0          2         0.672648   \n",
       "..           ...               ...    ...        ...              ...   \n",
       "663    BIG-G T=0  metaphor_boolean      0          2         0.751381   \n",
       "664    BIG-G T=0  metaphor_boolean      0          2         0.606125   \n",
       "669    BIG-G T=0  metaphor_boolean      0          2         0.888454   \n",
       "674    BIG-G T=0  metaphor_boolean      0          2         0.829130   \n",
       "677    BIG-G T=0  metaphor_boolean      0          2         0.878894   \n",
       "\n",
       "     conf_absolute  \n",
       "1         0.000478  \n",
       "4         0.007391  \n",
       "13        0.011766  \n",
       "14        0.039904  \n",
       "20        0.002109  \n",
       "..             ...  \n",
       "663       0.006410  \n",
       "664       0.000970  \n",
       "669       0.060145  \n",
       "674       0.197645  \n",
       "677       0.002292  \n",
       "\n",
       "[136 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_preds = np.array(df.scores.values.tolist())\n",
    "subject_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': 1.0, 'True': 0.0}    76\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 0\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': 0.0, 'True': 1.0}    54\n",
       "{'False': 1.0, 'True': 0.0}     6\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 1\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>asss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct  asss\n",
       "21         0     1\n",
       "102        1     0\n",
       "252        0     1\n",
       "273        0     1\n",
       "288        0     1\n",
       "295        0     1\n",
       "313        0     1\n",
       "330        0     1\n",
       "337        0     1\n",
       "385        1     0\n",
       "389        0     1\n",
       "401        0     1\n",
       "418        0     1\n",
       "427        1     0\n",
       "454        0     1\n",
       "460        0     1\n",
       "466        0     1\n",
       "474        0     1\n",
       "520        0     1\n",
       "553        1     0\n",
       "566        0     1\n",
       "579        0     1\n",
       "627        0     1\n",
       "661        0     1\n",
       "669        0     1\n",
       "677        0     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"logits\"].argmax(axis=1)\n",
    "\n",
    "j = df[\"correct\"].to_frame()\n",
    "j[\"asss\"] = results[\"logits\"].argmax(axis=1)\n",
    "j.query(\"correct != asss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.45391690731048584,\n",
       " 'test_conf_distribution_accuracy': 0.5588235294117647,\n",
       " 'test_conf_distribution_precision': 0.0,\n",
       " 'test_conf_distribution_recall': 0.0,\n",
       " 'test_conf_distribution_f1': 0.0,\n",
       " 'test_conf_distribution_roc_auc': 0.5,\n",
       " 'test_conf_distribution_bs': 0.24653979238754326,\n",
       " 'test_conf_distribution_bs_mcb': 0.0,\n",
       " 'test_conf_distribution_bs_dsc': 0.0,\n",
       " 'test_conf_distribution_bs_unc': 0.24653979238754326,\n",
       " 'test_conf_distribution_balanced_accuracy': 0.5,\n",
       " 'test_conf_absolute_accuracy': 0.5661764705882353,\n",
       " 'test_conf_absolute_precision': 0.6666666666666666,\n",
       " 'test_conf_absolute_recall': 0.03333333333333333,\n",
       " 'test_conf_absolute_f1': 0.06349206349206349,\n",
       " 'test_conf_absolute_roc_auc': 0.437938596491228,\n",
       " 'test_conf_absolute_bs': 0.3965975809972453,\n",
       " 'test_conf_absolute_bs_mcb': 0.15349546252747978,\n",
       " 'test_conf_absolute_bs_dsc': 0.003437673917777745,\n",
       " 'test_conf_absolute_bs_unc': 0.24653979238754326,\n",
       " 'test_conf_absolute_balanced_accuracy': 0.5100877192982456,\n",
       " 'test_conf_normalized_accuracy': 0.4411764705882353,\n",
       " 'test_conf_normalized_precision': 0.4411764705882353,\n",
       " 'test_conf_normalized_recall': 1.0,\n",
       " 'test_conf_normalized_f1': 0.6122448979591837,\n",
       " 'test_conf_normalized_roc_auc': 0.3899122807017544,\n",
       " 'test_conf_normalized_bs': 0.4158962694892523,\n",
       " 'test_conf_normalized_bs_mcb': 0.16935647710170904,\n",
       " 'test_conf_normalized_bs_dsc': 0.0,\n",
       " 'test_conf_normalized_bs_unc': 0.24653979238754326,\n",
       " 'test_conf_normalized_balanced_accuracy': 0.5,\n",
       " 'test_accuracy': 0.8088235294117647,\n",
       " 'test_precision': 0.717948717948718,\n",
       " 'test_recall': 0.9333333333333333,\n",
       " 'test_f1': 0.8115942028985509,\n",
       " 'test_roc_auc': 0.9285087719298246,\n",
       " 'test_bs': 0.14188149611108547,\n",
       " 'test_bs_mcb': 0.04840487469328755,\n",
       " 'test_bs_dsc': 0.15306317096974534,\n",
       " 'test_bs_unc': 0.24653979238754326,\n",
       " 'test_balanced_accuracy': 0.8219298245614035,\n",
       " 'test_runtime': 1.8992,\n",
       " 'test_samples_per_second': 71.61,\n",
       " 'test_steps_per_second': 8.951}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"metrics\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
