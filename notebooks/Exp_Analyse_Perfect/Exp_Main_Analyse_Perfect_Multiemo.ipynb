{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-10 13:48:44][INFO][test/test]: Starting data loading\n",
      "[2023-05-10 13:48:45][INFO][test/test]: Loaded data.\n",
      "[2023-05-10 13:48:45][INFO][pipeline/binarize]: Dropped 0 samples with non-binary correctness\n",
      "[2023-05-10 13:48:45][INFO][pipeline/clean]: Dropped 0 samples with faulty targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'conf-absolute': {'acc': {'test': 0.4898989898989899,\n",
      "                                       'train': 0.5277777777777778},\n",
      "                               'balanced_acc': {'test': 0.5,\n",
      "                                                'train': 0.5026595744680851},\n",
      "                               'bs': {'test': 0.43655752705951795,\n",
      "                                      'train': 0.4071109706958925},\n",
      "                               'bs_dcr': {'test': 0.007012287738669243,\n",
      "                                          'train': 0.004375439260473568},\n",
      "                               'bs_mcb': {'test': 0.1936718452032479,\n",
      "                                          'train': 0.16212409998799546},\n",
      "                               'bs_unc': {'test': 0.2498979695949393,\n",
      "                                          'train': 0.24936230996837064},\n",
      "                               'roc_auc': {'test': 0.5456772481371849,\n",
      "                                           'train': 0.5274844005728314}},\n",
      "             'conf-normalized': {'acc': {'test': 0.5303030303030303,\n",
      "                                         'train': 0.577020202020202},\n",
      "                                 'balanced_acc': {'test': 0.5277636011023783,\n",
      "                                                  'train': 0.5816284779050737},\n",
      "                                 'bs': {'test': 0.2513105924923199,\n",
      "                                        'train': 0.24201302100716487},\n",
      "                                 'bs_dcr': {'test': 0.016126309908645525,\n",
      "                                            'train': 0.015238942629566099},\n",
      "                                 'bs_mcb': {'test': 0.017538932806026142,\n",
      "                                            'train': 0.007889653668360336},\n",
      "                                 'bs_unc': {'test': 0.2498979695949393,\n",
      "                                            'train': 0.24936230996837064},\n",
      "                                 'roc_auc': {'test': 0.5382259875472084,\n",
      "                                             'train': 0.6163563829787234}},\n",
      "             'task-acc': {'test': 0.51010101010101,\n",
      "                          'train': 0.47474747474747475}},\n",
      " 'stats': {'n_instances': {'test': 198, 'train': 792},\n",
      "           'n_instances_nonbinary': {'test': 0, 'train': 0},\n",
      "           'n_tasks': {'test': 1, 'train': 1}}}\n",
      "                                                 input  \\\n",
      "213  Determine whether given opinion is positive, n...   \n",
      "\n",
      "                                       targets  \\\n",
      "213  [ambivalent, positive, negative, neutral]   \n",
      "\n",
      "                                                scores  \\\n",
      "213  [-3.925355911254883, -1.8364641666412354, -1.2...   \n",
      "\n",
      "                                         target_values  correct  \\\n",
      "213  {'ambivalent': 0, 'negative': 1, 'neutral': 0,...        1   \n",
      "\n",
      "                                       absolute_scores  \\\n",
      "213  [-3.925355911254883, -1.8364641666412354, -1.2...   \n",
      "\n",
      "                                     normalized_scores  \\\n",
      "213  [-3.4033539295196533, -1.3144621849060059, -0....   \n",
      "\n",
      "                                               metrics model_name  \\\n",
      "213  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
      "\n",
      "    model_family      task  shots  n_targets  conf_normalized  conf_absolute  \n",
      "213    BIG-G T=0  multiemo      0          4         0.497106       0.294949  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2023-05-10 13:48:54][WARNING][fingerprint/update_fingerprint]: Parameter 'function'=<function tokenize.<locals>.tokenize_function at 0x7f7f8c79b490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e73cb653d64f3f816815497c69ea5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 198\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9/25 00:01 < 00:02, 6.48 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[2023-05-10 13:48:59][INFO][test/test]: Starting tokenization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Determine whether given opinion is positive, negative, neutral or ambivalent in terms of its sentiment.\\nQ: Kurs : Vorlesung Anorganische Chemie II Der Professor ist eine Person, die sich mit Vorlesungen und Seminaren über anorganische Chemie I und II befasst. . ... im Grunde erklärt er während des Unterrichts alles, und für die meisten Klassen hat er Notizen, die den Studenten zur Verfügung stehen. . Der große Nachteil dieses Professors ist leider, dass sich die Vorlesung hauptsächlich auf das Lesen beschränkt. . was zu einer geringen Besucherzahl führt. . . aber ich empfehle generell. . .negativepositiveambivalentneutral\\nA: ', 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/spm.model from cache at /home/wout/.cache/huggingface/transformers/ec748fd4f03d0e5a2d5d56dff01e6dd733f23c67105cd54a9910f9d711870253.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json from cache at /home/wout/.cache/huggingface/transformers/967a4d63eb35950cfd24a9e335906419009f32940fa2ba1b73e7ba032628c38d.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-base/resolve/main/config.json from cache at /home/wout/.cache/huggingface/transformers/e6f9db57345f0f60c9f837fa97bcb27b1ed31e99feb33d732d7d8c80cb8f8459.de97182a9f32a68819030ba8f3f6ff2ba47276be3864425925523202f54cc79c\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "/home/wout/Code/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935e69207e404333ba4e0e0246b7bb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 198\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 198\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# autopep8: off\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "from lass.test import test\n",
    "from lass.log_handling import LogLoaderArgs\n",
    "# autopep8: on\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='[%(asctime)s][%(levelname)s][%(module)s/%(funcName)s]: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    return test(\n",
    "        data_args=LogLoaderArgs(\n",
    "            logdir=\"../artifacts/logs\",\n",
    "            # tasks=\"paper-full\",\n",
    "            tasks=[\"multiemo\"],\n",
    "            model_families=[\"BIG-G T=0\"],\n",
    "            model_sizes=[\"128b\"],\n",
    "            # model_sizes=[\"2m\"],\n",
    "            shots=[0],\n",
    "            query_types=[\"multiple_choice\"],\n",
    "        ),\n",
    "        model_name=\"microsoft/deberta-v3-base\",\n",
    "        split=\"instance\",\n",
    "        model_loc=\"../artifacts/assessors/reference-models/deberta-reference-bs16*2-0sh-instance-split-10241537/checkpoint-4000\",\n",
    "        per_task=True,\n",
    "    )\n",
    "\n",
    "results = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = results[\"test\"] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>targets</th>\n",
       "      <th>scores</th>\n",
       "      <th>target_values</th>\n",
       "      <th>correct</th>\n",
       "      <th>absolute_scores</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>metrics</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_family</th>\n",
       "      <th>task</th>\n",
       "      <th>shots</th>\n",
       "      <th>n_targets</th>\n",
       "      <th>conf_normalized</th>\n",
       "      <th>conf_absolute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-5.28861141204834, -2.8515725135803223, -2.82...</td>\n",
       "      <td>{'ambivalent': 1, 'negative': 0, 'neutral': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.28861141204834, -2.8515725135803223, -2.82...</td>\n",
       "      <td>[-3.391618013381958, -0.9545791149139404, -0.9...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.396049</td>\n",
       "      <td>0.059415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-5.299885272979736, -2.5333571434020996, -1.8...</td>\n",
       "      <td>{'ambivalent': 0, 'negative': 1, 'neutral': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-5.299885272979736, -2.5333571434020996, -1.8...</td>\n",
       "      <td>[-4.04693603515625, -1.2804079055786133, -0.58...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.559738</td>\n",
       "      <td>0.159895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-3.500535011291504, -1.7326862812042236, -1.1...</td>\n",
       "      <td>{'ambivalent': 0, 'negative': 0, 'neutral': 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-3.500535011291504, -1.7326862812042236, -1.1...</td>\n",
       "      <td>[-3.0969667434692383, -1.3291181325912476, -0....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.489936</td>\n",
       "      <td>0.327244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-4.900559425354004, -3.0800068378448486, -2.3...</td>\n",
       "      <td>{'ambivalent': 0, 'negative': 1, 'neutral': 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-4.900559425354004, -3.0800068378448486, -2.3...</td>\n",
       "      <td>[-3.2584879398345947, -1.4379353523254395, -0....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.480212</td>\n",
       "      <td>0.092959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-4.299986839294434, -2.9826583862304688, -2.7...</td>\n",
       "      <td>{'ambivalent': 0, 'negative': 0, 'neutral': 1,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-4.299986839294434, -2.9826583862304688, -2.7...</td>\n",
       "      <td>[-2.6580519676208496, -1.3407236337661743, -1....</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.335319</td>\n",
       "      <td>0.064919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-7.124908924102783, -4.416707515716553, -3.71...</td>\n",
       "      <td>{'ambivalent': 1, 'negative': 0, 'neutral': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-7.124908924102783, -4.416707515716553, -3.71...</td>\n",
       "      <td>[-3.928422451019287, -1.2202210426330566, -0.5...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.595829</td>\n",
       "      <td>0.024373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-8.287440299987793, -5.676698207855225, -5.20...</td>\n",
       "      <td>{'ambivalent': 0, 'negative': 0, 'neutral': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-8.287440299987793, -5.676698207855225, -5.20...</td>\n",
       "      <td>[-3.6665515899658203, -1.055809497833252, -0.5...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.558782</td>\n",
       "      <td>0.005501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-9.446662902832031, -7.795248985290527, -7.00...</td>\n",
       "      <td>{'ambivalent': 0, 'negative': 0, 'neutral': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-9.446662902832031, -7.795248985290527, -7.00...</td>\n",
       "      <td>[-3.05393648147583, -1.4025225639343262, -0.61...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.543050</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-7.332590579986572, -5.246275901794434, -3.36...</td>\n",
       "      <td>{'ambivalent': 0, 'negative': 0, 'neutral': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-7.332590579986572, -5.246275901794434, -3.36...</td>\n",
       "      <td>[-4.396450996398926, -2.310136556625366, -0.42...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>0.034731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Determine whether given opinion is positive, n...</td>\n",
       "      <td>[ambivalent, positive, negative, neutral]</td>\n",
       "      <td>[-8.221808433532715, -5.956296920776367, -4.98...</td>\n",
       "      <td>{'ambivalent': 1, 'negative': 0, 'neutral': 0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-8.221808433532715, -5.956296920776367, -4.98...</td>\n",
       "      <td>[-3.764322280883789, -1.4988107681274414, -0.5...</td>\n",
       "      <td>{'calibration_multiple_choice_brier_score': 0....</td>\n",
       "      <td>128b</td>\n",
       "      <td>BIG-G T=0</td>\n",
       "      <td>multiemo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.590258</td>\n",
       "      <td>0.006842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  \\\n",
       "1    Determine whether given opinion is positive, n...   \n",
       "4    Determine whether given opinion is positive, n...   \n",
       "13   Determine whether given opinion is positive, n...   \n",
       "14   Determine whether given opinion is positive, n...   \n",
       "20   Determine whether given opinion is positive, n...   \n",
       "..                                                 ...   \n",
       "966  Determine whether given opinion is positive, n...   \n",
       "970  Determine whether given opinion is positive, n...   \n",
       "972  Determine whether given opinion is positive, n...   \n",
       "982  Determine whether given opinion is positive, n...   \n",
       "986  Determine whether given opinion is positive, n...   \n",
       "\n",
       "                                       targets  \\\n",
       "1    [ambivalent, positive, negative, neutral]   \n",
       "4    [ambivalent, positive, negative, neutral]   \n",
       "13   [ambivalent, positive, negative, neutral]   \n",
       "14   [ambivalent, positive, negative, neutral]   \n",
       "20   [ambivalent, positive, negative, neutral]   \n",
       "..                                         ...   \n",
       "966  [ambivalent, positive, negative, neutral]   \n",
       "970  [ambivalent, positive, negative, neutral]   \n",
       "972  [ambivalent, positive, negative, neutral]   \n",
       "982  [ambivalent, positive, negative, neutral]   \n",
       "986  [ambivalent, positive, negative, neutral]   \n",
       "\n",
       "                                                scores  \\\n",
       "1    [-5.28861141204834, -2.8515725135803223, -2.82...   \n",
       "4    [-5.299885272979736, -2.5333571434020996, -1.8...   \n",
       "13   [-3.500535011291504, -1.7326862812042236, -1.1...   \n",
       "14   [-4.900559425354004, -3.0800068378448486, -2.3...   \n",
       "20   [-4.299986839294434, -2.9826583862304688, -2.7...   \n",
       "..                                                 ...   \n",
       "966  [-7.124908924102783, -4.416707515716553, -3.71...   \n",
       "970  [-8.287440299987793, -5.676698207855225, -5.20...   \n",
       "972  [-9.446662902832031, -7.795248985290527, -7.00...   \n",
       "982  [-7.332590579986572, -5.246275901794434, -3.36...   \n",
       "986  [-8.221808433532715, -5.956296920776367, -4.98...   \n",
       "\n",
       "                                         target_values  correct  \\\n",
       "1    {'ambivalent': 1, 'negative': 0, 'neutral': 0,...        0   \n",
       "4    {'ambivalent': 0, 'negative': 1, 'neutral': 0,...        1   \n",
       "13   {'ambivalent': 0, 'negative': 0, 'neutral': 1,...        0   \n",
       "14   {'ambivalent': 0, 'negative': 1, 'neutral': 0,...        1   \n",
       "20   {'ambivalent': 0, 'negative': 0, 'neutral': 1,...        1   \n",
       "..                                                 ...      ...   \n",
       "966  {'ambivalent': 1, 'negative': 0, 'neutral': 0,...        0   \n",
       "970  {'ambivalent': 0, 'negative': 0, 'neutral': 0,...        0   \n",
       "972  {'ambivalent': 0, 'negative': 0, 'neutral': 0,...        0   \n",
       "982  {'ambivalent': 0, 'negative': 0, 'neutral': 0,...        0   \n",
       "986  {'ambivalent': 1, 'negative': 0, 'neutral': 0,...        0   \n",
       "\n",
       "                                       absolute_scores  \\\n",
       "1    [-5.28861141204834, -2.8515725135803223, -2.82...   \n",
       "4    [-5.299885272979736, -2.5333571434020996, -1.8...   \n",
       "13   [-3.500535011291504, -1.7326862812042236, -1.1...   \n",
       "14   [-4.900559425354004, -3.0800068378448486, -2.3...   \n",
       "20   [-4.299986839294434, -2.9826583862304688, -2.7...   \n",
       "..                                                 ...   \n",
       "966  [-7.124908924102783, -4.416707515716553, -3.71...   \n",
       "970  [-8.287440299987793, -5.676698207855225, -5.20...   \n",
       "972  [-9.446662902832031, -7.795248985290527, -7.00...   \n",
       "982  [-7.332590579986572, -5.246275901794434, -3.36...   \n",
       "986  [-8.221808433532715, -5.956296920776367, -4.98...   \n",
       "\n",
       "                                     normalized_scores  \\\n",
       "1    [-3.391618013381958, -0.9545791149139404, -0.9...   \n",
       "4    [-4.04693603515625, -1.2804079055786133, -0.58...   \n",
       "13   [-3.0969667434692383, -1.3291181325912476, -0....   \n",
       "14   [-3.2584879398345947, -1.4379353523254395, -0....   \n",
       "20   [-2.6580519676208496, -1.3407236337661743, -1....   \n",
       "..                                                 ...   \n",
       "966  [-3.928422451019287, -1.2202210426330566, -0.5...   \n",
       "970  [-3.6665515899658203, -1.055809497833252, -0.5...   \n",
       "972  [-3.05393648147583, -1.4025225639343262, -0.61...   \n",
       "982  [-4.396450996398926, -2.310136556625366, -0.42...   \n",
       "986  [-3.764322280883789, -1.4988107681274414, -0.5...   \n",
       "\n",
       "                                               metrics model_name  \\\n",
       "1    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "4    {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "13   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "14   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "20   {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "..                                                 ...        ...   \n",
       "966  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "970  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "972  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "982  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "986  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
       "\n",
       "    model_family      task  shots  n_targets  conf_normalized  conf_absolute  \n",
       "1      BIG-G T=0  multiemo      0          4         0.396049       0.059415  \n",
       "4      BIG-G T=0  multiemo      0          4         0.559738       0.159895  \n",
       "13     BIG-G T=0  multiemo      0          4         0.489936       0.327244  \n",
       "14     BIG-G T=0  multiemo      0          4         0.480212       0.092959  \n",
       "20     BIG-G T=0  multiemo      0          4         0.335319       0.064919  \n",
       "..           ...       ...    ...        ...              ...            ...  \n",
       "966    BIG-G T=0  multiemo      0          4         0.595829       0.024373  \n",
       "970    BIG-G T=0  multiemo      0          4         0.558782       0.005501  \n",
       "972    BIG-G T=0  multiemo      0          4         0.543050       0.000909  \n",
       "982    BIG-G T=0  multiemo      0          4         0.654432       0.034731  \n",
       "986    BIG-G T=0  multiemo      0          4         0.590258       0.006842  \n",
       "\n",
       "[198 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 3, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1,\n",
       "       1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_preds = np.array(df.scores.values.tolist())\n",
    "print(np.unique(subject_preds.argmax(axis=1), return_counts=True))\n",
    "subject_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target_values.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ambivalent': 0, 'negative': 0, 'neutral': 0, 'positive': 1}    35\n",
       "{'ambivalent': 0, 'negative': 0, 'neutral': 1, 'positive': 0}    32\n",
       "{'ambivalent': 1, 'negative': 0, 'neutral': 0, 'positive': 0}    26\n",
       "{'ambivalent': 0, 'negative': 1, 'neutral': 0, 'positive': 0}     4\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 0\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ambivalent': 0, 'negative': 1, 'neutral': 0, 'positive': 0}    71\n",
       "{'ambivalent': 0, 'negative': 0, 'neutral': 0, 'positive': 1}    29\n",
       "{'ambivalent': 0, 'negative': 0, 'neutral': 1, 'positive': 0}     1\n",
       "Name: target_values, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"correct == 1\").target_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>asss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     correct  asss\n",
       "1          0     1\n",
       "4          1     0\n",
       "62         0     1\n",
       "85         0     1\n",
       "95         0     1\n",
       "105        0     1\n",
       "106        0     1\n",
       "128        0     1\n",
       "159        0     1\n",
       "160        0     1\n",
       "166        0     1\n",
       "170        0     1\n",
       "187        0     1\n",
       "191        0     1\n",
       "200        0     1\n",
       "201        0     1\n",
       "216        0     1\n",
       "230        0     1\n",
       "240        0     1\n",
       "313        0     1\n",
       "330        0     1\n",
       "343        0     1\n",
       "366        0     1\n",
       "372        0     1\n",
       "385        0     1\n",
       "406        1     0\n",
       "413        1     0\n",
       "461        0     1\n",
       "502        0     1\n",
       "561        0     1\n",
       "566        0     1\n",
       "600        0     1\n",
       "663        0     1\n",
       "686        0     1\n",
       "698        0     1\n",
       "702        0     1\n",
       "725        0     1\n",
       "726        0     1\n",
       "768        0     1\n",
       "794        0     1\n",
       "805        1     0\n",
       "856        0     1\n",
       "862        0     1\n",
       "864        0     1\n",
       "875        0     1\n",
       "880        0     1\n",
       "897        0     1\n",
       "952        0     1\n",
       "955        0     1\n",
       "972        0     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"logits\"].argmax(axis=1)\n",
    "\n",
    "j = df[\"correct\"].to_frame()\n",
    "j[\"asss\"] = results[\"logits\"].argmax(axis=1)\n",
    "j.query(\"correct != asss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5563997030258179,\n",
       " 'test_conf_distribution_accuracy': 0.51010101010101,\n",
       " 'test_conf_distribution_precision': 0.51010101010101,\n",
       " 'test_conf_distribution_recall': 1.0,\n",
       " 'test_conf_distribution_f1': 0.6755852842809364,\n",
       " 'test_conf_distribution_roc_auc': 0.5,\n",
       " 'test_conf_distribution_bs': 0.2498979695949393,\n",
       " 'test_conf_distribution_bs_mcb': 0.0,\n",
       " 'test_conf_distribution_bs_dsc': 0.0,\n",
       " 'test_conf_distribution_bs_unc': 0.2498979695949393,\n",
       " 'test_conf_distribution_balanced_accuracy': 0.5,\n",
       " 'test_conf_absolute_accuracy': 0.4898989898989899,\n",
       " 'test_conf_absolute_precision': 0.0,\n",
       " 'test_conf_absolute_recall': 0.0,\n",
       " 'test_conf_absolute_f1': 0.0,\n",
       " 'test_conf_absolute_roc_auc': 0.5456772481371849,\n",
       " 'test_conf_absolute_bs': 0.43655752705951795,\n",
       " 'test_conf_absolute_bs_mcb': 0.1936718452032479,\n",
       " 'test_conf_absolute_bs_dsc': 0.007012287738669243,\n",
       " 'test_conf_absolute_bs_unc': 0.2498979695949393,\n",
       " 'test_conf_absolute_balanced_accuracy': 0.5,\n",
       " 'test_conf_normalized_accuracy': 0.5303030303030303,\n",
       " 'test_conf_normalized_precision': 0.532258064516129,\n",
       " 'test_conf_normalized_recall': 0.6534653465346535,\n",
       " 'test_conf_normalized_f1': 0.5866666666666667,\n",
       " 'test_conf_normalized_roc_auc': 0.5382259875472084,\n",
       " 'test_conf_normalized_bs': 0.2513105924923199,\n",
       " 'test_conf_normalized_bs_mcb': 0.017538932806026142,\n",
       " 'test_conf_normalized_bs_dsc': 0.016126309908645525,\n",
       " 'test_conf_normalized_bs_unc': 0.2498979695949393,\n",
       " 'test_conf_normalized_balanced_accuracy': 0.5277636011023783,\n",
       " 'test_accuracy': 0.7474747474747475,\n",
       " 'test_precision': 0.6783216783216783,\n",
       " 'test_recall': 0.9603960396039604,\n",
       " 'test_f1': 0.7950819672131149,\n",
       " 'test_roc_auc': 0.8500561396345819,\n",
       " 'test_bs': 0.18573060443951156,\n",
       " 'test_bs_mcb': 0.04702305992729314,\n",
       " 'test_bs_dsc': 0.11119042508272087,\n",
       " 'test_bs_unc': 0.2498979695949393,\n",
       " 'test_balanced_accuracy': 0.7430846177401245,\n",
       " 'test_runtime': 3.9594,\n",
       " 'test_samples_per_second': 50.007,\n",
       " 'test_steps_per_second': 6.314}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"metrics\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
