{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a9b4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T16:38:08.697403Z",
     "iopub.status.busy": "2022-08-25T16:38:08.696703Z",
     "iopub.status.idle": "2022-08-25T16:38:08.722405Z",
     "shell.execute_reply": "2022-08-25T16:38:08.721569Z"
    },
    "papermill": {
     "duration": 0.036619,
     "end_time": "2022-08-25T16:38:08.725516",
     "exception": false,
     "start_time": "2022-08-25T16:38:08.688897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4f3bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T16:38:08.733208Z",
     "iopub.status.busy": "2022-08-25T16:38:08.732776Z",
     "iopub.status.idle": "2022-08-25T16:38:12.982243Z",
     "shell.execute_reply": "2022-08-25T16:38:12.981419Z"
    },
    "papermill": {
     "duration": 4.256514,
     "end_time": "2022-08-25T16:38:12.985272",
     "exception": false,
     "start_time": "2022-08-25T16:38:08.728758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from dataclasses import dataclass\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import lass.train\n",
    "import lass.test\n",
    "import lass.datasets\n",
    "from lass.log_handling import PaperTasks, LogIssues, LoaderArgs, LogLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a848adaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T16:38:12.990359Z",
     "iopub.status.busy": "2022-08-25T16:38:12.989499Z",
     "iopub.status.idle": "2022-08-25T16:38:13.027411Z",
     "shell.execute_reply": "2022-08-25T16:38:13.026202Z"
    },
    "papermill": {
     "duration": 0.043274,
     "end_time": "2022-08-25T16:38:13.030112",
     "exception": false,
     "start_time": "2022-08-25T16:38:12.986838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Architecture():\n",
    "    name: str\n",
    "    name_short: str\n",
    "    batch_size: int\n",
    "    gradient_accumulation_steps: int\n",
    "\n",
    "# architecture = Architecture(\n",
    "#     name=\"albert-base-v2\",\n",
    "#     name_short=\"albert\",\n",
    "#     batch_size=32,\n",
    "#     gradient_accumulation_steps=1,\n",
    "# )\n",
    "\n",
    "architecture = Architecture(\n",
    "    name=\"microsoft/deberta-v3-base\",\n",
    "    name_short=\"deberta\",\n",
    "    batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51db55b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-25T16:38:13.036938Z",
     "iopub.status.busy": "2022-08-25T16:38:13.036475Z"
    },
    "papermill": {
     "duration": 8.413121,
     "end_time": "2022-08-25T16:38:21.445787",
     "exception": false,
     "start_time": "2022-08-25T16:38:13.032666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader_args = LoaderArgs(\n",
    "    logdir=\"../artifacts/logs\",\n",
    "    tasks='paper-full',\n",
    "    model_families=[\"BIG-G T=0\"],\n",
    "    model_sizes=[\"128b\"],\n",
    "    shots=[0],\n",
    "    query_types=[\"multiple_choice\"],\n",
    ")\n",
    "\n",
    "loader = LogLoader.from_args(loader_args)\n",
    "data = lass.datasets.to_dataframe(loader)\n",
    "nonempty_tasks = data.task.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26197fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = [task for task in PaperTasks.full() if task in nonempty_tasks]\n",
    "assert \"ascii_word_recognition\" not in tasks\n",
    "\n",
    "results: Dict[str, Dict[str, Any]]=  {} # Dict[task, Dict[metric, value]]\n",
    "for i, task in enumerate(tasks):\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(f\"Task: {task} ({i+1}/{len(tasks)})\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "\n",
    "    model = lass.train.train(\n",
    "        data_args=LoaderArgs(**(loader_args.__dict__ | {'tasks': [task]})),\n",
    "        group=\"task-level-assessors\",\n",
    "        split=\"instance\",\n",
    "        model_name=architecture.name,\n",
    "        model_name_short=f\"{task}-{architecture.name_short}\",\n",
    "        batch_size=architecture.batch_size,\n",
    "        gradient_accumulation_steps=architecture.gradient_accumulation_steps,\n",
    "        include_model_in_input=False,\n",
    "        include_n_targets_in_input=False,\n",
    "        output_dir=f\"task-level-assessors/{task}\",\n",
    "        n_epochs=6,\n",
    "        extra_training_args={\n",
    "            \"evaluation_strategy\": \"epoch\",\n",
    "            \"save_strategy\": \"epoch\",\n",
    "            \"logging_strategy\": \"epoch\",\n",
    "            \"learning_rate\": 2e-5,\n",
    "        },\n",
    "        # is_test_run=True,\n",
    "    )\n",
    "\n",
    "    results_ = lass.test.test(\n",
    "        data_args=loader_args,\n",
    "        split = 'instance',\n",
    "        model_loc=model,\n",
    "        model_name=architecture.name,\n",
    "        max_sequence_length = 512,\n",
    "    )\n",
    "    results[task] = results_['metrics']\n",
    "    results[task]['count'] = len(results_['test'])\n",
    "\n",
    "    df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    df.to_csv(\"task-level-assessors.csv\")\n",
    "\n",
    "    shutil.rmtree(f\"task-level-assessors/{task}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.170488,
   "end_time": "2022-08-25T16:38:22.968966",
   "environment_variables": {},
   "exception": null,
   "input_path": "Task_Specific_Assessors.ipynb",
   "output_path": "Task_Specific_Assessors.ipynb",
   "parameters": {},
   "start_time": "2022-08-25T16:38:07.798478",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "eed4bfcf3d3cfcdb00482c10052e8eba5705b015008b357326d56e176b5397df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
