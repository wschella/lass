{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.special as sc_special\n",
    "import sklearn.metrics as sk_metrics\n",
    "\n",
    "import lass.datasets\n",
    "import lass.metrics\n",
    "import lass.metrics.brier\n",
    "import lass.test\n",
    "from lass.train import DataArgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'conf-absolute': {'acc': {'test': 0.709478021978022,\n",
      "                                       'train': 0.7687121918921359},\n",
      "                               'balanced_acc': {'test': 0.5016260777979034,\n",
      "                                                'train': 0.5104928543475661},\n",
      "                               'bs': {'test': 0.2584431138604377,\n",
      "                                      'train': 0.20531002639072962},\n",
      "                               'bs_dcr': {'test': 0.0010234770416069072,\n",
      "                                          'train': 0.022187596321620484},\n",
      "                               'bs_mcb': {'test': 0.05341959820981243,\n",
      "                                          'train': 0.05130582405729314},\n",
      "                               'bs_unc': {'test': 0.2060469926922322,\n",
      "                                          'train': 0.17619179865505696},\n",
      "                               'roc_auc': {'test': 0.491734003176178,\n",
      "                                           'train': 0.6941526913276941}},\n",
      "             'conf-normalized': {'acc': {'test': 0.4730425824175824,\n",
      "                                         'train': 0.34807536039967496},\n",
      "                                 'balanced_acc': {'test': 0.5886251390239641,\n",
      "                                                  'train': 0.5242482272343117},\n",
      "                                 'bs': {'test': 0.3769166466999366,\n",
      "                                        'train': 0.48396939464548094},\n",
      "                                 'bs_dcr': {'test': 0.007168054146896419,\n",
      "                                            'train': 0.0019219642329411368},\n",
      "                                 'bs_mcb': {'test': 0.1780377081546008,\n",
      "                                            'train': 0.3096995602233651},\n",
      "                                 'bs_unc': {'test': 0.2060469926922322,\n",
      "                                            'train': 0.17619179865505696},\n",
      "                                 'roc_auc': {'test': 0.5605052037494296,\n",
      "                                             'train': 0.42618851032719157}},\n",
      "             'task-acc': {'test': 0.29035027472527475,\n",
      "                          'train': 0.2283233514912571}},\n",
      " 'stats': {'n_instances': {'test': 11648, 'train': 66454},\n",
      "           'n_instances_nonbinary': {'test': 237, 'train': 136},\n",
      "           'n_tasks': {'test': 24, 'train': 95}}}\n",
      "                                                  input    targets  \\\n",
      "1023   N_TARGETS: 2  \\nDuring the Allied bombardment...  [Yes, No]   \n",
      "\n",
      "                                          scores        target_values  \\\n",
      "1023  [-3.8605194091796875, -5.1205034255981445]  {'No': 1, 'Yes': 0}   \n",
      "\n",
      "      correct                             absolute_scores  \\\n",
      "1023      0.0  [-3.8605194091796875, -5.1205034255981445]   \n",
      "\n",
      "                                normalized_scores  \\\n",
      "1023  [-0.24971413612365723, -1.5096981525421143]   \n",
      "\n",
      "                                                metrics model_name  \\\n",
      "1023  {'calibration_multiple_choice_brier_score': 0....       128b   \n",
      "\n",
      "     model_family          task  shots  n_targets  \n",
      "1023    BIG-G T=0  anachronisms      0          2  \n",
      "{'text': ' N_TARGETS: 2  \\nDuring the Allied bombardment of the beaches of Iwo Jima, Ralph spoke loudly into his radio.\\nDoes the preceding sentence contain non-contemporaneous (anachronistic) elements?\\n', 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/wout/pp/lass/.env/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "WARNING:datasets.fingerprint:Parameter 'function'=<function test.<locals>.tokenize_function at 0x7fa49b77ae60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597e3a404e404c9f8bcb9c31d36e4814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c441d7aed91431d8b9d6caf1e9174f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 11648\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1456' max='1456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1456/1456 02:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_loc = \"../artifacts/assessors/deberta-nt-bs16*2-0sh-instance-split-07120027/checkpoint-8000\"\n",
    "# model_loc = \"./deberta-nt-better-split-bs16*2-0sh-instance-split-07141059/checkpoint-9000\"\n",
    "model_loc = \"../artifacts/assessors/deberta-nt-bs16*2-0sh-task-split-07121735/checkpoint-2000\"\n",
    "\n",
    "results = lass.test.test(\n",
    "    data_args=DataArgs(\n",
    "        logdir=\"../artifacts/logs\",\n",
    "        tasks=\"paper-full\",\n",
    "        model_families=[\"BIG-G T=0\"],\n",
    "        model_sizes=[\"128b\"],\n",
    "        shots=[0],\n",
    "        query_types=[\"multiple_choice\"],\n",
    "    ),\n",
    "    # split = 'instance',\n",
    "    split = 'task',\n",
    "    model_loc=model_loc,\n",
    "    model_name = \"microsoft/deberta-v3-base\",\n",
    "    max_sequence_length = 512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = results[\"data\"]\n",
    "train = results[\"train\"]\n",
    "test = results[\"test\"]\n",
    "logits = results[\"logits\"]\n",
    "labels = results[\"labels\"]\n",
    "metrics = results[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2647375/1761386809.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['n_targets'] = test['targets'].map(lambda x: len(x))\n",
      "/tmp/ipykernel_2647375/1761386809.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['conf_normalized'] = test['normalized_scores'].map(lambda s: math.exp(np.max(s)))\n",
      "/tmp/ipykernel_2647375/1761386809.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['conf_absolute']= test['absolute_scores'].map(lambda s: math.exp(np.max(s)))\n"
     ]
    }
   ],
   "source": [
    "data['n_targets'] = data['targets'].map(lambda x: len(x))\n",
    "data['conf_normalized'] = data['normalized_scores'].map(lambda s: math.exp(np.max(s)))\n",
    "data['conf_absolute']= data['absolute_scores'].map(lambda s: math.exp(np.max(s)))\n",
    "test['n_targets'] = test['targets'].map(lambda x: len(x))\n",
    "test['conf_normalized'] = test['normalized_scores'].map(lambda s: math.exp(np.max(s)))\n",
    "test['conf_absolute']= test['absolute_scores'].map(lambda s: math.exp(np.max(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.5579606890678406, 'test_accuracy': 0.7206387362637363, 'test_precision': 0.7025316455696202, 'test_recall': 0.06564163217031342, 'test_f1': 0.12006489994591671, 'test_roc_auc': 0.712437953424164, 'test_bs': 0.18547732043134132, 'test_bs_mcb': 0.005516429596843314, 'test_bs_dsc': 0.02608610185773419, 'test_bs_unc': 0.2060469926922322, 'test_balanced_accuracy': 0.5271348736704459, 'test_runtime': 165.6678, 'test_samples_per_second': 70.309, 'test_steps_per_second': 8.789}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3852105 , 0.41795602, 0.41615838, ..., 0.3538577 , 0.3846273 ,\n",
       "       0.22022294], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics)\n",
    "predictions = np.argmax(logits, axis=-1)\n",
    "confs = sc_special.softmax(logits, axis=-1)[:, -1]\n",
    "confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test['correct'].isin([0.0, 1.0])].copy()\n",
    "test['assr'] = confs\n",
    "test.to_csv(f\"ilr_{model_loc.split('/')[-2]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pandas.read_csv(f\"ilr_{model_loc.split('/')[-2]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout, HBox\n",
    "\n",
    "def scrollwrap(df):\n",
    "    b=widgets.HTML(\n",
    "        value=df.to_html(escape=False),\n",
    "        disabled=True\n",
    "    )\n",
    "    return HBox([b], layout=Layout(height='300px', overflow_y='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f5c1a9654c432d8a0842b1b8889d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\"â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def aggr(group):\n",
    "    if len(group) == 1:\n",
    "        return None\n",
    "        # return pd.Series({'count': 1})\n",
    "\n",
    "    bs, mcb, dsc, unc = lass.metrics.brier.brier_score(group['correct'], group['assr'])\n",
    "    accuracy = sk_metrics.accuracy_score(group['correct'], group['assr'] > 0.5)\n",
    "    try:\n",
    "        roc_auc = sk_metrics.roc_auc_score(group['correct'], group['assr']),\n",
    "        lm_roc_auc = sk_metrics.roc_auc_score(group['correct'], group['conf_normalized']),\n",
    "    except ValueError:\n",
    "        roc_auc = None\n",
    "        lm_roc_auc = None\n",
    "    return pd.Series({\n",
    "        'bs': bs, \n",
    "        'mcb': mcb,\n",
    "        'dsc': dsc, \n",
    "        'unc': unc,\n",
    "        'roc_auc': roc_auc[0] if roc_auc is not None else None,\n",
    "        'lm_roc_auc': lm_roc_auc[0] if lm_roc_auc is not None else None,\n",
    "        'task_accuracy': group['correct'].mean(),\n",
    "        'accuracy': accuracy,\n",
    "        'count': len(group),\n",
    "    })\n",
    "\n",
    "task_perf = test.groupby('task').apply(aggr).reset_index()\n",
    "task_perf['acc_improvement'] = task_perf.apply(lambda r: r['accuracy'] - max(r['task_accuracy'], 1-r['task_accuracy']), axis=1)\n",
    "task_perf.to_csv(f\"ilr_{model_loc.split('/')[-2]}_task_perf.csv\")\n",
    "\n",
    "scrollwrap(task_perf\n",
    "    # .query('count > 10')\n",
    "    .sort_values(by='acc_improvement', ascending=False))\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eed4bfcf3d3cfcdb00482c10052e8eba5705b015008b357326d56e176b5397df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
