{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-level Performance Quantification\n",
    "\n",
    "This notebook analyses the utility of assessors for predicting performance at the task level by aggregating instance level predictions, i.e. it does a predict-then-count quantization. We compare to using the models self-assessed confidence and just using the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't find a directory or a metric named 'roc_auc' in this version. It was picked from the master branch on github instead.\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "from transformers.models.auto.modeling_auto import AutoModelForSequenceClassification\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "from transformers.trainer import Trainer\n",
    "import scipy.special as sc_special\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bigbench.api.results as bb\n",
    "\n",
    "from lass.log_handling import LogLoader\n",
    "from lass.datasets import split_task_level, huggingfaceify\n",
    "import lass\n",
    "import lass.metrics.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = (LogLoader(logdir = Path('../artifacts/logs'))\n",
    "        .with_tasks('paper-full')\n",
    "        .with_model_families(['BIG-G T=0'])\n",
    "        .with_model_sizes(['128b'])\n",
    "        .with_shots([0])\n",
    "        .with_query_types([bb.MultipleChoiceQuery])\n",
    ")\n",
    "\n",
    "_train, test = split_task_level(loader, seed=42, test_fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "dataset = huggingfaceify(_train[:1], test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb0f81c7b3642858c6770ab73880938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa417cd469bc477588348268f59dd807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `AlbertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `AlbertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 8986\n",
      "  Batch size = 8\n",
      "/home/wout/pp/lass/.env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_error() # type: ignore\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../artifacts/assessors/albert-bs32-0sh-task-split/checkpoint-1500\")\n",
    "\n",
    "# Tokenize according to specific model tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"np\")\n",
    "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Dummy Trainer for easy batched predictions\n",
    "dummy_trainer = Trainer(model=model)\n",
    "\n",
    "predictions, labels, metrics = dummy_trainer.predict(tokenized_datasets['test']) #type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assr_conf</th>\n",
       "      <th>lm_conf_normalized</th>\n",
       "      <th>lm_conf_absolute</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cause_and_effect</th>\n",
       "      <td>0.430424</td>\n",
       "      <td>0.850228</td>\n",
       "      <td>0.115619</td>\n",
       "      <td>0.673203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkmate_in_one</th>\n",
       "      <td>0.182302</td>\n",
       "      <td>0.586714</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cifar10_classification</th>\n",
       "      <td>0.183313</td>\n",
       "      <td>0.390550</td>\n",
       "      <td>0.211644</td>\n",
       "      <td>0.101562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common_morpheme</th>\n",
       "      <td>0.307563</td>\n",
       "      <td>0.744003</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryobiology_spanish</th>\n",
       "      <td>0.389640</td>\n",
       "      <td>0.803192</td>\n",
       "      <td>0.119684</td>\n",
       "      <td>0.636986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs_algorithms</th>\n",
       "      <td>0.445052</td>\n",
       "      <td>0.587033</td>\n",
       "      <td>0.070153</td>\n",
       "      <td>0.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emoji_movie</th>\n",
       "      <td>0.370966</td>\n",
       "      <td>0.549358</td>\n",
       "      <td>0.131002</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emojis_emotion_prediction</th>\n",
       "      <td>0.292092</td>\n",
       "      <td>0.331735</td>\n",
       "      <td>0.118214</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_russian_proverbs</th>\n",
       "      <td>0.315421</td>\n",
       "      <td>0.773879</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhh_alignment</th>\n",
       "      <td>0.494786</td>\n",
       "      <td>0.979555</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.434389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hindu_knowledge</th>\n",
       "      <td>0.441106</td>\n",
       "      <td>0.596753</td>\n",
       "      <td>0.380474</td>\n",
       "      <td>0.405714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_value_maps</th>\n",
       "      <td>0.235083</td>\n",
       "      <td>0.798790</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>0.495050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logical_args</th>\n",
       "      <td>0.391231</td>\n",
       "      <td>0.635667</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>navigate</th>\n",
       "      <td>0.372834</td>\n",
       "      <td>0.838529</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>novel_concepts</th>\n",
       "      <td>0.427040</td>\n",
       "      <td>0.704838</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odd_one_out</th>\n",
       "      <td>0.484531</td>\n",
       "      <td>0.420937</td>\n",
       "      <td>0.219706</td>\n",
       "      <td>0.313953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penguins_in_a_table</th>\n",
       "      <td>0.199874</td>\n",
       "      <td>0.509035</td>\n",
       "      <td>0.301450</td>\n",
       "      <td>0.302013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persian_idioms</th>\n",
       "      <td>0.298916</td>\n",
       "      <td>0.704365</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_ambiguity</th>\n",
       "      <td>0.516126</td>\n",
       "      <td>0.613621</td>\n",
       "      <td>0.021586</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategyqa</th>\n",
       "      <td>0.514017</td>\n",
       "      <td>0.660308</td>\n",
       "      <td>0.234131</td>\n",
       "      <td>0.606445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timedial</th>\n",
       "      <td>0.381708</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>0.413086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitaminc_fact_verification</th>\n",
       "      <td>0.433118</td>\n",
       "      <td>0.943378</td>\n",
       "      <td>0.047854</td>\n",
       "      <td>0.120117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which_wiki_edit</th>\n",
       "      <td>0.336200</td>\n",
       "      <td>0.796809</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.259194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            assr_conf  lm_conf_normalized  lm_conf_absolute  \\\n",
       "task                                                                          \n",
       "cause_and_effect             0.430424            0.850228          0.115619   \n",
       "checkmate_in_one             0.182302            0.586714          0.000016   \n",
       "cifar10_classification       0.183313            0.390550          0.211644   \n",
       "common_morpheme              0.307563            0.744003          0.006946   \n",
       "cryobiology_spanish          0.389640            0.803192          0.119684   \n",
       "cs_algorithms                0.445052            0.587033          0.070153   \n",
       "emoji_movie                  0.370966            0.549358          0.131002   \n",
       "emojis_emotion_prediction    0.292092            0.331735          0.118214   \n",
       "english_russian_proverbs     0.315421            0.773879          0.010380   \n",
       "hhh_alignment                0.494786            0.979555          0.002842   \n",
       "hindu_knowledge              0.441106            0.596753          0.380474   \n",
       "key_value_maps               0.235083            0.798790          0.196507   \n",
       "logical_args                 0.391231            0.635667          0.012324   \n",
       "navigate                     0.372834            0.838529          0.001295   \n",
       "novel_concepts               0.427040            0.704838          0.000768   \n",
       "odd_one_out                  0.484531            0.420937          0.219706   \n",
       "penguins_in_a_table          0.199874            0.509035          0.301450   \n",
       "persian_idioms               0.298916            0.704365          0.004988   \n",
       "sentence_ambiguity           0.516126            0.613621          0.021586   \n",
       "strategyqa                   0.514017            0.660308          0.234131   \n",
       "timedial                     0.381708            0.702445          0.015406   \n",
       "vitaminc_fact_verification   0.433118            0.943378          0.047854   \n",
       "which_wiki_edit              0.336200            0.796809          0.001160   \n",
       "\n",
       "                             correct  \n",
       "task                                  \n",
       "cause_and_effect            0.673203  \n",
       "checkmate_in_one            0.004883  \n",
       "cifar10_classification      0.101562  \n",
       "common_morpheme             0.320000  \n",
       "cryobiology_spanish         0.636986  \n",
       "cs_algorithms               0.296875  \n",
       "emoji_movie                 0.320000  \n",
       "emojis_emotion_prediction   0.250000  \n",
       "english_russian_proverbs    0.300000  \n",
       "hhh_alignment               0.434389  \n",
       "hindu_knowledge             0.405714  \n",
       "key_value_maps              0.495050  \n",
       "logical_args                0.406250  \n",
       "navigate                    0.500000  \n",
       "novel_concepts              0.312500  \n",
       "odd_one_out                 0.313953  \n",
       "penguins_in_a_table         0.302013  \n",
       "persian_idioms              0.303030  \n",
       "sentence_ambiguity          0.616667  \n",
       "strategyqa                  0.606445  \n",
       "timedial                    0.413086  \n",
       "vitaminc_fact_verification  0.120117  \n",
       "which_wiki_edit             0.259194  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test.copy()\n",
    "df = df[df['correct'].isin([0.0, 1.0])]\n",
    "\n",
    "df['assr_conf']= sc_special.softmax(predictions, axis=-1)[:, -1] # Softmax and take success prob\n",
    "df['lm_conf_normalized'] = df.apply(lambda row: math.exp(np.max(row['normalized_scores'])), axis=1)\n",
    "df['lm_conf_absolute'] = df.apply(lambda row: math.exp(np.max(row['absolute_scores'])), axis=1)\n",
    "\n",
    "# Group by task\n",
    "perfs = df.groupby('task').agg({\n",
    "    'assr_conf': 'mean',\n",
    "    'lm_conf_normalized': 'mean',\n",
    "    'lm_conf_absolute': 'mean',\n",
    "    'correct': 'mean'\n",
    "})\n",
    "perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mse(confs):\n",
    "    return (perfs['correct'] - confs)**2\n",
    "\n",
    "def me(confs):\n",
    "    return abs(perfs['correct'] - confs)\n",
    "\n",
    "bp = plt.boxplot([\n",
    "    me(perfs['assr_conf']), \n",
    "    me(perfs['lm_conf_normalized']), \n",
    "    me(perfs['lm_conf_absolute']),\n",
    "    me(_train['correct'].mean())\n",
    "], labels=[\n",
    "    'Assr',\n",
    "    'LM (normalized)', \n",
    "    'LM (absolute)',\n",
    "    'mean'\n",
    "],\n",
    "    showbox=False, widths=0.5, showfliers=False\n",
    ")\n",
    "\n",
    "jitter = [np.random.normal(1+i, 0.07, size=len(perfs)) for i in range(0,4)]\n",
    "_ = plt.plot(\n",
    "    jitter,\n",
    "    [me(perfs['assr_conf']), me(perfs['lm_conf_normalized']), me(perfs['lm_conf_absolute']), me(_train['correct'].mean())],\n",
    "     'r+', alpha=0.4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5915863078715249, 0.002946078092444128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mse</th>\n",
       "      <th>me</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assr</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.109654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lm_normalized</td>\n",
       "      <td>0.132380</td>\n",
       "      <td>0.310256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lm_absolute</td>\n",
       "      <td>0.107586</td>\n",
       "      <td>0.277736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.028601</td>\n",
       "      <td>0.130851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name       mse        me\n",
       "0           assr  0.019569  0.109654\n",
       "1  lm_normalized  0.132380  0.310256\n",
       "2    lm_absolute  0.107586  0.277736\n",
       "3           mean  0.028601  0.130851"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(pearsonr(me(perfs['assr_conf']),  me(_train['correct'].mean())))\n",
    "\n",
    "pd.DataFrame([{\n",
    "    'name': 'assr',\n",
    "    'mse': mse(perfs['assr_conf']).mean(),\n",
    "    'me': me(perfs['assr_conf']).mean(),\n",
    "}, {\n",
    "    'name': 'lm_normalized',\n",
    "    'mse': mse(perfs['lm_conf_normalized']).mean(),\n",
    "    'me': me(perfs['lm_conf_normalized']).mean(),\n",
    "}, {\n",
    "    'name': 'lm_absolute',\n",
    "    'mse': mse(perfs['lm_conf_absolute']).mean(),\n",
    "    'me': me(perfs['lm_conf_absolute']).mean(),\n",
    "}, {\n",
    "    'name': 'mean',\n",
    "    'mse': mse(_train['correct'].mean()).mean(),\n",
    "    'me': me(_train['correct'].mean()).mean(),\n",
    "}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eed4bfcf3d3cfcdb00482c10052e8eba5705b015008b357326d56e176b5397df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
