{
  "anachronisms": {
    "test_loss": 0.6931437849998474,
    "test_accuracy": 0.5652173913043478,
    "test_roc_auc": 0.6136363636363636,
    "test_runtime": 1.469,
    "test_samples_per_second": 31.313,
    "test_steps_per_second": 31.313,
    "instance_count": 46
  },
  "analogical_similarity": {
    "test_loss": 1.945885419845581,
    "test_accuracy": 0.12307692307692308,
    "test_roc_auc": 0.5,
    "test_runtime": 4.7094,
    "test_samples_per_second": 13.802,
    "test_steps_per_second": 13.802,
    "instance_count": 65
  },
  "analytic_entailment": {
    "test_loss": 0.6930708885192871,
    "test_accuracy": 0.7142857142857143,
    "test_roc_auc": 0.7291666666666667,
    "test_runtime": 0.4579,
    "test_samples_per_second": 30.575,
    "test_steps_per_second": 30.575,
    "instance_count": 14
  },
  "authorship_verification": {
    "test_loss": 0.6932060122489929,
    "test_accuracy": 0.5170454545454546,
    "test_roc_auc": 0.48326414115204985,
    "test_runtime": 5.6287,
    "test_samples_per_second": 31.268,
    "test_steps_per_second": 31.268,
    "instance_count": 176
  },
  "bbq_lite_json": {
    "test_loss": 1.0986149311065674,
    "test_accuracy": 0.3465346534653465,
    "test_roc_auc": 0.48110606053643196,
    "test_runtime": 7.9029,
    "test_samples_per_second": 25.56,
    "test_steps_per_second": 25.56,
    "instance_count": 202
  },
  "causal_judgment": {
    "test_loss": 0.6931549310684204,
    "test_accuracy": 0.5,
    "test_roc_auc": 0.5015384615384615,
    "test_runtime": 1.2295,
    "test_samples_per_second": 30.908,
    "test_steps_per_second": 30.908,
    "instance_count": 38
  },
  "cause_and_effect": {
    "test_loss": 0.6931382417678833,
    "test_accuracy": 0.6451612903225806,
    "test_roc_auc": NaN,
    "test_runtime": 0.983,
    "test_samples_per_second": 31.537,
    "test_steps_per_second": 31.537,
    "instance_count": 31
  },
  "cifar10_classification": {
    "test_loss": 2.3025882244110107,
    "test_accuracy": 0.07804878048780488,
    "test_roc_auc": 0.4769868698706446,
    "test_runtime": 19.8389,
    "test_samples_per_second": 10.333,
    "test_steps_per_second": 10.333,
    "instance_count": 205
  },
  "color": {
    "test_loss": 2.3025355339050293,
    "test_accuracy": 0.13170731707317074,
    "test_roc_auc": 0.4777117349633153,
    "test_runtime": 19.6425,
    "test_samples_per_second": 10.437,
    "test_steps_per_second": 10.437,
    "instance_count": 205
  },
  "common_morpheme": {
    "test_loss": 1.3861777782440186,
    "test_accuracy": 0.8,
    "test_roc_auc": 0.828888888888889,
    "test_runtime": 0.4962,
    "test_samples_per_second": 20.153,
    "test_steps_per_second": 20.153,
    "instance_count": 10
  },
  "conceptual_combinations": {
    "test_loss": 1.386332392692566,
    "test_accuracy": 0.2857142857142857,
    "test_roc_auc": NaN,
    "test_runtime": 1.0096,
    "test_samples_per_second": 20.8,
    "test_steps_per_second": 20.8,
    "instance_count": 21
  },
  "crash_blossom": {
    "test_loss": 1.3863662481307983,
    "test_accuracy": 0.0,
    "test_roc_auc": NaN,
    "test_runtime": 0.3978,
    "test_samples_per_second": 20.111,
    "test_steps_per_second": 20.111,
    "instance_count": 8
  },
  "crass_ai": {
    "test_loss": 1.3863705396652222,
    "test_accuracy": 0.4444444444444444,
    "test_roc_auc": NaN,
    "test_runtime": 0.4395,
    "test_samples_per_second": 20.48,
    "test_steps_per_second": 20.48,
    "instance_count": 9
  },
  "cryobiology_spanish": {
    "test_loss": 0.6931042671203613,
    "test_accuracy": 0.5862068965517241,
    "test_roc_auc": NaN,
    "test_runtime": 0.9255,
    "test_samples_per_second": 31.335,
    "test_steps_per_second": 31.335,
    "instance_count": 29
  },
  "dark_humor_detection": {
    "test_loss": 0.693219780921936,
    "test_accuracy": 0.4375,
    "test_roc_auc": 0.2833333333333333,
    "test_runtime": 0.5215,
    "test_samples_per_second": 30.683,
    "test_steps_per_second": 30.683,
    "instance_count": 16
  },
  "discourse_marker_prediction": {
    "test_loss": 2.3024394512176514,
    "test_accuracy": 0.19298245614035087,
    "test_roc_auc": 0.6558136088049693,
    "test_runtime": 16.5635,
    "test_samples_per_second": 10.324,
    "test_steps_per_second": 10.324,
    "instance_count": 171
  },
  "emoji_movie": {
    "test_loss": 1.6094589233398438,
    "test_accuracy": 0.15,
    "test_roc_auc": NaN,
    "test_runtime": 1.1949,
    "test_samples_per_second": 16.738,
    "test_steps_per_second": 16.738,
    "instance_count": 20
  },
  "emojis_emotion_prediction": {
    "test_loss": 2.0794308185577393,
    "test_accuracy": 0.0,
    "test_roc_auc": NaN,
    "test_runtime": 0.3307,
    "test_samples_per_second": 12.097,
    "test_steps_per_second": 12.097,
    "instance_count": 4
  },
  "empirical_judgments": {
    "test_loss": 1.0986177921295166,
    "test_accuracy": 0.25,
    "test_roc_auc": 0.4239010989010989,
    "test_runtime": 0.7959,
    "test_samples_per_second": 25.128,
    "test_steps_per_second": 25.128,
    "instance_count": 20
  },
  "english_russian_proverbs": {
    "test_loss": 1.3863577842712402,
    "test_accuracy": 0.1875,
    "test_roc_auc": 0.3798076923076923,
    "test_runtime": 0.787,
    "test_samples_per_second": 20.331,
    "test_steps_per_second": 20.331,
    "instance_count": 16
  },
  "entailed_polarity": {
    "test_loss": 0.6931506991386414,
    "test_accuracy": 0.5666666666666667,
    "test_roc_auc": 0.7241379310344828,
    "test_runtime": 0.9721,
    "test_samples_per_second": 30.862,
    "test_steps_per_second": 30.862,
    "instance_count": 30
  },
  "entailed_polarity_hindi": {
    "test_loss": 0.6931333541870117,
    "test_accuracy": 0.7142857142857143,
    "test_roc_auc": 0.672514619883041,
    "test_runtime": 0.8976,
    "test_samples_per_second": 31.195,
    "test_steps_per_second": 31.195,
    "instance_count": 28
  },
  "epistemic_reasoning": {
    "test_loss": 0.6931535005569458,
    "test_accuracy": 0.4926829268292683,
    "test_roc_auc": 0.426952798663325,
    "test_runtime": 6.4605,
    "test_samples_per_second": 31.731,
    "test_steps_per_second": 31.731,
    "instance_count": 205
  },
  "evaluating_information_essentiality": {
    "test_loss": 1.6094157695770264,
    "test_accuracy": 0.21428571428571427,
    "test_roc_auc": 0.5768398268398267,
    "test_runtime": 0.8701,
    "test_samples_per_second": 16.09,
    "test_steps_per_second": 16.09,
    "instance_count": 14
  },
  "fact_checker": {
    "test_loss": 0.6931421160697937,
    "test_accuracy": 0.509090909090909,
    "test_roc_auc": 0.53,
    "test_runtime": 5.1927,
    "test_samples_per_second": 31.776,
    "test_steps_per_second": 31.776,
    "instance_count": 165
  },
  "fantasy_reasoning": {
    "test_loss": 0.6931432485580444,
    "test_accuracy": 0.525,
    "test_roc_auc": 0.5864661654135338,
    "test_runtime": 1.2778,
    "test_samples_per_second": 31.303,
    "test_steps_per_second": 31.303,
    "instance_count": 40
  },
  "figure_of_speech_detection": {
    "test_loss": 2.3026249408721924,
    "test_accuracy": 0.08333333333333333,
    "test_roc_auc": NaN,
    "test_runtime": 1.1505,
    "test_samples_per_second": 10.43,
    "test_steps_per_second": 10.43,
    "instance_count": 12
  },
  "formal_fallacies_syllogisms_negation": {
    "test_loss": 0.6931490302085876,
    "test_accuracy": 0.5219512195121951,
    "test_roc_auc": 0.5031947358382606,
    "test_runtime": 6.5046,
    "test_samples_per_second": 31.516,
    "test_steps_per_second": 31.516,
    "instance_count": 205
  },
  "hhh_alignment": {
    "test_loss": 0.6931008100509644,
    "test_accuracy": 0.5227272727272727,
    "test_roc_auc": NaN,
    "test_runtime": 1.3971,
    "test_samples_per_second": 31.493,
    "test_steps_per_second": 31.493,
    "instance_count": 44
  },
  "hinglish_toxicity": {
    "test_loss": 0.693156898021698,
    "test_accuracy": 0.35,
    "test_roc_auc": 0.5146666666666666,
    "test_runtime": 1.2759,
    "test_samples_per_second": 31.351,
    "test_steps_per_second": 31.351,
    "instance_count": 40
  },
  "human_organs_senses": {
    "test_loss": 1.386274814605713,
    "test_accuracy": 0.5,
    "test_roc_auc": NaN,
    "test_runtime": 0.3898,
    "test_samples_per_second": 20.521,
    "test_steps_per_second": 20.521,
    "instance_count": 8
  },
  "hyperbaton": {
    "test_loss": 0.69309002161026,
    "test_accuracy": 0.5804878048780487,
    "test_roc_auc": 0.5873068853709709,
    "test_runtime": 6.4412,
    "test_samples_per_second": 31.826,
    "test_steps_per_second": 31.826,
    "instance_count": 205
  },
  "implicatures": {
    "test_loss": 0.6931353807449341,
    "test_accuracy": 0.6224489795918368,
    "test_roc_auc": 0.5601293103448276,
    "test_runtime": 3.0927,
    "test_samples_per_second": 31.688,
    "test_steps_per_second": 31.688,
    "instance_count": 98
  },
  "implicit_relations": {
    "test_loss": 3.2187633514404297,
    "test_accuracy": 0.058823529411764705,
    "test_roc_auc": NaN,
    "test_runtime": 3.7491,
    "test_samples_per_second": 4.534,
    "test_steps_per_second": 4.534,
    "instance_count": 17
  },
  "intent_recognition": {
    "test_loss": 1.9458667039871216,
    "test_accuracy": 0.23741007194244604,
    "test_roc_auc": 0.5826913363130583,
    "test_runtime": 9.8436,
    "test_samples_per_second": 14.121,
    "test_steps_per_second": 14.121,
    "instance_count": 139
  },
  "international_phonetic_alphabet_nli": {
    "test_loss": 1.0986027717590332,
    "test_accuracy": 0.36,
    "test_roc_auc": 0.5528366013071895,
    "test_runtime": 0.9975,
    "test_samples_per_second": 25.063,
    "test_steps_per_second": 25.063,
    "instance_count": 25
  },
  "irony_identification": {
    "test_loss": 0.6930809617042542,
    "test_accuracy": 0.6,
    "test_roc_auc": 0.4285714285714286,
    "test_runtime": 0.6448,
    "test_samples_per_second": 31.015,
    "test_steps_per_second": 31.015,
    "instance_count": 20
  },
  "kanji_ascii": {
    "test_loss": 1.6094245910644531,
    "test_accuracy": 0.2894736842105263,
    "test_roc_auc": 0.4998401453110956,
    "test_runtime": 2.1457,
    "test_samples_per_second": 17.71,
    "test_steps_per_second": 17.71,
    "instance_count": 38
  },
  "key_value_maps": {
    "test_loss": 0.6931628584861755,
    "test_accuracy": 0.35,
    "test_roc_auc": 0.6,
    "test_runtime": 0.6499,
    "test_samples_per_second": 30.775,
    "test_steps_per_second": 30.775,
    "instance_count": 20
  },
  "known_unknowns": {
    "test_loss": 0.6932132840156555,
    "test_accuracy": 0.3333333333333333,
    "test_roc_auc": 0.39999999999999997,
    "test_runtime": 0.3015,
    "test_samples_per_second": 29.848,
    "test_steps_per_second": 29.848,
    "instance_count": 9
  },
  "language_identification": {
    "test_loss": 2.397880792617798,
    "test_accuracy": 0.0975609756097561,
    "test_roc_auc": 0.5245260079773065,
    "test_runtime": 21.8488,
    "test_samples_per_second": 9.383,
    "test_steps_per_second": 9.383,
    "instance_count": 205
  },
  "logical_args": {
    "test_loss": 1.6093889474868774,
    "test_accuracy": 0.3333333333333333,
    "test_roc_auc": NaN,
    "test_runtime": 0.3458,
    "test_samples_per_second": 17.351,
    "test_steps_per_second": 17.351,
    "instance_count": 6
  },
  "logical_fallacy_detection": {
    "test_loss": 0.6931672096252441,
    "test_accuracy": 0.5024390243902439,
    "test_roc_auc": 0.44512312427856865,
    "test_runtime": 6.4659,
    "test_samples_per_second": 31.705,
    "test_steps_per_second": 31.705,
    "instance_count": 205
  },
  "mathematical_induction": {
    "test_loss": 0.6931434869766235,
    "test_accuracy": 0.5714285714285714,
    "test_roc_auc": 0.625,
    "test_runtime": 0.4596,
    "test_samples_per_second": 30.462,
    "test_steps_per_second": 30.462,
    "instance_count": 14
  },
  "metaphor_boolean": {
    "test_loss": 0.6931572556495667,
    "test_accuracy": 0.47058823529411764,
    "test_roc_auc": 0.45891455972101136,
    "test_runtime": 4.2884,
    "test_samples_per_second": 31.713,
    "test_steps_per_second": 31.713,
    "instance_count": 136
  },
  "metaphor_understanding": {
    "test_loss": 1.3863800764083862,
    "test_accuracy": 0.19148936170212766,
    "test_roc_auc": NaN,
    "test_runtime": 2.2556,
    "test_samples_per_second": 20.837,
    "test_steps_per_second": 20.837,
    "instance_count": 47
  },
  "misconceptions": {
    "test_loss": 0.6931506395339966,
    "test_accuracy": 0.45454545454545453,
    "test_roc_auc": 0.49375,
    "test_runtime": 1.3971,
    "test_samples_per_second": 31.493,
    "test_steps_per_second": 31.493,
    "instance_count": 44
  },
  "misconceptions_russian": {
    "test_loss": 0.6929264068603516,
    "test_accuracy": 0.8,
    "test_roc_auc": NaN,
    "test_runtime": 0.3246,
    "test_samples_per_second": 30.805,
    "test_steps_per_second": 30.805,
    "instance_count": 10
  },
  "mnist_ascii": {
    "test_loss": 2.302581548690796,
    "test_accuracy": 0.06341463414634146,
    "test_roc_auc": 0.5367577627205878,
    "test_runtime": 19.9029,
    "test_samples_per_second": 10.3,
    "test_steps_per_second": 10.3,
    "instance_count": 205
  },
  "moral_permissibility": {
    "test_loss": 0.6931563019752502,
    "test_accuracy": 0.4117647058823529,
    "test_roc_auc": 0.4385964912280702,
    "test_runtime": 2.1643,
    "test_samples_per_second": 31.418,
    "test_steps_per_second": 31.418,
    "instance_count": 68
  },
  "movie_dialog_same_or_different": {
    "test_loss": 0.6931509375572205,
    "test_accuracy": 0.47804878048780486,
    "test_roc_auc": 0.4598341909662664,
    "test_runtime": 6.5143,
    "test_samples_per_second": 31.469,
    "test_steps_per_second": 31.469,
    "instance_count": 205
  },
  "movie_recommendation": {
    "test_loss": 1.3863765001296997,
    "test_accuracy": 0.08,
    "test_roc_auc": 0.3534560909980431,
    "test_runtime": 4.7818,
    "test_samples_per_second": 20.912,
    "test_steps_per_second": 20.912,
    "instance_count": 100
  },
  "multiemo": {
    "test_loss": 1.386287808418274,
    "test_accuracy": 0.31313131313131315,
    "test_roc_auc": 0.5185059034288458,
    "test_runtime": 9.6173,
    "test_samples_per_second": 20.588,
    "test_steps_per_second": 20.588,
    "instance_count": 198
  },
  "navigate": {
    "test_loss": 0.6931473016738892,
    "test_accuracy": 0.48,
    "test_roc_auc": 0.4967948717948718,
    "test_runtime": 6.2899,
    "test_samples_per_second": 31.797,
    "test_steps_per_second": 31.797,
    "instance_count": 200
  },
  "persian_idioms": {
    "test_loss": 1.3862967491149902,
    "test_accuracy": 0.23076923076923078,
    "test_roc_auc": NaN,
    "test_runtime": 0.6291,
    "test_samples_per_second": 20.665,
    "test_steps_per_second": 20.665,
    "instance_count": 13
  },
  "phrase_relatedness": {
    "test_loss": 1.3861989974975586,
    "test_accuracy": 0.4,
    "test_roc_auc": 0.712827380952381,
    "test_runtime": 0.9691,
    "test_samples_per_second": 20.638,
    "test_steps_per_second": 20.638,
    "instance_count": 20
  },
  "play_dialog_same_or_different": {
    "test_loss": 0.6931513547897339,
    "test_accuracy": 0.4682926829268293,
    "test_roc_auc": 0.46447340760983813,
    "test_runtime": 6.5089,
    "test_samples_per_second": 31.495,
    "test_steps_per_second": 31.495,
    "instance_count": 205
  },
  "presuppositions_as_nli": {
    "test_loss": 1.098621129989624,
    "test_accuracy": 0.32653061224489793,
    "test_roc_auc": 0.4635396634844414,
    "test_runtime": 5.7467,
    "test_samples_per_second": 25.58,
    "test_steps_per_second": 25.58,
    "instance_count": 147
  },
  "riddle_sense": {
    "test_loss": 1.6094295978546143,
    "test_accuracy": 0.2,
    "test_roc_auc": NaN,
    "test_runtime": 0.5642,
    "test_samples_per_second": 17.725,
    "test_steps_per_second": 17.725,
    "instance_count": 10
  },
  "salient_translation_error_detection": {
    "test_loss": 1.791762351989746,
    "test_accuracy": 0.19,
    "test_roc_auc": 0.46873270613153456,
    "test_runtime": 12.7995,
    "test_samples_per_second": 15.626,
    "test_steps_per_second": 15.626,
    "instance_count": 200
  },
  "sentence_ambiguity": {
    "test_loss": 0.693112313747406,
    "test_accuracy": 0.4166666666666667,
    "test_roc_auc": 0.6666666666666666,
    "test_runtime": 0.3952,
    "test_samples_per_second": 30.363,
    "test_steps_per_second": 30.363,
    "instance_count": 12
  },
  "simple_ethical_questions": {
    "test_loss": 1.386309266090393,
    "test_accuracy": 0.2608695652173913,
    "test_roc_auc": NaN,
    "test_runtime": 1.1127,
    "test_samples_per_second": 20.67,
    "test_steps_per_second": 20.67,
    "instance_count": 23
  },
  "snarks": {
    "test_loss": 0.6931439638137817,
    "test_accuracy": 0.5,
    "test_roc_auc": 0.632716049382716,
    "test_runtime": 1.1512,
    "test_samples_per_second": 31.271,
    "test_steps_per_second": 31.271,
    "instance_count": 36
  },
  "social_support": {
    "test_loss": 1.0986413955688477,
    "test_accuracy": 0.1452513966480447,
    "test_roc_auc": 0.46080081201742823,
    "test_runtime": 6.9943,
    "test_samples_per_second": 25.592,
    "test_steps_per_second": 25.592,
    "instance_count": 179
  },
  "sports_understanding": {
    "test_loss": 0.6931544542312622,
    "test_accuracy": 0.4416243654822335,
    "test_roc_auc": 0.49020016680567136,
    "test_runtime": 6.1873,
    "test_samples_per_second": 31.839,
    "test_steps_per_second": 31.839,
    "instance_count": 197
  },
  "strategyqa": {
    "test_loss": 0.6931493282318115,
    "test_accuracy": 0.48292682926829267,
    "test_roc_auc": 0.4463562753036437,
    "test_runtime": 6.4546,
    "test_samples_per_second": 31.76,
    "test_steps_per_second": 31.76,
    "instance_count": 205
  },
  "suicide_risk": {
    "test_loss": 1.3863122463226318,
    "test_accuracy": 0.125,
    "test_roc_auc": 0.4714285714285714,
    "test_runtime": 0.4054,
    "test_samples_per_second": 19.735,
    "test_steps_per_second": 19.735,
    "instance_count": 8
  },
  "swahili_english_proverbs": {
    "test_loss": 1.386387825012207,
    "test_accuracy": 0.1935483870967742,
    "test_roc_auc": NaN,
    "test_runtime": 1.4881,
    "test_samples_per_second": 20.832,
    "test_steps_per_second": 20.832,
    "instance_count": 31
  },
  "swedish_to_german_proverbs": {
    "test_loss": 1.3864580392837524,
    "test_accuracy": 0.14285714285714285,
    "test_roc_auc": 0.25793650793650796,
    "test_runtime": 0.6892,
    "test_samples_per_second": 20.315,
    "test_steps_per_second": 20.315,
    "instance_count": 14
  },
  "symbol_interpretation": {
    "test_loss": 1.6094545125961304,
    "test_accuracy": 0.23232323232323232,
    "test_roc_auc": 0.48221639076277584,
    "test_runtime": 11.0978,
    "test_samples_per_second": 17.841,
    "test_steps_per_second": 17.841,
    "instance_count": 198
  },
  "temporal_sequences": {
    "test_loss": 1.3862931728363037,
    "test_accuracy": 0.23,
    "test_roc_auc": NaN,
    "test_runtime": 9.5945,
    "test_samples_per_second": 20.845,
    "test_steps_per_second": 20.845,
    "instance_count": 200
  },
  "timedial": {
    "test_loss": 1.0986618995666504,
    "test_accuracy": 0.34146341463414637,
    "test_roc_auc": NaN,
    "test_runtime": 8.0462,
    "test_samples_per_second": 25.478,
    "test_steps_per_second": 25.478,
    "instance_count": 205
  },
  "understanding_fables": {
    "test_loss": 1.6094566583633423,
    "test_accuracy": 0.23684210526315788,
    "test_roc_auc": 0.4887141985092236,
    "test_runtime": 2.1447,
    "test_samples_per_second": 17.718,
    "test_steps_per_second": 17.718,
    "instance_count": 38
  },
  "unit_interpretation": {
    "test_loss": 1.609464406967163,
    "test_accuracy": 0.2,
    "test_roc_auc": 0.411313578062804,
    "test_runtime": 1.1303,
    "test_samples_per_second": 17.695,
    "test_steps_per_second": 17.695,
    "instance_count": 20
  },
  "vitaminc_fact_verification": {
    "test_loss": 1.0985835790634155,
    "test_accuracy": 0.43902439024390244,
    "test_roc_auc": 0.5462411639958661,
    "test_runtime": 7.9846,
    "test_samples_per_second": 25.674,
    "test_steps_per_second": 25.674,
    "instance_count": 205
  },
  "what_is_the_tao": {
    "test_loss": 0.6931501626968384,
    "test_accuracy": 0.2857142857142857,
    "test_roc_auc": 0.5833333333333334,
    "test_runtime": 0.2399,
    "test_samples_per_second": 29.173,
    "test_steps_per_second": 29.173,
    "instance_count": 7
  },
  "which_wiki_edit": {
    "test_loss": 1.3862860202789307,
    "test_accuracy": 0.23684210526315788,
    "test_roc_auc": NaN,
    "test_runtime": 5.4791,
    "test_samples_per_second": 20.806,
    "test_steps_per_second": 20.806,
    "instance_count": 114
  },
  "winowhy": {
    "test_loss": 0.6931493878364563,
    "test_accuracy": 0.5219512195121951,
    "test_roc_auc": 0.5132700503680744,
    "test_runtime": 6.4692,
    "test_samples_per_second": 31.689,
    "test_steps_per_second": 31.689,
    "instance_count": 205
  }
}