{
  "anachronisms": {
    "test_loss": 0.6931628584861755,
    "test_accuracy": 0.43478260869565216,
    "test_roc_auc": 0.6432692307692307,
    "test_runtime": 1.5942,
    "test_samples_per_second": 28.854,
    "test_steps_per_second": 28.854,
    "instance_count": 46
  },
  "analogical_similarity": {
    "test_loss": 1.9458911418914795,
    "test_accuracy": 0.12307692307692308,
    "test_roc_auc": 0.5,
    "test_runtime": 4.7885,
    "test_samples_per_second": 13.574,
    "test_steps_per_second": 13.574,
    "instance_count": 65
  },
  "analytic_entailment": {
    "test_loss": 0.6930654644966125,
    "test_accuracy": 0.6428571428571429,
    "test_roc_auc": 0.4666666666666666,
    "test_runtime": 0.4877,
    "test_samples_per_second": 28.704,
    "test_steps_per_second": 28.704,
    "instance_count": 14
  },
  "authorship_verification": {
    "test_loss": 0.6931363940238953,
    "test_accuracy": 0.5284090909090909,
    "test_roc_auc": 0.5257918552036199,
    "test_runtime": 6.0348,
    "test_samples_per_second": 29.164,
    "test_steps_per_second": 29.164,
    "instance_count": 176
  },
  "bbq_lite_json": {
    "test_loss": 1.0986522436141968,
    "test_accuracy": 0.32673267326732675,
    "test_roc_auc": 0.43770356344157396,
    "test_runtime": 8.3264,
    "test_samples_per_second": 24.26,
    "test_steps_per_second": 24.26,
    "instance_count": 202
  },
  "causal_judgment": {
    "test_loss": 0.6931367516517639,
    "test_accuracy": 0.5789473684210527,
    "test_roc_auc": 0.484375,
    "test_runtime": 1.3067,
    "test_samples_per_second": 29.08,
    "test_steps_per_second": 29.08,
    "instance_count": 38
  },
  "cause_and_effect": {
    "test_loss": 0.6930103302001953,
    "test_accuracy": 0.5483870967741935,
    "test_roc_auc": NaN,
    "test_runtime": 1.0545,
    "test_samples_per_second": 29.398,
    "test_steps_per_second": 29.398,
    "instance_count": 31
  },
  "cifar10_classification": {
    "test_loss": 2.3025894165039062,
    "test_accuracy": 0.07317073170731707,
    "test_roc_auc": 0.46720587128779956,
    "test_runtime": 20.1653,
    "test_samples_per_second": 10.166,
    "test_steps_per_second": 10.166,
    "instance_count": 205
  },
  "color": {
    "test_loss": 2.30253005027771,
    "test_accuracy": 0.1951219512195122,
    "test_roc_auc": 0.5083144522411271,
    "test_runtime": 19.8527,
    "test_samples_per_second": 10.326,
    "test_steps_per_second": 10.326,
    "instance_count": 205
  },
  "common_morpheme": {
    "test_loss": 1.3861831426620483,
    "test_accuracy": 0.4,
    "test_roc_auc": 0.6841269841269841,
    "test_runtime": 0.5151,
    "test_samples_per_second": 19.413,
    "test_steps_per_second": 19.413,
    "instance_count": 10
  },
  "conceptual_combinations": {
    "test_loss": 1.3863824605941772,
    "test_accuracy": 0.23809523809523808,
    "test_roc_auc": NaN,
    "test_runtime": 1.0536,
    "test_samples_per_second": 19.932,
    "test_steps_per_second": 19.932,
    "instance_count": 21
  },
  "crash_blossom": {
    "test_loss": 1.3863248825073242,
    "test_accuracy": 0.125,
    "test_roc_auc": NaN,
    "test_runtime": 0.4112,
    "test_samples_per_second": 19.455,
    "test_steps_per_second": 19.455,
    "instance_count": 8
  },
  "crass_ai": {
    "test_loss": 1.3863884210586548,
    "test_accuracy": 0.2222222222222222,
    "test_roc_auc": 0.47129629629629627,
    "test_runtime": 0.4719,
    "test_samples_per_second": 19.071,
    "test_steps_per_second": 19.071,
    "instance_count": 9
  },
  "cryobiology_spanish": {
    "test_loss": 0.693128764629364,
    "test_accuracy": 0.5517241379310345,
    "test_roc_auc": NaN,
    "test_runtime": 0.9922,
    "test_samples_per_second": 29.228,
    "test_steps_per_second": 29.228,
    "instance_count": 29
  },
  "dark_humor_detection": {
    "test_loss": 0.6931808590888977,
    "test_accuracy": 0.4375,
    "test_roc_auc": 0.5555555555555556,
    "test_runtime": 0.5562,
    "test_samples_per_second": 28.766,
    "test_steps_per_second": 28.766,
    "instance_count": 16
  },
  "discourse_marker_prediction": {
    "test_loss": 2.3025708198547363,
    "test_accuracy": 0.1111111111111111,
    "test_roc_auc": 0.5312452886489814,
    "test_runtime": 16.6648,
    "test_samples_per_second": 10.261,
    "test_steps_per_second": 10.261,
    "instance_count": 171
  },
  "emoji_movie": {
    "test_loss": 1.6094201803207397,
    "test_accuracy": 0.1,
    "test_roc_auc": NaN,
    "test_runtime": 1.1496,
    "test_samples_per_second": 17.397,
    "test_steps_per_second": 17.397,
    "instance_count": 20
  },
  "emojis_emotion_prediction": {
    "test_loss": 2.0794830322265625,
    "test_accuracy": 0.0,
    "test_roc_auc": NaN,
    "test_runtime": 0.1731,
    "test_samples_per_second": 11.557,
    "test_steps_per_second": 11.557,
    "instance_count": 2
  },
  "empirical_judgments": {
    "test_loss": 1.0986069440841675,
    "test_accuracy": 0.4,
    "test_roc_auc": 0.6707277097902098,
    "test_runtime": 0.8424,
    "test_samples_per_second": 23.742,
    "test_steps_per_second": 23.742,
    "instance_count": 20
  },
  "english_russian_proverbs": {
    "test_loss": 1.386213779449463,
    "test_accuracy": 0.5,
    "test_roc_auc": 0.5922619047619047,
    "test_runtime": 0.8184,
    "test_samples_per_second": 19.549,
    "test_steps_per_second": 19.549,
    "instance_count": 16
  },
  "entailed_polarity": {
    "test_loss": 0.693109393119812,
    "test_accuracy": 0.5666666666666667,
    "test_roc_auc": NaN,
    "test_runtime": 1.0186,
    "test_samples_per_second": 29.453,
    "test_steps_per_second": 29.453,
    "instance_count": 30
  },
  "entailed_polarity_hindi": {
    "test_loss": 0.6931306719779968,
    "test_accuracy": 0.7142857142857143,
    "test_roc_auc": 0.6615384615384615,
    "test_runtime": 0.9618,
    "test_samples_per_second": 29.113,
    "test_steps_per_second": 29.113,
    "instance_count": 28
  },
  "epistemic_reasoning": {
    "test_loss": 0.6932057738304138,
    "test_accuracy": 0.3853658536585366,
    "test_roc_auc": 0.4411974704202366,
    "test_runtime": 6.9831,
    "test_samples_per_second": 29.356,
    "test_steps_per_second": 29.356,
    "instance_count": 205
  },
  "evaluating_information_essentiality": {
    "test_loss": 1.6094034910202026,
    "test_accuracy": 0.14285714285714285,
    "test_roc_auc": 0.5637862137862137,
    "test_runtime": 0.8296,
    "test_samples_per_second": 16.876,
    "test_steps_per_second": 16.876,
    "instance_count": 14
  },
  "fact_checker": {
    "test_loss": 0.6931555867195129,
    "test_accuracy": 0.4727272727272727,
    "test_roc_auc": 0.5269672855879752,
    "test_runtime": 5.5963,
    "test_samples_per_second": 29.484,
    "test_steps_per_second": 29.484,
    "instance_count": 165
  },
  "fantasy_reasoning": {
    "test_loss": 0.6931541562080383,
    "test_accuracy": 0.475,
    "test_roc_auc": 0.5151515151515151,
    "test_runtime": 1.3762,
    "test_samples_per_second": 29.066,
    "test_steps_per_second": 29.066,
    "instance_count": 40
  },
  "figure_of_speech_detection": {
    "test_loss": 2.3024485111236572,
    "test_accuracy": 0.08333333333333333,
    "test_roc_auc": NaN,
    "test_runtime": 1.1661,
    "test_samples_per_second": 10.29,
    "test_steps_per_second": 10.29,
    "instance_count": 12
  },
  "formal_fallacies_syllogisms_negation": {
    "test_loss": 0.6931468844413757,
    "test_accuracy": 0.5121951219512195,
    "test_roc_auc": 0.47538095238095235,
    "test_runtime": 6.9519,
    "test_samples_per_second": 29.488,
    "test_steps_per_second": 29.488,
    "instance_count": 205
  },
  "hhh_alignment": {
    "test_loss": 0.6924600005149841,
    "test_accuracy": 0.7045454545454546,
    "test_roc_auc": NaN,
    "test_runtime": 1.4975,
    "test_samples_per_second": 29.382,
    "test_steps_per_second": 29.382,
    "instance_count": 44
  },
  "hinglish_toxicity": {
    "test_loss": 0.6931647062301636,
    "test_accuracy": 0.375,
    "test_roc_auc": 0.22556390977443608,
    "test_runtime": 1.3827,
    "test_samples_per_second": 28.929,
    "test_steps_per_second": 28.929,
    "instance_count": 40
  },
  "human_organs_senses": {
    "test_loss": 1.3864834308624268,
    "test_accuracy": 0.0,
    "test_roc_auc": NaN,
    "test_runtime": 0.4043,
    "test_samples_per_second": 19.79,
    "test_steps_per_second": 19.79,
    "instance_count": 8
  },
  "hyperbaton": {
    "test_loss": 0.6931100487709045,
    "test_accuracy": 0.5219512195121951,
    "test_roc_auc": 0.639567041769979,
    "test_runtime": 6.9288,
    "test_samples_per_second": 29.587,
    "test_steps_per_second": 29.587,
    "instance_count": 205
  },
  "implicatures": {
    "test_loss": 0.6931400895118713,
    "test_accuracy": 0.5102040816326531,
    "test_roc_auc": 0.6415094339622641,
    "test_runtime": 3.3329,
    "test_samples_per_second": 29.404,
    "test_steps_per_second": 29.404,
    "instance_count": 98
  },
  "implicit_relations": {
    "test_loss": 3.2188708782196045,
    "test_accuracy": 0.0,
    "test_roc_auc": NaN,
    "test_runtime": 3.7243,
    "test_samples_per_second": 4.565,
    "test_steps_per_second": 4.565,
    "instance_count": 17
  },
  "intent_recognition": {
    "test_loss": 1.9458763599395752,
    "test_accuracy": 0.22302158273381295,
    "test_roc_auc": 0.5778689050938147,
    "test_runtime": 10.0616,
    "test_samples_per_second": 13.815,
    "test_steps_per_second": 13.815,
    "instance_count": 139
  },
  "international_phonetic_alphabet_nli": {
    "test_loss": 1.0986227989196777,
    "test_accuracy": 0.32,
    "test_roc_auc": 0.4726666666666667,
    "test_runtime": 1.046,
    "test_samples_per_second": 23.9,
    "test_steps_per_second": 23.9,
    "instance_count": 25
  },
  "irony_identification": {
    "test_loss": 0.6930934190750122,
    "test_accuracy": 0.7,
    "test_roc_auc": 0.3928571428571428,
    "test_runtime": 0.6982,
    "test_samples_per_second": 28.643,
    "test_steps_per_second": 28.643,
    "instance_count": 20
  },
  "kanji_ascii": {
    "test_loss": 1.609320044517517,
    "test_accuracy": 0.2631578947368421,
    "test_roc_auc": 0.5507167207828761,
    "test_runtime": 2.2045,
    "test_samples_per_second": 17.237,
    "test_steps_per_second": 17.237,
    "instance_count": 38
  },
  "key_value_maps": {
    "test_loss": 0.6931517124176025,
    "test_accuracy": 0.5,
    "test_roc_auc": 0.5416666666666667,
    "test_runtime": 0.6967,
    "test_samples_per_second": 28.707,
    "test_steps_per_second": 28.707,
    "instance_count": 20
  },
  "known_unknowns": {
    "test_loss": 0.693243682384491,
    "test_accuracy": 0.5555555555555556,
    "test_roc_auc": 0.44999999999999996,
    "test_runtime": 0.3216,
    "test_samples_per_second": 27.988,
    "test_steps_per_second": 27.988,
    "instance_count": 9
  },
  "language_identification": {
    "test_loss": 2.3978664875030518,
    "test_accuracy": 0.08292682926829269,
    "test_roc_auc": 0.532962670857607,
    "test_runtime": 21.8277,
    "test_samples_per_second": 9.392,
    "test_steps_per_second": 9.392,
    "instance_count": 205
  },
  "logical_args": {
    "test_loss": 1.609358310699463,
    "test_accuracy": 0.0,
    "test_roc_auc": NaN,
    "test_runtime": 0.3529,
    "test_samples_per_second": 17.002,
    "test_steps_per_second": 17.002,
    "instance_count": 6
  },
  "logical_fallacy_detection": {
    "test_loss": 0.693160355091095,
    "test_accuracy": 0.44878048780487806,
    "test_roc_auc": 0.5523759138130049,
    "test_runtime": 6.9289,
    "test_samples_per_second": 29.586,
    "test_steps_per_second": 29.586,
    "instance_count": 205
  },
  "mathematical_induction": {
    "test_loss": 0.6931555867195129,
    "test_accuracy": 0.5,
    "test_roc_auc": 0.40816326530612246,
    "test_runtime": 0.592,
    "test_samples_per_second": 23.649,
    "test_steps_per_second": 23.649,
    "instance_count": 14
  },
  "metaphor_boolean": {
    "test_loss": 0.6931466460227966,
    "test_accuracy": 0.5220588235294118,
    "test_roc_auc": 0.5829228243021348,
    "test_runtime": 4.6245,
    "test_samples_per_second": 29.409,
    "test_steps_per_second": 29.409,
    "instance_count": 136
  },
  "metaphor_understanding": {
    "test_loss": 1.3863260746002197,
    "test_accuracy": 0.23404255319148937,
    "test_roc_auc": NaN,
    "test_runtime": 2.3385,
    "test_samples_per_second": 20.098,
    "test_steps_per_second": 20.098,
    "instance_count": 47
  },
  "misconceptions": {
    "test_loss": 0.6931566596031189,
    "test_accuracy": 0.4772727272727273,
    "test_roc_auc": 0.47544642857142855,
    "test_runtime": 1.502,
    "test_samples_per_second": 29.294,
    "test_steps_per_second": 29.294,
    "instance_count": 44
  },
  "misconceptions_russian": {
    "test_loss": 0.6935945749282837,
    "test_accuracy": 0.3,
    "test_roc_auc": NaN,
    "test_runtime": 0.3477,
    "test_samples_per_second": 28.756,
    "test_steps_per_second": 28.756,
    "instance_count": 10
  },
  "mnist_ascii": {
    "test_loss": 2.3025765419006348,
    "test_accuracy": 0.12195121951219512,
    "test_roc_auc": 0.5031391706465332,
    "test_runtime": 20.0128,
    "test_samples_per_second": 10.243,
    "test_steps_per_second": 10.243,
    "instance_count": 205
  },
  "moral_permissibility": {
    "test_loss": 0.6931431889533997,
    "test_accuracy": 0.5588235294117647,
    "test_roc_auc": 0.5475778546712803,
    "test_runtime": 2.3205,
    "test_samples_per_second": 29.304,
    "test_steps_per_second": 29.304,
    "instance_count": 68
  },
  "movie_dialog_same_or_different": {
    "test_loss": 0.6931464672088623,
    "test_accuracy": 0.5121951219512195,
    "test_roc_auc": 0.5442633886030113,
    "test_runtime": 6.9657,
    "test_samples_per_second": 29.43,
    "test_steps_per_second": 29.43,
    "instance_count": 205
  },
  "movie_recommendation": {
    "test_loss": 1.3863341808319092,
    "test_accuracy": 0.12,
    "test_roc_auc": 0.4341678230445354,
    "test_runtime": 4.9844,
    "test_samples_per_second": 20.063,
    "test_steps_per_second": 20.063,
    "instance_count": 100
  },
  "multiemo": {
    "test_loss": 1.3863109350204468,
    "test_accuracy": 0.1919191919191919,
    "test_roc_auc": 0.5559583228247,
    "test_runtime": 9.8826,
    "test_samples_per_second": 20.035,
    "test_steps_per_second": 20.035,
    "instance_count": 198
  },
  "navigate": {
    "test_loss": 0.6931628584861755,
    "test_accuracy": 0.435,
    "test_roc_auc": 0.5271081273522531,
    "test_runtime": 6.7935,
    "test_samples_per_second": 29.44,
    "test_steps_per_second": 29.44,
    "instance_count": 200
  },
  "persian_idioms": {
    "test_loss": 1.386555552482605,
    "test_accuracy": 0.0,
    "test_roc_auc": 0.18974358974358976,
    "test_runtime": 0.6641,
    "test_samples_per_second": 19.576,
    "test_steps_per_second": 19.576,
    "instance_count": 13
  },
  "phrase_relatedness": {
    "test_loss": 1.3862323760986328,
    "test_accuracy": 0.4,
    "test_roc_auc": 0.6008968972204266,
    "test_runtime": 1.0172,
    "test_samples_per_second": 19.661,
    "test_steps_per_second": 19.661,
    "instance_count": 20
  },
  "play_dialog_same_or_different": {
    "test_loss": 0.6931523084640503,
    "test_accuracy": 0.37073170731707317,
    "test_roc_auc": 0.56595543409712,
    "test_runtime": 6.9967,
    "test_samples_per_second": 29.3,
    "test_steps_per_second": 29.3,
    "instance_count": 205
  },
  "presuppositions_as_nli": {
    "test_loss": 1.0986366271972656,
    "test_accuracy": 0.23809523809523808,
    "test_roc_auc": 0.4853754955468802,
    "test_runtime": 6.0498,
    "test_samples_per_second": 24.298,
    "test_steps_per_second": 24.298,
    "instance_count": 147
  },
  "riddle_sense": {
    "test_loss": 1.6093800067901611,
    "test_accuracy": 0.2,
    "test_roc_auc": 0.5827380952380953,
    "test_runtime": 0.5929,
    "test_samples_per_second": 16.866,
    "test_steps_per_second": 16.866,
    "instance_count": 10
  },
  "salient_translation_error_detection": {
    "test_loss": 1.7917494773864746,
    "test_accuracy": 0.165,
    "test_roc_auc": 0.5001536043716276,
    "test_runtime": 13.0844,
    "test_samples_per_second": 15.285,
    "test_steps_per_second": 15.285,
    "instance_count": 200
  },
  "sentence_ambiguity": {
    "test_loss": 0.6932051777839661,
    "test_accuracy": 0.4166666666666667,
    "test_roc_auc": 0.45714285714285713,
    "test_runtime": 0.4208,
    "test_samples_per_second": 28.517,
    "test_steps_per_second": 28.517,
    "instance_count": 12
  },
  "simple_ethical_questions": {
    "test_loss": 1.3863420486450195,
    "test_accuracy": 0.17391304347826086,
    "test_roc_auc": NaN,
    "test_runtime": 1.1529,
    "test_samples_per_second": 19.95,
    "test_steps_per_second": 19.95,
    "instance_count": 23
  },
  "snarks": {
    "test_loss": 0.6931026577949524,
    "test_accuracy": 0.5555555555555556,
    "test_roc_auc": 0.6006191950464397,
    "test_runtime": 1.2427,
    "test_samples_per_second": 28.969,
    "test_steps_per_second": 28.969,
    "instance_count": 36
  },
  "social_support": {
    "test_loss": 1.0985934734344482,
    "test_accuracy": 0.3743016759776536,
    "test_roc_auc": 0.4970934733860742,
    "test_runtime": 7.3557,
    "test_samples_per_second": 24.335,
    "test_steps_per_second": 24.335,
    "instance_count": 179
  },
  "sports_understanding": {
    "test_loss": 0.6931454539299011,
    "test_accuracy": 0.4873096446700508,
    "test_roc_auc": 0.5719368811881188,
    "test_runtime": 6.6581,
    "test_samples_per_second": 29.588,
    "test_steps_per_second": 29.588,
    "instance_count": 197
  },
  "strategyqa": {
    "test_loss": 0.6931658983230591,
    "test_accuracy": 0.48292682926829267,
    "test_roc_auc": 0.49336283185840707,
    "test_runtime": 6.9568,
    "test_samples_per_second": 29.468,
    "test_steps_per_second": 29.468,
    "instance_count": 205
  },
  "suicide_risk": {
    "test_loss": 1.386335849761963,
    "test_accuracy": 0.0,
    "test_roc_auc": NaN,
    "test_runtime": 0.4055,
    "test_samples_per_second": 19.731,
    "test_steps_per_second": 19.731,
    "instance_count": 8
  },
  "swahili_english_proverbs": {
    "test_loss": 1.3864961862564087,
    "test_accuracy": 0.16129032258064516,
    "test_roc_auc": NaN,
    "test_runtime": 1.5482,
    "test_samples_per_second": 20.023,
    "test_steps_per_second": 20.023,
    "instance_count": 31
  },
  "swedish_to_german_proverbs": {
    "test_loss": 1.3862875699996948,
    "test_accuracy": 0.35714285714285715,
    "test_roc_auc": 0.5576118326118327,
    "test_runtime": 0.7155,
    "test_samples_per_second": 19.568,
    "test_steps_per_second": 19.568,
    "instance_count": 14
  },
  "symbol_interpretation": {
    "test_loss": 1.6094307899475098,
    "test_accuracy": 0.20707070707070707,
    "test_roc_auc": 0.5254661474604699,
    "test_runtime": 11.373,
    "test_samples_per_second": 17.41,
    "test_steps_per_second": 17.41,
    "instance_count": 198
  },
  "temporal_sequences": {
    "test_loss": 1.3862496614456177,
    "test_accuracy": 0.395,
    "test_roc_auc": NaN,
    "test_runtime": 9.9391,
    "test_samples_per_second": 20.123,
    "test_steps_per_second": 20.123,
    "instance_count": 200
  },
  "timedial": {
    "test_loss": 1.09861421585083,
    "test_accuracy": 0.32195121951219513,
    "test_roc_auc": NaN,
    "test_runtime": 8.4659,
    "test_samples_per_second": 24.215,
    "test_steps_per_second": 24.215,
    "instance_count": 205
  },
  "understanding_fables": {
    "test_loss": 1.6094694137573242,
    "test_accuracy": 0.15789473684210525,
    "test_roc_auc": 0.44880468522234224,
    "test_runtime": 2.2117,
    "test_samples_per_second": 17.182,
    "test_steps_per_second": 17.182,
    "instance_count": 38
  },
  "unit_interpretation": {
    "test_loss": 1.6095203161239624,
    "test_accuracy": 0.05,
    "test_roc_auc": 0.3510573780794369,
    "test_runtime": 1.1772,
    "test_samples_per_second": 16.989,
    "test_steps_per_second": 16.989,
    "instance_count": 20
  },
  "vitaminc_fact_verification": {
    "test_loss": 1.0986137390136719,
    "test_accuracy": 0.424390243902439,
    "test_roc_auc": 0.4930747910925242,
    "test_runtime": 8.4323,
    "test_samples_per_second": 24.311,
    "test_steps_per_second": 24.311,
    "instance_count": 205
  },
  "what_is_the_tao": {
    "test_loss": 0.6931400299072266,
    "test_accuracy": 0.7142857142857143,
    "test_roc_auc": 0.8333333333333334,
    "test_runtime": 0.2565,
    "test_samples_per_second": 27.286,
    "test_steps_per_second": 27.286,
    "instance_count": 7
  },
  "which_wiki_edit": {
    "test_loss": 1.3863632678985596,
    "test_accuracy": 0.21052631578947367,
    "test_roc_auc": NaN,
    "test_runtime": 5.7049,
    "test_samples_per_second": 19.983,
    "test_steps_per_second": 19.983,
    "instance_count": 114
  },
  "winowhy": {
    "test_loss": 0.6931588649749756,
    "test_accuracy": 0.4634146341463415,
    "test_roc_auc": 0.5658851674641149,
    "test_runtime": 6.9707,
    "test_samples_per_second": 29.409,
    "test_steps_per_second": 29.409,
    "instance_count": 205
  }
}